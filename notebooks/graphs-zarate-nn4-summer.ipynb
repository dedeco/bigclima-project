{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, integrate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import shutil\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAABLCAYAAABEDTEaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAAkNJREFUeJzt3L+OjGEYxuHnw2SxFISIKDYSpUZQ6ZyEYvupHIsDcAJqidoR0CGi0hKRFcGKlVej0dg/yXu/M99eVzfJV9xP9fsyk8zUWisA6O3E6AEAHA+CA0CE4AAQITgARAgOABGCA0CE4AAQITgARAgOABGn9ntgmqZlVS2rqqbF6dsbF651HzXK+XMboyd0dfHsYvSErjYXM35/2v06ekFXezs7oyd09ePz99ETuvnw62d9+b03HeTZ6TB/bXPmyo12ffvRkYetuvv3tkZP6OrBrfm+LFRV3b26OXpCNyffPB89oauPz56OntDV6ycvR0/o5uH7t/Vu99uBgjPjV0IAVongABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEVNr7f8PTNOyqpZ/P96sqle9Rw10qao+jR7RyZxvq3LfunPf+tpqrV0+yIP7Buefh6fpRWvtzpFnrbg53zfn26rct+7cdzz4Sg2ACMEBIOKwwXncZcXqmPN9c76tyn3rzn3HwKF+wwGAo/KVGgARggNAhOAAECE4AEQIDgARfwD+T1i7/7LiygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f409d2b1210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.palplot(sns.color_palette(\"RdBu_r\", 7))\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Base com todos os dados do sudeste</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9779168\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/sudeste.csv',low_memory=False)\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3206856\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wsid</th>\n",
       "      <th>wsnm</th>\n",
       "      <th>elvt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>inme</th>\n",
       "      <th>city</th>\n",
       "      <th>prov</th>\n",
       "      <th>mdct</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>tmin</th>\n",
       "      <th>dewp</th>\n",
       "      <th>dmax</th>\n",
       "      <th>dmin</th>\n",
       "      <th>hmdy</th>\n",
       "      <th>hmax</th>\n",
       "      <th>hmin</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>wdct</th>\n",
       "      <th>gust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>178</td>\n",
       "      <td>SÃO GONÇALO</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>A333</td>\n",
       "      <td>São Gonçalo</td>\n",
       "      <td>RJ</td>\n",
       "      <td>2007-12-01 00:00:00</td>\n",
       "      <td>2007-12-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>178</td>\n",
       "      <td>SÃO GONÇALO</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>A333</td>\n",
       "      <td>São Gonçalo</td>\n",
       "      <td>RJ</td>\n",
       "      <td>2007-12-01 01:00:00</td>\n",
       "      <td>2007-12-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>178</td>\n",
       "      <td>SÃO GONÇALO</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>A333</td>\n",
       "      <td>São Gonçalo</td>\n",
       "      <td>RJ</td>\n",
       "      <td>2007-12-01 02:00:00</td>\n",
       "      <td>2007-12-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     wsid         wsnm   elvt       lat        lon  inme         city prov  \\\n",
       "600   178  SÃO GONÇALO  237.0 -6.835777 -38.311583  A333  São Gonçalo   RJ   \n",
       "601   178  SÃO GONÇALO  237.0 -6.835777 -38.311583  A333  São Gonçalo   RJ   \n",
       "602   178  SÃO GONÇALO  237.0 -6.835777 -38.311583  A333  São Gonçalo   RJ   \n",
       "\n",
       "                    mdct        date  ...   tmin  dewp  dmax  dmin  hmdy  \\\n",
       "600  2007-12-01 00:00:00  2007-12-01  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "601  2007-12-01 01:00:00  2007-12-01  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "602  2007-12-01 02:00:00  2007-12-01  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "     hmax  hmin  wdsp  wdct  gust  \n",
       "600   0.0   0.0   0.0   0.0   0.0  \n",
       "601   0.0   0.0   0.0   0.0   0.0  \n",
       "602   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['mo'].isin([1,2,3,12])] #  somente meses do verão  DEZ a MAR\n",
    "print len(df)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Limpeza dos dados</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Campos não numericos e campos derivados\n",
    "DES= ['wsid','wsnm','elvt','lat','lon','inme','city','prov']\n",
    "INT = ['yr','mo','da','hr']\n",
    "DAT = ['mdct','date']\n",
    "DER = ['smax','smin','tmax','tmin','dmax','dmin','hmax','hmin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe apenas com os dados continuos\n",
    "dfcont = df\n",
    "for f in DES + INT + DAT:    \n",
    "    dfcont = dfcont.drop(f, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcont = dfcont.apply(pd.to_numeric, errors='coerce')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3206856 entries, 600 to 9774775\n",
      "Data columns (total 17 columns):\n",
      "prcp    float64\n",
      "stp     float64\n",
      "smax    float64\n",
      "smin    float64\n",
      "gbrd    float64\n",
      "temp    float64\n",
      "tmax    float64\n",
      "tmin    float64\n",
      "dewp    float64\n",
      "dmax    float64\n",
      "dmin    float64\n",
      "hmdy    float64\n",
      "hmax    float64\n",
      "hmin    float64\n",
      "wdsp    float64\n",
      "wdct    float64\n",
      "gust    float64\n",
      "dtypes: float64(17)\n",
      "memory usage: 440.4 MB\n"
     ]
    }
   ],
   "source": [
    "dfcont.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prcp</th>\n",
       "      <td>594823.0</td>\n",
       "      <td>1.244019</td>\n",
       "      <td>3.534589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.800</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>871.062130</td>\n",
       "      <td>259.613938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>909.100</td>\n",
       "      <td>941.700</td>\n",
       "      <td>969.500</td>\n",
       "      <td>1050.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>871.009694</td>\n",
       "      <td>260.134167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>909.300</td>\n",
       "      <td>942.000</td>\n",
       "      <td>969.700</td>\n",
       "      <td>1049.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>870.524392</td>\n",
       "      <td>259.991361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>908.800</td>\n",
       "      <td>941.400</td>\n",
       "      <td>969.200</td>\n",
       "      <td>1048.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbrd</th>\n",
       "      <td>1867241.0</td>\n",
       "      <td>1327.603616</td>\n",
       "      <td>1226.852731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.523</td>\n",
       "      <td>1030.932</td>\n",
       "      <td>2338.961</td>\n",
       "      <td>9173.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>22.195866</td>\n",
       "      <td>7.324802</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>20.200</td>\n",
       "      <td>23.000</td>\n",
       "      <td>26.300</td>\n",
       "      <td>44.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax</th>\n",
       "      <td>3206841.0</td>\n",
       "      <td>17.297762</td>\n",
       "      <td>5.658299</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>16.600</td>\n",
       "      <td>18.700</td>\n",
       "      <td>20.500</td>\n",
       "      <td>42.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>22.799069</td>\n",
       "      <td>7.576136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.700</td>\n",
       "      <td>23.600</td>\n",
       "      <td>27.200</td>\n",
       "      <td>45.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewp</th>\n",
       "      <td>3206840.0</td>\n",
       "      <td>17.823554</td>\n",
       "      <td>5.776646</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>17.200</td>\n",
       "      <td>19.300</td>\n",
       "      <td>21.000</td>\n",
       "      <td>44.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmax</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>21.616621</td>\n",
       "      <td>7.095030</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>19.800</td>\n",
       "      <td>22.500</td>\n",
       "      <td>25.500</td>\n",
       "      <td>45.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmin</th>\n",
       "      <td>3206837.0</td>\n",
       "      <td>16.782890</td>\n",
       "      <td>5.583865</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>16.000</td>\n",
       "      <td>18.200</td>\n",
       "      <td>20.000</td>\n",
       "      <td>44.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>70.058209</td>\n",
       "      <td>26.138010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.000</td>\n",
       "      <td>78.000</td>\n",
       "      <td>90.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>72.838245</td>\n",
       "      <td>26.016667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.000</td>\n",
       "      <td>82.000</td>\n",
       "      <td>92.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin</th>\n",
       "      <td>3206828.0</td>\n",
       "      <td>67.099326</td>\n",
       "      <td>26.188570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>88.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp</th>\n",
       "      <td>2915478.0</td>\n",
       "      <td>1.922870</td>\n",
       "      <td>1.557723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700</td>\n",
       "      <td>1.700</td>\n",
       "      <td>2.800</td>\n",
       "      <td>19.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>138.789374</td>\n",
       "      <td>109.824019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.000</td>\n",
       "      <td>110.000</td>\n",
       "      <td>226.000</td>\n",
       "      <td>360.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust</th>\n",
       "      <td>3115041.0</td>\n",
       "      <td>4.466501</td>\n",
       "      <td>2.936953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.300</td>\n",
       "      <td>4.200</td>\n",
       "      <td>6.300</td>\n",
       "      <td>50.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count         mean          std   min      25%       50%       75%  \\\n",
       "prcp   594823.0     1.244019     3.534589   0.0    0.000     0.200     0.800   \n",
       "stp   3206856.0   871.062130   259.613938   0.0  909.100   941.700   969.500   \n",
       "smax  3206856.0   871.009694   260.134167   0.0  909.300   942.000   969.700   \n",
       "smin  3206856.0   870.524392   259.991361   0.0  908.800   941.400   969.200   \n",
       "gbrd  1867241.0  1327.603616  1226.852731   0.0  132.523  1030.932  2338.961   \n",
       "temp  3206856.0    22.195866     7.324802  -2.8   20.200    23.000    26.300   \n",
       "tmax  3206841.0    17.297762     5.658299 -10.0   16.600    18.700    20.500   \n",
       "tmin  3206856.0    22.799069     7.576136   0.0   20.700    23.600    27.200   \n",
       "dewp  3206840.0    17.823554     5.776646 -10.0   17.200    19.300    21.000   \n",
       "dmax  3206856.0    21.616621     7.095030  -6.9   19.800    22.500    25.500   \n",
       "dmin  3206837.0    16.782890     5.583865 -10.0   16.000    18.200    20.000   \n",
       "hmdy  3206856.0    70.058209    26.138010   0.0   59.000    78.000    90.000   \n",
       "hmax  3206856.0    72.838245    26.016667   0.0   63.000    82.000    92.000   \n",
       "hmin  3206828.0    67.099326    26.188570   0.0   54.000    74.000    88.000   \n",
       "wdsp  2915478.0     1.922870     1.557723   0.0    0.700     1.700     2.800   \n",
       "wdct  3206856.0   138.789374   109.824019   0.0   50.000   110.000   226.000   \n",
       "gust  3115041.0     4.466501     2.936953   0.0    2.300     4.200     6.300   \n",
       "\n",
       "           max  \n",
       "prcp   100.000  \n",
       "stp   1050.000  \n",
       "smax  1049.100  \n",
       "smin  1048.100  \n",
       "gbrd  9173.064  \n",
       "temp    44.900  \n",
       "tmax    42.000  \n",
       "tmin    45.000  \n",
       "dewp    44.800  \n",
       "dmax    45.000  \n",
       "dmin    44.900  \n",
       "hmdy   100.000  \n",
       "hmax   100.000  \n",
       "hmin   100.000  \n",
       "wdsp    19.800  \n",
       "wdct   360.000  \n",
       "gust    50.000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcont.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> A variável gbbr(radiação global) apresenta massivamente números nulos e não pode ser recuperada. Vamos retirar esta variável.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcont =  dfcont.drop('gbrd',1)\n",
    "df = df.drop('gbrd',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Para as precipitações nulas foi inputado 0.0 mm. Também para o vento e rajada de vento.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAN_BE_NULL = ['wdsp','prcp','gust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in CAN_BE_NULL:\n",
    "    df[v] = df[v].fillna(0.0)\n",
    "    dfcont[v] = dfcont[v].fillna(0.0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Vamos ver como os dados contínuos estão organizados: MÍNIMOS, MÁXIMOS, MEDIAS</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prcp</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>0.230747</td>\n",
       "      <td>1.597225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>871.062130</td>\n",
       "      <td>259.613938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>909.1</td>\n",
       "      <td>941.7</td>\n",
       "      <td>969.5</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>871.009694</td>\n",
       "      <td>260.134167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>909.3</td>\n",
       "      <td>942.0</td>\n",
       "      <td>969.7</td>\n",
       "      <td>1049.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>870.524392</td>\n",
       "      <td>259.991361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>908.8</td>\n",
       "      <td>941.4</td>\n",
       "      <td>969.2</td>\n",
       "      <td>1048.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>22.195866</td>\n",
       "      <td>7.324802</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>20.2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax</th>\n",
       "      <td>3206841.0</td>\n",
       "      <td>17.297762</td>\n",
       "      <td>5.658299</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>18.7</td>\n",
       "      <td>20.5</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>22.799069</td>\n",
       "      <td>7.576136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>23.6</td>\n",
       "      <td>27.2</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewp</th>\n",
       "      <td>3206840.0</td>\n",
       "      <td>17.823554</td>\n",
       "      <td>5.776646</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>44.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmax</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>21.616621</td>\n",
       "      <td>7.095030</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>19.8</td>\n",
       "      <td>22.5</td>\n",
       "      <td>25.5</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmin</th>\n",
       "      <td>3206837.0</td>\n",
       "      <td>16.782890</td>\n",
       "      <td>5.583865</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>70.058209</td>\n",
       "      <td>26.138010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>72.838245</td>\n",
       "      <td>26.016667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin</th>\n",
       "      <td>3206828.0</td>\n",
       "      <td>67.099326</td>\n",
       "      <td>26.188570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>1.748157</td>\n",
       "      <td>1.584757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>138.789374</td>\n",
       "      <td>109.824019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>4.338622</td>\n",
       "      <td>2.988905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count        mean         std   min    25%    50%    75%     max\n",
       "prcp  3206856.0    0.230747    1.597225   0.0    0.0    0.0    0.0   100.0\n",
       "stp   3206856.0  871.062130  259.613938   0.0  909.1  941.7  969.5  1050.0\n",
       "smax  3206856.0  871.009694  260.134167   0.0  909.3  942.0  969.7  1049.1\n",
       "smin  3206856.0  870.524392  259.991361   0.0  908.8  941.4  969.2  1048.1\n",
       "temp  3206856.0   22.195866    7.324802  -2.8   20.2   23.0   26.3    44.9\n",
       "tmax  3206841.0   17.297762    5.658299 -10.0   16.6   18.7   20.5    42.0\n",
       "tmin  3206856.0   22.799069    7.576136   0.0   20.7   23.6   27.2    45.0\n",
       "dewp  3206840.0   17.823554    5.776646 -10.0   17.2   19.3   21.0    44.8\n",
       "dmax  3206856.0   21.616621    7.095030  -6.9   19.8   22.5   25.5    45.0\n",
       "dmin  3206837.0   16.782890    5.583865 -10.0   16.0   18.2   20.0    44.9\n",
       "hmdy  3206856.0   70.058209   26.138010   0.0   59.0   78.0   90.0   100.0\n",
       "hmax  3206856.0   72.838245   26.016667   0.0   63.0   82.0   92.0   100.0\n",
       "hmin  3206828.0   67.099326   26.188570   0.0   54.0   74.0   88.0   100.0\n",
       "wdsp  3206856.0    1.748157    1.584757   0.0    0.4    1.5    2.6    19.8\n",
       "wdct  3206856.0  138.789374  109.824019   0.0   50.0  110.0  226.0   360.0\n",
       "gust  3206856.0    4.338622    2.988905   0.0    2.1    4.1    6.2    50.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcont.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>A temperatura será inputada pela média</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = ['temp','dewp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in MEAN:\n",
    "    df[v] = df[v].fillna(value=df[v].median())\n",
    "    dfcont[v] = dfcont[v].fillna(value=dfcont[v].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prcp</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>0.230747</td>\n",
       "      <td>1.597225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>871.062130</td>\n",
       "      <td>259.613938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>909.1</td>\n",
       "      <td>941.7</td>\n",
       "      <td>969.5</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>871.009694</td>\n",
       "      <td>260.134167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>909.3</td>\n",
       "      <td>942.0</td>\n",
       "      <td>969.7</td>\n",
       "      <td>1049.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>870.524392</td>\n",
       "      <td>259.991361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>908.8</td>\n",
       "      <td>941.4</td>\n",
       "      <td>969.2</td>\n",
       "      <td>1048.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>22.195866</td>\n",
       "      <td>7.324802</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>20.2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax</th>\n",
       "      <td>3206841.0</td>\n",
       "      <td>17.297762</td>\n",
       "      <td>5.658299</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>18.7</td>\n",
       "      <td>20.5</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>22.799069</td>\n",
       "      <td>7.576136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>23.6</td>\n",
       "      <td>27.2</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewp</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>17.823561</td>\n",
       "      <td>5.776632</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>44.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmax</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>21.616621</td>\n",
       "      <td>7.095030</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>19.8</td>\n",
       "      <td>22.5</td>\n",
       "      <td>25.5</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmin</th>\n",
       "      <td>3206837.0</td>\n",
       "      <td>16.782890</td>\n",
       "      <td>5.583865</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>70.058209</td>\n",
       "      <td>26.138010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>72.838245</td>\n",
       "      <td>26.016667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin</th>\n",
       "      <td>3206828.0</td>\n",
       "      <td>67.099326</td>\n",
       "      <td>26.188570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>1.748157</td>\n",
       "      <td>1.584757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>138.789374</td>\n",
       "      <td>109.824019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>4.338622</td>\n",
       "      <td>2.988905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count        mean         std   min    25%    50%    75%     max\n",
       "prcp  3206856.0    0.230747    1.597225   0.0    0.0    0.0    0.0   100.0\n",
       "stp   3206856.0  871.062130  259.613938   0.0  909.1  941.7  969.5  1050.0\n",
       "smax  3206856.0  871.009694  260.134167   0.0  909.3  942.0  969.7  1049.1\n",
       "smin  3206856.0  870.524392  259.991361   0.0  908.8  941.4  969.2  1048.1\n",
       "temp  3206856.0   22.195866    7.324802  -2.8   20.2   23.0   26.3    44.9\n",
       "tmax  3206841.0   17.297762    5.658299 -10.0   16.6   18.7   20.5    42.0\n",
       "tmin  3206856.0   22.799069    7.576136   0.0   20.7   23.6   27.2    45.0\n",
       "dewp  3206856.0   17.823561    5.776632 -10.0   17.2   19.3   21.0    44.8\n",
       "dmax  3206856.0   21.616621    7.095030  -6.9   19.8   22.5   25.5    45.0\n",
       "dmin  3206837.0   16.782890    5.583865 -10.0   16.0   18.2   20.0    44.9\n",
       "hmdy  3206856.0   70.058209   26.138010   0.0   59.0   78.0   90.0   100.0\n",
       "hmax  3206856.0   72.838245   26.016667   0.0   63.0   82.0   92.0   100.0\n",
       "hmin  3206828.0   67.099326   26.188570   0.0   54.0   74.0   88.0   100.0\n",
       "wdsp  3206856.0    1.748157    1.584757   0.0    0.4    1.5    2.6    19.8\n",
       "wdct  3206856.0  138.789374  109.824019   0.0   50.0  110.0  226.0   360.0\n",
       "gust  3206856.0    4.338622    2.988905   0.0    2.1    4.1    6.2    50.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcont.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in ['tmax','tmin']:\n",
    "    dfcont[v] = dfcont[v].fillna(value=dfcont['temp'])\n",
    "    df[v] = df[v].fillna(value=df['temp'])\n",
    "for v in ['dmax','dmin']:\n",
    "    dfcont[v] = dfcont[v].fillna(value=dfcont['dewp'])\n",
    "    df[v] = df[v].fillna(value=df['dewp'])\n",
    "for v in ['hmax','hmin']:\n",
    "    dfcont[v] = dfcont[v].fillna(value=dfcont['hmdy'])\n",
    "    df[v] = df[v].fillna(value=df['hmdy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prcp</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>0.230747</td>\n",
       "      <td>1.597225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>871.062130</td>\n",
       "      <td>259.613938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>909.1</td>\n",
       "      <td>941.7</td>\n",
       "      <td>969.5</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>871.009694</td>\n",
       "      <td>260.134167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>909.3</td>\n",
       "      <td>942.0</td>\n",
       "      <td>969.7</td>\n",
       "      <td>1049.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>870.524392</td>\n",
       "      <td>259.991361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>908.8</td>\n",
       "      <td>941.4</td>\n",
       "      <td>969.2</td>\n",
       "      <td>1048.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>22.195866</td>\n",
       "      <td>7.324802</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>20.2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>17.297780</td>\n",
       "      <td>5.658298</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>18.7</td>\n",
       "      <td>20.5</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>22.799069</td>\n",
       "      <td>7.576136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>23.6</td>\n",
       "      <td>27.2</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewp</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>17.823561</td>\n",
       "      <td>5.776632</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>44.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmax</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>21.616621</td>\n",
       "      <td>7.095030</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>19.8</td>\n",
       "      <td>22.5</td>\n",
       "      <td>25.5</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmin</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>16.782836</td>\n",
       "      <td>5.583923</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>70.058209</td>\n",
       "      <td>26.138010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>72.838245</td>\n",
       "      <td>26.016667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>67.098740</td>\n",
       "      <td>26.189206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>1.748157</td>\n",
       "      <td>1.584757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>138.789374</td>\n",
       "      <td>109.824019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust</th>\n",
       "      <td>3206856.0</td>\n",
       "      <td>4.338622</td>\n",
       "      <td>2.988905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count        mean         std   min    25%    50%    75%     max\n",
       "prcp  3206856.0    0.230747    1.597225   0.0    0.0    0.0    0.0   100.0\n",
       "stp   3206856.0  871.062130  259.613938   0.0  909.1  941.7  969.5  1050.0\n",
       "smax  3206856.0  871.009694  260.134167   0.0  909.3  942.0  969.7  1049.1\n",
       "smin  3206856.0  870.524392  259.991361   0.0  908.8  941.4  969.2  1048.1\n",
       "temp  3206856.0   22.195866    7.324802  -2.8   20.2   23.0   26.3    44.9\n",
       "tmax  3206856.0   17.297780    5.658298 -10.0   16.6   18.7   20.5    42.0\n",
       "tmin  3206856.0   22.799069    7.576136   0.0   20.7   23.6   27.2    45.0\n",
       "dewp  3206856.0   17.823561    5.776632 -10.0   17.2   19.3   21.0    44.8\n",
       "dmax  3206856.0   21.616621    7.095030  -6.9   19.8   22.5   25.5    45.0\n",
       "dmin  3206856.0   16.782836    5.583923 -10.0   16.0   18.2   20.0    44.9\n",
       "hmdy  3206856.0   70.058209   26.138010   0.0   59.0   78.0   90.0   100.0\n",
       "hmax  3206856.0   72.838245   26.016667   0.0   63.0   82.0   92.0   100.0\n",
       "hmin  3206856.0   67.098740   26.189206   0.0   54.0   74.0   88.0   100.0\n",
       "wdsp  3206856.0    1.748157    1.584757   0.0    0.4    1.5    2.6    19.8\n",
       "wdct  3206856.0  138.789374  109.824019   0.0   50.0  110.0  226.0   360.0\n",
       "gust  3206856.0    4.338622    2.988905   0.0    2.1    4.1    6.2    50.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcont.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Derivando novas variáveis</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>O objetivo é derivar cada variável climática contínua em uma nova variável t-1, t-2, t-3... t-n, onde n é o numeros de horas antes do momento t. Vamos primeiramente derivá-las para depois verificar quais quando massivamente as variávies estão zeradas, o que pode indicar que a estação falhou.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Utilizando um exemplo especifico de uma estação, depois verificamos o conjunto maior</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3206856"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wsid</th>\n",
       "      <th>wsnm</th>\n",
       "      <th>elvt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>inme</th>\n",
       "      <th>city</th>\n",
       "      <th>prov</th>\n",
       "      <th>mdct</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>tmin</th>\n",
       "      <th>dewp</th>\n",
       "      <th>dmax</th>\n",
       "      <th>dmin</th>\n",
       "      <th>hmdy</th>\n",
       "      <th>hmax</th>\n",
       "      <th>hmin</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>wdct</th>\n",
       "      <th>gust</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdct</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-12-01 00:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>SÃO GONÇALO</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>A333</td>\n",
       "      <td>São Gonçalo</td>\n",
       "      <td>RJ</td>\n",
       "      <td>2007-12-01 00:00:00</td>\n",
       "      <td>2007-12-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 01:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>SÃO GONÇALO</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>A333</td>\n",
       "      <td>São Gonçalo</td>\n",
       "      <td>RJ</td>\n",
       "      <td>2007-12-01 01:00:00</td>\n",
       "      <td>2007-12-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 02:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>SÃO GONÇALO</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>A333</td>\n",
       "      <td>São Gonçalo</td>\n",
       "      <td>RJ</td>\n",
       "      <td>2007-12-01 02:00:00</td>\n",
       "      <td>2007-12-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 03:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>SÃO GONÇALO</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>A333</td>\n",
       "      <td>São Gonçalo</td>\n",
       "      <td>RJ</td>\n",
       "      <td>2007-12-01 03:00:00</td>\n",
       "      <td>2007-12-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     wsid         wsnm   elvt       lat        lon  inme  \\\n",
       "mdct                                                                       \n",
       "2007-12-01 00:00:00   178  SÃO GONÇALO  237.0 -6.835777 -38.311583  A333   \n",
       "2007-12-01 01:00:00   178  SÃO GONÇALO  237.0 -6.835777 -38.311583  A333   \n",
       "2007-12-01 02:00:00   178  SÃO GONÇALO  237.0 -6.835777 -38.311583  A333   \n",
       "2007-12-01 03:00:00   178  SÃO GONÇALO  237.0 -6.835777 -38.311583  A333   \n",
       "\n",
       "                            city prov                 mdct        date  ...   \\\n",
       "mdct                                                                    ...    \n",
       "2007-12-01 00:00:00  São Gonçalo   RJ  2007-12-01 00:00:00  2007-12-01  ...    \n",
       "2007-12-01 01:00:00  São Gonçalo   RJ  2007-12-01 01:00:00  2007-12-01  ...    \n",
       "2007-12-01 02:00:00  São Gonçalo   RJ  2007-12-01 02:00:00  2007-12-01  ...    \n",
       "2007-12-01 03:00:00  São Gonçalo   RJ  2007-12-01 03:00:00  2007-12-01  ...    \n",
       "\n",
       "                     tmin  dewp  dmax  dmin  hmdy  hmax  hmin  wdsp  wdct  \\\n",
       "mdct                                                                        \n",
       "2007-12-01 00:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2007-12-01 01:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2007-12-01 02:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2007-12-01 03:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "                     gust  \n",
       "mdct                       \n",
       "2007-12-01 00:00:00   0.0  \n",
       "2007-12-01 01:00:00   0.0  \n",
       "2007-12-01 02:00:00   0.0  \n",
       "2007-12-01 03:00:00   0.0  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.index = pd.to_datetime(dfm.mdct)\n",
    "dfm.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wsid</th>\n",
       "      <th>elvt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>prcp</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>dewp</th>\n",
       "      <th>dmax</th>\n",
       "      <th>dmin</th>\n",
       "      <th>hmdy</th>\n",
       "      <th>hmax</th>\n",
       "      <th>hmin</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>wdct</th>\n",
       "      <th>gust</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdct</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-12-01 00:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 01:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 02:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 03:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 04:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     wsid   elvt       lat        lon  prcp  stp  smax  smin  \\\n",
       "mdct                                                                           \n",
       "2007-12-01 00:00:00   178  237.0 -6.835777 -38.311583   0.0  0.0   0.0   0.0   \n",
       "2007-12-01 01:00:00   178  237.0 -6.835777 -38.311583   0.0  0.0   0.0   0.0   \n",
       "2007-12-01 02:00:00   178  237.0 -6.835777 -38.311583   0.0  0.0   0.0   0.0   \n",
       "2007-12-01 03:00:00   178  237.0 -6.835777 -38.311583   0.0  0.0   0.0   0.0   \n",
       "2007-12-01 04:00:00   178  237.0 -6.835777 -38.311583   0.0  0.0   0.0   0.0   \n",
       "\n",
       "                     temp  tmax  tmin  dewp  dmax  dmin  hmdy  hmax  hmin  \\\n",
       "mdct                                                                        \n",
       "2007-12-01 00:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2007-12-01 01:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2007-12-01 02:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2007-12-01 03:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2007-12-01 04:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "                     wdsp  wdct  gust  \n",
       "mdct                                   \n",
       "2007-12-01 00:00:00   0.0   0.0   0.0  \n",
       "2007-12-01 01:00:00   0.0   0.0   0.0  \n",
       "2007-12-01 02:00:00   0.0   0.0   0.0  \n",
       "2007-12-01 03:00:00   0.0   0.0   0.0  \n",
       "2007-12-01 04:00:00   0.0   0.0   0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLEAN = ['wsnm','inme','city','prov','mdct','date']\n",
    "REMOVE = ['yr', 'mo', 'da', 'hr']\n",
    "#REMOVE = ['wsid','yr', 'mo', 'da', 'hr']\n",
    "for v in CLEAN + REMOVE:\n",
    "    dfm = dfm.drop(v,1)\n",
    "dfm.head(5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[178, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423]\n"
     ]
    }
   ],
   "source": [
    "ws = dfm['wsid'].groupby(dfm['wsid']).count()\n",
    "ws = list(ws.keys())\n",
    "print ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfm = dfm[dfm['wsid'].isin([178, 329])]\n",
    "#len(dfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_derived_by_shift(df,lag=0,NON_DER=[]):\n",
    "    df = df.copy()\n",
    "    \n",
    "    if not lag:\n",
    "        return df\n",
    "    \n",
    "    cols ={}\n",
    "    for i in range(1,lag+1):\n",
    "        for x in list(df.columns):\n",
    "            if x not in NON_DER:\n",
    "                if not x in cols:\n",
    "                    cols[x] = ['{}_{}'.format(x, i)]\n",
    "                else:\n",
    "                    cols[x].append('{}_{}'.format(x, i))\n",
    "  \n",
    "    for k,v in cols.items():\n",
    "        columns = v\n",
    "        dfn = pd.DataFrame(data=None, columns=columns, index=df.index)    \n",
    "        i = 1\n",
    "        for c in columns:\n",
    "            dfn[c] = df[k].shift(periods=i)\n",
    "            i+=1\n",
    "        df = pd.concat([df, dfn], axis=1, join_axes=[df.index])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_DER = ['wsid','elvt','lat', 'lon', 'yr', 'mo', 'da', 'hr']\n",
    "\n",
    "dfr = df_derived_by_shift(dfm,3,NON_DER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr.head(4)\n",
    "\n",
    "var = []\n",
    "cld = list(dfr.columns)\n",
    "for x in cld:\n",
    "    if len(x.split('_')) >= 2:\n",
    "        var.append((x.split('_')[0], x.split('_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wsid</th>\n",
       "      <th>elvt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>prcp</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>...</th>\n",
       "      <th>smin_3</th>\n",
       "      <th>dmin_1</th>\n",
       "      <th>dmin_2</th>\n",
       "      <th>dmin_3</th>\n",
       "      <th>dmax_1</th>\n",
       "      <th>dmax_2</th>\n",
       "      <th>dmax_3</th>\n",
       "      <th>prcp_1</th>\n",
       "      <th>prcp_2</th>\n",
       "      <th>prcp_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdct</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-12-01 00:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 01:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 02:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 03:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 04:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 05:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 06:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 07:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 08:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 09:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 10:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>986.3</td>\n",
       "      <td>986.3</td>\n",
       "      <td>985.7</td>\n",
       "      <td>25.4</td>\n",
       "      <td>17.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 11:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>986.3</td>\n",
       "      <td>986.4</td>\n",
       "      <td>986.2</td>\n",
       "      <td>26.6</td>\n",
       "      <td>17.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 12:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>986.3</td>\n",
       "      <td>986.0</td>\n",
       "      <td>28.6</td>\n",
       "      <td>15.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.1</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 13:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>985.3</td>\n",
       "      <td>986.0</td>\n",
       "      <td>985.3</td>\n",
       "      <td>30.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>...</td>\n",
       "      <td>985.7</td>\n",
       "      <td>15.6</td>\n",
       "      <td>16.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>26.2</td>\n",
       "      <td>25.1</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 14:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>984.5</td>\n",
       "      <td>985.3</td>\n",
       "      <td>984.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.8</td>\n",
       "      <td>...</td>\n",
       "      <td>986.2</td>\n",
       "      <td>14.7</td>\n",
       "      <td>15.6</td>\n",
       "      <td>16.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>26.2</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 15:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>983.6</td>\n",
       "      <td>984.5</td>\n",
       "      <td>983.6</td>\n",
       "      <td>32.3</td>\n",
       "      <td>12.4</td>\n",
       "      <td>...</td>\n",
       "      <td>986.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>14.7</td>\n",
       "      <td>15.6</td>\n",
       "      <td>29.9</td>\n",
       "      <td>28.4</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 16:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>982.6</td>\n",
       "      <td>983.6</td>\n",
       "      <td>982.6</td>\n",
       "      <td>33.2</td>\n",
       "      <td>12.2</td>\n",
       "      <td>...</td>\n",
       "      <td>985.3</td>\n",
       "      <td>12.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>14.7</td>\n",
       "      <td>31.1</td>\n",
       "      <td>29.9</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 17:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>981.7</td>\n",
       "      <td>982.6</td>\n",
       "      <td>981.7</td>\n",
       "      <td>34.4</td>\n",
       "      <td>13.2</td>\n",
       "      <td>...</td>\n",
       "      <td>984.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>12.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.1</td>\n",
       "      <td>29.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 18:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>981.3</td>\n",
       "      <td>981.7</td>\n",
       "      <td>981.3</td>\n",
       "      <td>34.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>...</td>\n",
       "      <td>983.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>11.5</td>\n",
       "      <td>12.1</td>\n",
       "      <td>33.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 19:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>981.0</td>\n",
       "      <td>981.3</td>\n",
       "      <td>981.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>...</td>\n",
       "      <td>982.6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>11.3</td>\n",
       "      <td>11.5</td>\n",
       "      <td>34.2</td>\n",
       "      <td>33.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 20:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>981.0</td>\n",
       "      <td>981.0</td>\n",
       "      <td>980.9</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>...</td>\n",
       "      <td>981.7</td>\n",
       "      <td>10.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>11.3</td>\n",
       "      <td>34.6</td>\n",
       "      <td>34.2</td>\n",
       "      <td>33.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 21:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>981.5</td>\n",
       "      <td>981.5</td>\n",
       "      <td>981.0</td>\n",
       "      <td>26.1</td>\n",
       "      <td>19.2</td>\n",
       "      <td>...</td>\n",
       "      <td>981.3</td>\n",
       "      <td>10.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>34.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 22:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>982.1</td>\n",
       "      <td>982.1</td>\n",
       "      <td>981.5</td>\n",
       "      <td>24.3</td>\n",
       "      <td>19.3</td>\n",
       "      <td>...</td>\n",
       "      <td>981.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>10.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>26.1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-01 23:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>980.9</td>\n",
       "      <td>18.5</td>\n",
       "      <td>15.9</td>\n",
       "      <td>10.4</td>\n",
       "      <td>24.3</td>\n",
       "      <td>26.1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-02 00:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>981.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-02 01:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>981.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-02 02:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-02 03:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-02 04:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-02 05:00:00</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30 18:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>929.3</td>\n",
       "      <td>929.4</td>\n",
       "      <td>929.2</td>\n",
       "      <td>26.5</td>\n",
       "      <td>20.1</td>\n",
       "      <td>...</td>\n",
       "      <td>930.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>13.6</td>\n",
       "      <td>28.6</td>\n",
       "      <td>29.6</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30 19:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.8</td>\n",
       "      <td>930.2</td>\n",
       "      <td>930.4</td>\n",
       "      <td>929.2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>...</td>\n",
       "      <td>930.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>26.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30 20:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.2</td>\n",
       "      <td>930.8</td>\n",
       "      <td>931.0</td>\n",
       "      <td>930.2</td>\n",
       "      <td>22.5</td>\n",
       "      <td>20.5</td>\n",
       "      <td>...</td>\n",
       "      <td>929.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30 21:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>931.4</td>\n",
       "      <td>931.4</td>\n",
       "      <td>930.7</td>\n",
       "      <td>22.1</td>\n",
       "      <td>20.1</td>\n",
       "      <td>...</td>\n",
       "      <td>929.2</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30 22:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>931.6</td>\n",
       "      <td>931.9</td>\n",
       "      <td>931.3</td>\n",
       "      <td>22.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>929.2</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30 23:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>931.1</td>\n",
       "      <td>931.6</td>\n",
       "      <td>931.1</td>\n",
       "      <td>21.9</td>\n",
       "      <td>19.9</td>\n",
       "      <td>...</td>\n",
       "      <td>930.2</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 00:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>931.8</td>\n",
       "      <td>931.9</td>\n",
       "      <td>931.1</td>\n",
       "      <td>22.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>...</td>\n",
       "      <td>930.7</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.1</td>\n",
       "      <td>21.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 01:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.7</td>\n",
       "      <td>932.7</td>\n",
       "      <td>931.7</td>\n",
       "      <td>22.3</td>\n",
       "      <td>19.8</td>\n",
       "      <td>...</td>\n",
       "      <td>931.3</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 02:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.8</td>\n",
       "      <td>933.2</td>\n",
       "      <td>932.3</td>\n",
       "      <td>21.6</td>\n",
       "      <td>17.6</td>\n",
       "      <td>...</td>\n",
       "      <td>931.1</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>22.3</td>\n",
       "      <td>21.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 03:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.6</td>\n",
       "      <td>932.0</td>\n",
       "      <td>932.8</td>\n",
       "      <td>931.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>...</td>\n",
       "      <td>931.1</td>\n",
       "      <td>17.6</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.5</td>\n",
       "      <td>22.3</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 04:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>931.7</td>\n",
       "      <td>932.2</td>\n",
       "      <td>931.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>17.1</td>\n",
       "      <td>...</td>\n",
       "      <td>931.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>17.6</td>\n",
       "      <td>19.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 05:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>930.7</td>\n",
       "      <td>931.7</td>\n",
       "      <td>930.7</td>\n",
       "      <td>19.7</td>\n",
       "      <td>17.8</td>\n",
       "      <td>...</td>\n",
       "      <td>932.3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>17.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 06:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>930.5</td>\n",
       "      <td>930.7</td>\n",
       "      <td>930.1</td>\n",
       "      <td>19.3</td>\n",
       "      <td>17.4</td>\n",
       "      <td>...</td>\n",
       "      <td>931.9</td>\n",
       "      <td>17.1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 07:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>930.3</td>\n",
       "      <td>930.6</td>\n",
       "      <td>930.3</td>\n",
       "      <td>19.7</td>\n",
       "      <td>18.4</td>\n",
       "      <td>...</td>\n",
       "      <td>931.7</td>\n",
       "      <td>16.8</td>\n",
       "      <td>17.1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 08:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>930.7</td>\n",
       "      <td>930.7</td>\n",
       "      <td>930.2</td>\n",
       "      <td>18.9</td>\n",
       "      <td>17.6</td>\n",
       "      <td>...</td>\n",
       "      <td>930.7</td>\n",
       "      <td>17.1</td>\n",
       "      <td>16.8</td>\n",
       "      <td>17.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 09:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>931.1</td>\n",
       "      <td>931.2</td>\n",
       "      <td>930.7</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>930.1</td>\n",
       "      <td>17.4</td>\n",
       "      <td>17.1</td>\n",
       "      <td>16.8</td>\n",
       "      <td>18.7</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 10:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>931.9</td>\n",
       "      <td>931.9</td>\n",
       "      <td>931.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>18.7</td>\n",
       "      <td>...</td>\n",
       "      <td>930.3</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>17.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.7</td>\n",
       "      <td>18.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 11:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.2</td>\n",
       "      <td>932.2</td>\n",
       "      <td>931.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>...</td>\n",
       "      <td>930.2</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 12:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.4</td>\n",
       "      <td>932.4</td>\n",
       "      <td>932.2</td>\n",
       "      <td>23.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>...</td>\n",
       "      <td>930.7</td>\n",
       "      <td>18.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.5</td>\n",
       "      <td>19.7</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 13:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.3</td>\n",
       "      <td>932.4</td>\n",
       "      <td>932.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>...</td>\n",
       "      <td>931.1</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>21.7</td>\n",
       "      <td>19.7</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 14:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>931.8</td>\n",
       "      <td>932.3</td>\n",
       "      <td>931.8</td>\n",
       "      <td>27.8</td>\n",
       "      <td>18.6</td>\n",
       "      <td>...</td>\n",
       "      <td>931.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>23.5</td>\n",
       "      <td>21.7</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 15:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>931.3</td>\n",
       "      <td>931.8</td>\n",
       "      <td>931.3</td>\n",
       "      <td>29.3</td>\n",
       "      <td>16.8</td>\n",
       "      <td>...</td>\n",
       "      <td>932.2</td>\n",
       "      <td>18.5</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.1</td>\n",
       "      <td>25.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 16:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>930.4</td>\n",
       "      <td>931.3</td>\n",
       "      <td>930.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>...</td>\n",
       "      <td>932.2</td>\n",
       "      <td>16.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>18.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>25.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 17:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>929.3</td>\n",
       "      <td>930.4</td>\n",
       "      <td>929.3</td>\n",
       "      <td>31.6</td>\n",
       "      <td>17.8</td>\n",
       "      <td>...</td>\n",
       "      <td>931.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>29.2</td>\n",
       "      <td>27.8</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 18:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>928.6</td>\n",
       "      <td>929.3</td>\n",
       "      <td>928.6</td>\n",
       "      <td>30.6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>931.3</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>29.8</td>\n",
       "      <td>29.2</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 19:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>929.2</td>\n",
       "      <td>929.4</td>\n",
       "      <td>928.5</td>\n",
       "      <td>26.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>...</td>\n",
       "      <td>930.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.6</td>\n",
       "      <td>29.8</td>\n",
       "      <td>29.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 20:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>0.4</td>\n",
       "      <td>930.2</td>\n",
       "      <td>930.2</td>\n",
       "      <td>929.2</td>\n",
       "      <td>23.6</td>\n",
       "      <td>19.5</td>\n",
       "      <td>...</td>\n",
       "      <td>929.3</td>\n",
       "      <td>16.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>14.5</td>\n",
       "      <td>26.7</td>\n",
       "      <td>30.6</td>\n",
       "      <td>29.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 21:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>4.4</td>\n",
       "      <td>930.6</td>\n",
       "      <td>930.7</td>\n",
       "      <td>929.8</td>\n",
       "      <td>18.9</td>\n",
       "      <td>17.3</td>\n",
       "      <td>...</td>\n",
       "      <td>928.6</td>\n",
       "      <td>16.1</td>\n",
       "      <td>16.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>23.6</td>\n",
       "      <td>26.7</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 22:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>2.4</td>\n",
       "      <td>930.7</td>\n",
       "      <td>931.1</td>\n",
       "      <td>930.5</td>\n",
       "      <td>20.4</td>\n",
       "      <td>18.8</td>\n",
       "      <td>...</td>\n",
       "      <td>928.5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>16.4</td>\n",
       "      <td>18.7</td>\n",
       "      <td>23.6</td>\n",
       "      <td>26.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31 23:00:00</th>\n",
       "      <td>423</td>\n",
       "      <td>777.0</td>\n",
       "      <td>-23.523890</td>\n",
       "      <td>-46.869450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>930.5</td>\n",
       "      <td>930.7</td>\n",
       "      <td>930.4</td>\n",
       "      <td>20.8</td>\n",
       "      <td>19.2</td>\n",
       "      <td>...</td>\n",
       "      <td>929.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.7</td>\n",
       "      <td>23.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3206856 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     wsid   elvt        lat        lon  prcp    stp   smax  \\\n",
       "mdct                                                                         \n",
       "2007-12-01 00:00:00   178  237.0  -6.835777 -38.311583   0.0    0.0    0.0   \n",
       "2007-12-01 01:00:00   178  237.0  -6.835777 -38.311583   0.0    0.0    0.0   \n",
       "2007-12-01 02:00:00   178  237.0  -6.835777 -38.311583   0.0    0.0    0.0   \n",
       "2007-12-01 03:00:00   178  237.0  -6.835777 -38.311583   0.0    0.0    0.0   \n",
       "2007-12-01 04:00:00   178  237.0  -6.835777 -38.311583   0.0    0.0    0.0   \n",
       "2007-12-01 05:00:00   178  237.0  -6.835777 -38.311583   0.0    0.0    0.0   \n",
       "2007-12-01 06:00:00   178  237.0  -6.835777 -38.311583   0.0    0.0    0.0   \n",
       "2007-12-01 07:00:00   178  237.0  -6.835777 -38.311583   0.0    0.0    0.0   \n",
       "2007-12-01 08:00:00   178  237.0  -6.835777 -38.311583   0.0    0.0    0.0   \n",
       "2007-12-01 09:00:00   178  237.0  -6.835777 -38.311583   0.0    0.0    0.0   \n",
       "2007-12-01 10:00:00   178  237.0  -6.835777 -38.311583   0.0  986.3  986.3   \n",
       "2007-12-01 11:00:00   178  237.0  -6.835777 -38.311583   0.0  986.3  986.4   \n",
       "2007-12-01 12:00:00   178  237.0  -6.835777 -38.311583   0.0  986.0  986.3   \n",
       "2007-12-01 13:00:00   178  237.0  -6.835777 -38.311583   0.0  985.3  986.0   \n",
       "2007-12-01 14:00:00   178  237.0  -6.835777 -38.311583   0.0  984.5  985.3   \n",
       "2007-12-01 15:00:00   178  237.0  -6.835777 -38.311583   0.0  983.6  984.5   \n",
       "2007-12-01 16:00:00   178  237.0  -6.835777 -38.311583   0.0  982.6  983.6   \n",
       "2007-12-01 17:00:00   178  237.0  -6.835777 -38.311583   0.0  981.7  982.6   \n",
       "2007-12-01 18:00:00   178  237.0  -6.835777 -38.311583   0.0  981.3  981.7   \n",
       "2007-12-01 19:00:00   178  237.0  -6.835777 -38.311583   0.0  981.0  981.3   \n",
       "2007-12-01 20:00:00   178  237.0  -6.835777 -38.311583   0.0  981.0  981.0   \n",
       "2007-12-01 21:00:00   178  237.0  -6.835777 -38.311583   0.0  981.5  981.5   \n",
       "2007-12-01 22:00:00   178  237.0  -6.835777 -38.311583   0.0  982.1  982.1   \n",
       "2007-12-01 23:00:00   178  237.0  -6.835777 -38.311583   0.0    0.0    0.0   \n",
       "2007-12-02 00:00:00   178  237.0  -6.835777 -38.311583   0.0    0.0    0.0   \n",
       "2007-12-02 01:00:00   178  237.0  -6.835777 -38.311583   0.0    0.0    0.0   \n",
       "2007-12-02 02:00:00   178  237.0  -6.835777 -38.311583   0.0    0.0    0.0   \n",
       "2007-12-02 03:00:00   178  237.0  -6.835777 -38.311583   0.0    0.0    0.0   \n",
       "2007-12-02 04:00:00   178  237.0  -6.835777 -38.311583   0.0    0.0    0.0   \n",
       "2007-12-02 05:00:00   178  237.0  -6.835777 -38.311583   0.0    0.0    0.0   \n",
       "...                   ...    ...        ...        ...   ...    ...    ...   \n",
       "2016-03-30 18:00:00   423  777.0 -23.523890 -46.869450   0.0  929.3  929.4   \n",
       "2016-03-30 19:00:00   423  777.0 -23.523890 -46.869450   0.8  930.2  930.4   \n",
       "2016-03-30 20:00:00   423  777.0 -23.523890 -46.869450   0.2  930.8  931.0   \n",
       "2016-03-30 21:00:00   423  777.0 -23.523890 -46.869450   0.0  931.4  931.4   \n",
       "2016-03-30 22:00:00   423  777.0 -23.523890 -46.869450   0.0  931.6  931.9   \n",
       "2016-03-30 23:00:00   423  777.0 -23.523890 -46.869450   0.0  931.1  931.6   \n",
       "2016-03-31 00:00:00   423  777.0 -23.523890 -46.869450   0.0  931.8  931.9   \n",
       "2016-03-31 01:00:00   423  777.0 -23.523890 -46.869450   0.0  932.7  932.7   \n",
       "2016-03-31 02:00:00   423  777.0 -23.523890 -46.869450   0.0  932.8  933.2   \n",
       "2016-03-31 03:00:00   423  777.0 -23.523890 -46.869450   0.6  932.0  932.8   \n",
       "2016-03-31 04:00:00   423  777.0 -23.523890 -46.869450   0.0  931.7  932.2   \n",
       "2016-03-31 05:00:00   423  777.0 -23.523890 -46.869450   0.0  930.7  931.7   \n",
       "2016-03-31 06:00:00   423  777.0 -23.523890 -46.869450   0.0  930.5  930.7   \n",
       "2016-03-31 07:00:00   423  777.0 -23.523890 -46.869450   0.0  930.3  930.6   \n",
       "2016-03-31 08:00:00   423  777.0 -23.523890 -46.869450   0.0  930.7  930.7   \n",
       "2016-03-31 09:00:00   423  777.0 -23.523890 -46.869450   0.0  931.1  931.2   \n",
       "2016-03-31 10:00:00   423  777.0 -23.523890 -46.869450   0.0  931.9  931.9   \n",
       "2016-03-31 11:00:00   423  777.0 -23.523890 -46.869450   0.0  932.2  932.2   \n",
       "2016-03-31 12:00:00   423  777.0 -23.523890 -46.869450   0.0  932.4  932.4   \n",
       "2016-03-31 13:00:00   423  777.0 -23.523890 -46.869450   0.0  932.3  932.4   \n",
       "2016-03-31 14:00:00   423  777.0 -23.523890 -46.869450   0.0  931.8  932.3   \n",
       "2016-03-31 15:00:00   423  777.0 -23.523890 -46.869450   0.0  931.3  931.8   \n",
       "2016-03-31 16:00:00   423  777.0 -23.523890 -46.869450   0.0  930.4  931.3   \n",
       "2016-03-31 17:00:00   423  777.0 -23.523890 -46.869450   0.0  929.3  930.4   \n",
       "2016-03-31 18:00:00   423  777.0 -23.523890 -46.869450   0.0  928.6  929.3   \n",
       "2016-03-31 19:00:00   423  777.0 -23.523890 -46.869450   0.0  929.2  929.4   \n",
       "2016-03-31 20:00:00   423  777.0 -23.523890 -46.869450   0.4  930.2  930.2   \n",
       "2016-03-31 21:00:00   423  777.0 -23.523890 -46.869450   4.4  930.6  930.7   \n",
       "2016-03-31 22:00:00   423  777.0 -23.523890 -46.869450   2.4  930.7  931.1   \n",
       "2016-03-31 23:00:00   423  777.0 -23.523890 -46.869450   1.0  930.5  930.7   \n",
       "\n",
       "                      smin  temp  tmax   ...    smin_3  dmin_1  dmin_2  \\\n",
       "mdct                                     ...                             \n",
       "2007-12-01 00:00:00    0.0   0.0   0.0   ...       NaN     NaN     NaN   \n",
       "2007-12-01 01:00:00    0.0   0.0   0.0   ...       NaN     0.0     NaN   \n",
       "2007-12-01 02:00:00    0.0   0.0   0.0   ...       NaN     0.0     0.0   \n",
       "2007-12-01 03:00:00    0.0   0.0   0.0   ...       0.0     0.0     0.0   \n",
       "2007-12-01 04:00:00    0.0   0.0   0.0   ...       0.0     0.0     0.0   \n",
       "2007-12-01 05:00:00    0.0   0.0   0.0   ...       0.0     0.0     0.0   \n",
       "2007-12-01 06:00:00    0.0   0.0   0.0   ...       0.0     0.0     0.0   \n",
       "2007-12-01 07:00:00    0.0   0.0   0.0   ...       0.0     0.0     0.0   \n",
       "2007-12-01 08:00:00    0.0   0.0   0.0   ...       0.0     0.0     0.0   \n",
       "2007-12-01 09:00:00    0.0   0.0   0.0   ...       0.0     0.0     0.0   \n",
       "2007-12-01 10:00:00  985.7  25.4  17.5   ...       0.0     0.0     0.0   \n",
       "2007-12-01 11:00:00  986.2  26.6  17.1   ...       0.0    17.4     0.0   \n",
       "2007-12-01 12:00:00  986.0  28.6  15.6   ...       0.0    16.8    17.4   \n",
       "2007-12-01 13:00:00  985.3  30.1  15.4   ...     985.7    15.6    16.8   \n",
       "2007-12-01 14:00:00  984.5  31.1  12.8   ...     986.2    14.7    15.6   \n",
       "2007-12-01 15:00:00  983.6  32.3  12.4   ...     986.0    12.6    14.7   \n",
       "2007-12-01 16:00:00  982.6  33.2  12.2   ...     985.3    12.1    12.6   \n",
       "2007-12-01 17:00:00  981.7  34.4  13.2   ...     984.5    11.5    12.1   \n",
       "2007-12-01 18:00:00  981.3  34.8  11.2   ...     983.6    11.3    11.5   \n",
       "2007-12-01 19:00:00  981.0  35.0  12.2   ...     982.6    11.2    11.3   \n",
       "2007-12-01 20:00:00  980.9  33.0  16.7   ...     981.7    10.8    11.2   \n",
       "2007-12-01 21:00:00  981.0  26.1  19.2   ...     981.3    10.4    10.8   \n",
       "2007-12-01 22:00:00  981.5  24.3  19.3   ...     981.0    15.9    10.4   \n",
       "2007-12-01 23:00:00    0.0   0.0   0.0   ...     980.9    18.5    15.9   \n",
       "2007-12-02 00:00:00    0.0   0.0   0.0   ...     981.0     0.0    18.5   \n",
       "2007-12-02 01:00:00    0.0   0.0   0.0   ...     981.5     0.0     0.0   \n",
       "2007-12-02 02:00:00    0.0   0.0   0.0   ...       0.0     0.0     0.0   \n",
       "2007-12-02 03:00:00    0.0   0.0   0.0   ...       0.0     0.0     0.0   \n",
       "2007-12-02 04:00:00    0.0   0.0   0.0   ...       0.0     0.0     0.0   \n",
       "2007-12-02 05:00:00    0.0   0.0   0.0   ...       0.0     0.0     0.0   \n",
       "...                    ...   ...   ...   ...       ...     ...     ...   \n",
       "2016-03-30 18:00:00  929.2  26.5  20.1   ...     930.7    15.0    15.2   \n",
       "2016-03-30 19:00:00  929.2  23.0  20.7   ...     930.0    19.0    15.0   \n",
       "2016-03-30 20:00:00  930.2  22.5  20.5   ...     929.4    19.9    19.0   \n",
       "2016-03-30 21:00:00  930.7  22.1  20.1   ...     929.2    20.4    19.9   \n",
       "2016-03-30 22:00:00  931.3  22.1  20.0   ...     929.2    20.1    20.4   \n",
       "2016-03-30 23:00:00  931.1  21.9  19.9   ...     930.2    19.9    20.1   \n",
       "2016-03-31 00:00:00  931.1  22.5  19.5   ...     930.7    19.7    19.9   \n",
       "2016-03-31 01:00:00  931.7  22.3  19.8   ...     931.3    19.4    19.7   \n",
       "2016-03-31 02:00:00  932.3  21.6  17.6   ...     931.1    19.5    19.4   \n",
       "2016-03-31 03:00:00  931.9  20.0  17.7   ...     931.1    17.6    19.5   \n",
       "2016-03-31 04:00:00  931.7  19.3  17.1   ...     931.7    15.5    17.6   \n",
       "2016-03-31 05:00:00  930.7  19.7  17.8   ...     932.3    17.0    15.5   \n",
       "2016-03-31 06:00:00  930.1  19.3  17.4   ...     931.9    17.1    17.0   \n",
       "2016-03-31 07:00:00  930.3  19.7  18.4   ...     931.7    16.8    17.1   \n",
       "2016-03-31 08:00:00  930.2  18.9  17.6   ...     930.7    17.1    16.8   \n",
       "2016-03-31 09:00:00  930.7  19.1  18.0   ...     930.1    17.4    17.1   \n",
       "2016-03-31 10:00:00  931.1  19.8  18.7   ...     930.3    17.5    17.4   \n",
       "2016-03-31 11:00:00  931.9  21.8  20.6   ...     930.2    17.7    17.5   \n",
       "2016-03-31 12:00:00  932.2  23.6  19.3   ...     930.7    18.7    17.7   \n",
       "2016-03-31 13:00:00  932.2  26.0  19.3   ...     931.1    19.1    18.7   \n",
       "2016-03-31 14:00:00  931.8  27.8  18.6   ...     931.9    18.9    19.1   \n",
       "2016-03-31 15:00:00  931.3  29.3  16.8   ...     932.2    18.5    18.9   \n",
       "2016-03-31 16:00:00  930.4  30.0  15.7   ...     932.2    16.5    18.5   \n",
       "2016-03-31 17:00:00  929.3  31.6  17.8   ...     931.8    15.0    16.5   \n",
       "2016-03-31 18:00:00  928.6  30.6  15.0   ...     931.3    14.5    15.0   \n",
       "2016-03-31 19:00:00  928.5  26.7  19.8   ...     930.4    13.7    14.5   \n",
       "2016-03-31 20:00:00  929.2  23.6  19.5   ...     929.3    16.4    13.7   \n",
       "2016-03-31 21:00:00  929.8  18.9  17.3   ...     928.6    16.1    16.4   \n",
       "2016-03-31 22:00:00  930.5  20.4  18.8   ...     928.5    17.0    16.1   \n",
       "2016-03-31 23:00:00  930.4  20.8  19.2   ...     929.2    17.3    17.0   \n",
       "\n",
       "                     dmin_3  dmax_1  dmax_2  dmax_3  prcp_1  prcp_2  prcp_3  \n",
       "mdct                                                                         \n",
       "2007-12-01 00:00:00     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "2007-12-01 01:00:00     NaN     0.0     NaN     NaN     0.0     NaN     NaN  \n",
       "2007-12-01 02:00:00     NaN     0.0     0.0     NaN     0.0     0.0     NaN  \n",
       "2007-12-01 03:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2007-12-01 04:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2007-12-01 05:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2007-12-01 06:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2007-12-01 07:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2007-12-01 08:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2007-12-01 09:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2007-12-01 10:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2007-12-01 11:00:00     0.0    24.3     0.0     0.0     0.0     0.0     0.0  \n",
       "2007-12-01 12:00:00     0.0    25.1    24.3     0.0     0.0     0.0     0.0  \n",
       "2007-12-01 13:00:00    17.4    26.2    25.1    24.3     0.0     0.0     0.0  \n",
       "2007-12-01 14:00:00    16.8    28.4    26.2    25.1     0.0     0.0     0.0  \n",
       "2007-12-01 15:00:00    15.6    29.9    28.4    26.2     0.0     0.0     0.0  \n",
       "2007-12-01 16:00:00    14.7    31.1    29.9    28.4     0.0     0.0     0.0  \n",
       "2007-12-01 17:00:00    12.6    32.0    31.1    29.9     0.0     0.0     0.0  \n",
       "2007-12-01 18:00:00    12.1    33.2    32.0    31.1     0.0     0.0     0.0  \n",
       "2007-12-01 19:00:00    11.5    34.2    33.2    32.0     0.0     0.0     0.0  \n",
       "2007-12-01 20:00:00    11.3    34.6    34.2    33.2     0.0     0.0     0.0  \n",
       "2007-12-01 21:00:00    11.2    33.0    34.6    34.2     0.0     0.0     0.0  \n",
       "2007-12-01 22:00:00    10.8    26.1    33.0    34.6     0.0     0.0     0.0  \n",
       "2007-12-01 23:00:00    10.4    24.3    26.1    33.0     0.0     0.0     0.0  \n",
       "2007-12-02 00:00:00    15.9     0.0    24.3    26.1     0.0     0.0     0.0  \n",
       "2007-12-02 01:00:00    18.5     0.0     0.0    24.3     0.0     0.0     0.0  \n",
       "2007-12-02 02:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2007-12-02 03:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2007-12-02 04:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2007-12-02 05:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "...                     ...     ...     ...     ...     ...     ...     ...  \n",
       "2016-03-30 18:00:00    13.6    28.6    29.6    28.6     0.0     0.0     0.0  \n",
       "2016-03-30 19:00:00    15.2    26.5    28.6    29.6     0.0     0.0     0.0  \n",
       "2016-03-30 20:00:00    15.0    23.0    26.5    28.6     0.8     0.0     0.0  \n",
       "2016-03-30 21:00:00    19.0    22.5    23.0    26.5     0.2     0.8     0.0  \n",
       "2016-03-30 22:00:00    19.9    22.0    22.5    23.0     0.0     0.2     0.8  \n",
       "2016-03-30 23:00:00    20.4    22.0    22.0    22.5     0.0     0.0     0.2  \n",
       "2016-03-31 00:00:00    20.1    21.8    22.0    22.0     0.0     0.0     0.0  \n",
       "2016-03-31 01:00:00    19.9    21.9    21.8    22.0     0.0     0.0     0.0  \n",
       "2016-03-31 02:00:00    19.7    22.3    21.9    21.8     0.0     0.0     0.0  \n",
       "2016-03-31 03:00:00    19.4    21.5    22.3    21.9     0.0     0.0     0.0  \n",
       "2016-03-31 04:00:00    19.5    20.0    21.5    22.3     0.6     0.0     0.0  \n",
       "2016-03-31 05:00:00    17.6    19.3    20.0    21.5     0.0     0.6     0.0  \n",
       "2016-03-31 06:00:00    15.5    19.3    19.3    20.0     0.0     0.0     0.6  \n",
       "2016-03-31 07:00:00    17.0    18.7    19.3    19.3     0.0     0.0     0.0  \n",
       "2016-03-31 08:00:00    17.1    18.9    18.7    19.3     0.0     0.0     0.0  \n",
       "2016-03-31 09:00:00    16.8    18.7    18.9    18.7     0.0     0.0     0.0  \n",
       "2016-03-31 10:00:00    17.1    18.8    18.7    18.9     0.0     0.0     0.0  \n",
       "2016-03-31 11:00:00    17.4    18.8    18.8    18.7     0.0     0.0     0.0  \n",
       "2016-03-31 12:00:00    17.5    19.7    18.8    18.8     0.0     0.0     0.0  \n",
       "2016-03-31 13:00:00    17.7    21.7    19.7    18.8     0.0     0.0     0.0  \n",
       "2016-03-31 14:00:00    18.7    23.5    21.7    19.7     0.0     0.0     0.0  \n",
       "2016-03-31 15:00:00    19.1    25.8    23.5    21.7     0.0     0.0     0.0  \n",
       "2016-03-31 16:00:00    18.9    27.8    25.8    23.5     0.0     0.0     0.0  \n",
       "2016-03-31 17:00:00    18.5    29.2    27.8    25.8     0.0     0.0     0.0  \n",
       "2016-03-31 18:00:00    16.5    29.8    29.2    27.8     0.0     0.0     0.0  \n",
       "2016-03-31 19:00:00    15.0    30.6    29.8    29.2     0.0     0.0     0.0  \n",
       "2016-03-31 20:00:00    14.5    26.7    30.6    29.8     0.0     0.0     0.0  \n",
       "2016-03-31 21:00:00    13.7    23.6    26.7    30.6     0.4     0.0     0.0  \n",
       "2016-03-31 22:00:00    16.4    18.7    23.6    26.7     4.4     0.4     0.0  \n",
       "2016-03-31 23:00:00    16.1    18.8    18.7    23.6     2.4     4.4     0.4  \n",
       "\n",
       "[3206856 rows x 68 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for w in ws:\n",
    "#    for col,lag in var:\n",
    "#        col_name = col + '_'+ lag\n",
    "#        for i in range(0,int(lag)):\n",
    "#            idx = dfr.loc[dfr['wsid']==w].index\n",
    "#            dfr.loc[dfr.loc[idx,col_name].index[int(i)],col_name] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = dfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels [u'prcp_4'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-fca195876383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mREMOVE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mu'prcp_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'prcp_2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'prcp_3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'prcp_4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'prcp_5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mREMOVE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dedeco/envs/tensorflow/local/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2528\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dedeco/envs/tensorflow/local/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   2560\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2563\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dedeco/envs/tensorflow/local/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3743\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3744\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3745\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3746\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels [u'prcp_4'] not contained in axis"
     ]
    }
   ],
   "source": [
    "REMOVE = [u'prcp_1', u'prcp_2', u'prcp_3', u'prcp_4', u'prcp_5']\n",
    "for v in REMOVE:\n",
    "    dfm = dfm.drop(v,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'wsid', u'elvt', u'lat', u'lon', u'prcp', u'stp', u'smax', u'smin',\n",
       "       u'temp', u'tmax', u'tmin', u'dewp', u'dmax', u'dmin', u'hmdy', u'hmax',\n",
       "       u'hmin', u'wdsp', u'wdct', u'gust', u'wdct_1', u'wdct_2', u'wdct_3',\n",
       "       u'tmin_1', u'tmin_2', u'tmin_3', u'hmax_1', u'hmax_2', u'hmax_3',\n",
       "       u'temp_1', u'temp_2', u'temp_3', u'hmin_1', u'hmin_2', u'hmin_3',\n",
       "       u'gust_1', u'gust_2', u'gust_3', u'tmax_1', u'tmax_2', u'tmax_3',\n",
       "       u'smax_1', u'smax_2', u'smax_3', u'hmdy_1', u'hmdy_2', u'hmdy_3',\n",
       "       u'dewp_1', u'dewp_2', u'dewp_3', u'wdsp_1', u'wdsp_2', u'wdsp_3',\n",
       "       u'stp_1', u'stp_2', u'stp_3', u'smin_1', u'smin_2', u'smin_3',\n",
       "       u'dmin_1', u'dmin_2', u'dmin_3', u'dmax_1', u'dmax_2', u'dmax_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = dfm.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = dfm.dropna()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wsid</th>\n",
       "      <th>elvt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>prcp</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>...</th>\n",
       "      <th>stp_3</th>\n",
       "      <th>smin_1</th>\n",
       "      <th>smin_2</th>\n",
       "      <th>smin_3</th>\n",
       "      <th>dmin_1</th>\n",
       "      <th>dmin_2</th>\n",
       "      <th>dmin_3</th>\n",
       "      <th>dmax_1</th>\n",
       "      <th>dmax_2</th>\n",
       "      <th>dmax_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wsid   elvt       lat        lon  prcp  stp  smax  smin  temp  tmax  \\\n",
       "3   178  237.0 -6.835777 -38.311583   0.0  0.0   0.0   0.0   0.0   0.0   \n",
       "4   178  237.0 -6.835777 -38.311583   0.0  0.0   0.0   0.0   0.0   0.0   \n",
       "5   178  237.0 -6.835777 -38.311583   0.0  0.0   0.0   0.0   0.0   0.0   \n",
       "6   178  237.0 -6.835777 -38.311583   0.0  0.0   0.0   0.0   0.0   0.0   \n",
       "7   178  237.0 -6.835777 -38.311583   0.0  0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "    ...    stp_3  smin_1  smin_2  smin_3  dmin_1  dmin_2  dmin_3  dmax_1  \\\n",
       "3   ...      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4   ...      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5   ...      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "6   ...      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "7   ...      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   dmax_2  dmax_3  \n",
       "3     0.0     0.0  \n",
       "4     0.0     0.0  \n",
       "5     0.0     0.0  \n",
       "6     0.0     0.0  \n",
       "7     0.0     0.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como esta rede é especifica para a BH, vamos remover elvt, lat, lon\n",
    "#REMOVE = ['elvt','lat', 'lon']\n",
    "#for v in REMOVE:\n",
    "#    dfm = dfm.drop(v,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wsid</th>\n",
       "      <th>elvt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>prcp</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>...</th>\n",
       "      <th>stp_3</th>\n",
       "      <th>smin_1</th>\n",
       "      <th>smin_2</th>\n",
       "      <th>smin_3</th>\n",
       "      <th>dmin_1</th>\n",
       "      <th>dmin_2</th>\n",
       "      <th>dmin_3</th>\n",
       "      <th>dmax_1</th>\n",
       "      <th>dmax_2</th>\n",
       "      <th>dmax_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wsid   elvt       lat        lon  prcp  stp  smax  smin  temp  tmax  \\\n",
       "3   178  237.0 -6.835777 -38.311583   0.0  0.0   0.0   0.0   0.0   0.0   \n",
       "4   178  237.0 -6.835777 -38.311583   0.0  0.0   0.0   0.0   0.0   0.0   \n",
       "5   178  237.0 -6.835777 -38.311583   0.0  0.0   0.0   0.0   0.0   0.0   \n",
       "6   178  237.0 -6.835777 -38.311583   0.0  0.0   0.0   0.0   0.0   0.0   \n",
       "7   178  237.0 -6.835777 -38.311583   0.0  0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "    ...    stp_3  smin_1  smin_2  smin_3  dmin_1  dmin_2  dmin_3  dmax_1  \\\n",
       "3   ...      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4   ...      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5   ...      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "6   ...      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "7   ...      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   dmax_2  dmax_3  \n",
       "3     0.0     0.0  \n",
       "4     0.0     0.0  \n",
       "5     0.0     0.0  \n",
       "6     0.0     0.0  \n",
       "7     0.0     0.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wdsp', 'prcp', 'gust']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAN_BE_NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preparando a base</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Removendo registros que não pode ser nulos e prejudicariam o treinamento</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(dfm.columns)\n",
    "\n",
    "COLS_BE_NULL = ['prcp','wdsp','wdsp_1','wdsp_2','wdsp_3','wdsp_4','wdsp_5',\\\n",
    "                'gust','gust_1','gust_2','gust_3','gust_4','gust_5']\n",
    "for v in COLS_BE_NULL:\n",
    "    if v in cols:\n",
    "        cols.remove(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wsid</th>\n",
       "      <th>elvt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>prcp</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>...</th>\n",
       "      <th>stp_3</th>\n",
       "      <th>smin_1</th>\n",
       "      <th>smin_2</th>\n",
       "      <th>smin_3</th>\n",
       "      <th>dmin_1</th>\n",
       "      <th>dmin_2</th>\n",
       "      <th>dmin_3</th>\n",
       "      <th>dmax_1</th>\n",
       "      <th>dmax_2</th>\n",
       "      <th>dmax_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wsid   elvt       lat        lon  prcp  stp  smax  smin  temp  tmax  \\\n",
       "3   178  237.0 -6.835777 -38.311583   0.0  NaN   NaN   NaN   NaN   NaN   \n",
       "4   178  237.0 -6.835777 -38.311583   0.0  NaN   NaN   NaN   NaN   NaN   \n",
       "5   178  237.0 -6.835777 -38.311583   0.0  NaN   NaN   NaN   NaN   NaN   \n",
       "6   178  237.0 -6.835777 -38.311583   0.0  NaN   NaN   NaN   NaN   NaN   \n",
       "7   178  237.0 -6.835777 -38.311583   0.0  NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "    ...    stp_3  smin_1  smin_2  smin_3  dmin_1  dmin_2  dmin_3  dmax_1  \\\n",
       "3   ...      NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4   ...      NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "5   ...      NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "6   ...      NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "7   ...      NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "   dmax_2  dmax_3  \n",
       "3     NaN     NaN  \n",
       "4     NaN     NaN  \n",
       "5     NaN     NaN  \n",
       "6     NaN     NaN  \n",
       "7     NaN     NaN  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm[cols] = dfm[cols].replace({0.0:np.nan})\n",
    "dfm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = dfm.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2797897"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wsid</th>\n",
       "      <th>elvt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>prcp</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>...</th>\n",
       "      <th>stp_3</th>\n",
       "      <th>smin_1</th>\n",
       "      <th>smin_2</th>\n",
       "      <th>smin_3</th>\n",
       "      <th>dmin_1</th>\n",
       "      <th>dmin_2</th>\n",
       "      <th>dmin_3</th>\n",
       "      <th>dmax_1</th>\n",
       "      <th>dmax_2</th>\n",
       "      <th>dmax_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>985.3</td>\n",
       "      <td>986.0</td>\n",
       "      <td>985.3</td>\n",
       "      <td>30.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>...</td>\n",
       "      <td>986.3</td>\n",
       "      <td>986.0</td>\n",
       "      <td>986.2</td>\n",
       "      <td>985.7</td>\n",
       "      <td>15.6</td>\n",
       "      <td>16.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>26.2</td>\n",
       "      <td>25.1</td>\n",
       "      <td>24.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>984.5</td>\n",
       "      <td>985.3</td>\n",
       "      <td>984.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.8</td>\n",
       "      <td>...</td>\n",
       "      <td>986.3</td>\n",
       "      <td>985.3</td>\n",
       "      <td>986.0</td>\n",
       "      <td>986.2</td>\n",
       "      <td>14.7</td>\n",
       "      <td>15.6</td>\n",
       "      <td>16.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>26.2</td>\n",
       "      <td>25.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>983.6</td>\n",
       "      <td>984.5</td>\n",
       "      <td>983.6</td>\n",
       "      <td>32.3</td>\n",
       "      <td>12.4</td>\n",
       "      <td>...</td>\n",
       "      <td>986.0</td>\n",
       "      <td>984.5</td>\n",
       "      <td>985.3</td>\n",
       "      <td>986.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>14.7</td>\n",
       "      <td>15.6</td>\n",
       "      <td>29.9</td>\n",
       "      <td>28.4</td>\n",
       "      <td>26.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>982.6</td>\n",
       "      <td>983.6</td>\n",
       "      <td>982.6</td>\n",
       "      <td>33.2</td>\n",
       "      <td>12.2</td>\n",
       "      <td>...</td>\n",
       "      <td>985.3</td>\n",
       "      <td>983.6</td>\n",
       "      <td>984.5</td>\n",
       "      <td>985.3</td>\n",
       "      <td>12.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>14.7</td>\n",
       "      <td>31.1</td>\n",
       "      <td>29.9</td>\n",
       "      <td>28.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>178</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>981.7</td>\n",
       "      <td>982.6</td>\n",
       "      <td>981.7</td>\n",
       "      <td>34.4</td>\n",
       "      <td>13.2</td>\n",
       "      <td>...</td>\n",
       "      <td>984.5</td>\n",
       "      <td>982.6</td>\n",
       "      <td>983.6</td>\n",
       "      <td>984.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>12.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.1</td>\n",
       "      <td>29.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    wsid   elvt       lat        lon  prcp    stp   smax   smin  temp  tmax  \\\n",
       "13   178  237.0 -6.835777 -38.311583   0.0  985.3  986.0  985.3  30.1  15.4   \n",
       "14   178  237.0 -6.835777 -38.311583   0.0  984.5  985.3  984.5  31.1  12.8   \n",
       "15   178  237.0 -6.835777 -38.311583   0.0  983.6  984.5  983.6  32.3  12.4   \n",
       "16   178  237.0 -6.835777 -38.311583   0.0  982.6  983.6  982.6  33.2  12.2   \n",
       "17   178  237.0 -6.835777 -38.311583   0.0  981.7  982.6  981.7  34.4  13.2   \n",
       "\n",
       "     ...    stp_3  smin_1  smin_2  smin_3  dmin_1  dmin_2  dmin_3  dmax_1  \\\n",
       "13   ...    986.3   986.0   986.2   985.7    15.6    16.8    17.4    26.2   \n",
       "14   ...    986.3   985.3   986.0   986.2    14.7    15.6    16.8    28.4   \n",
       "15   ...    986.0   984.5   985.3   986.0    12.6    14.7    15.6    29.9   \n",
       "16   ...    985.3   983.6   984.5   985.3    12.1    12.6    14.7    31.1   \n",
       "17   ...    984.5   982.6   983.6   984.5    11.5    12.1    12.6    32.0   \n",
       "\n",
       "    dmax_2  dmax_3  \n",
       "13    25.1    24.3  \n",
       "14    26.2    25.1  \n",
       "15    28.4    26.2  \n",
       "16    29.9    28.4  \n",
       "17    31.1    29.9  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wsid</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>357.492991</td>\n",
       "      <td>38.903906</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>327.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>423.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elvt</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>594.566203</td>\n",
       "      <td>375.224934</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>582.000000</td>\n",
       "      <td>875.000000</td>\n",
       "      <td>1758.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>-20.270528</td>\n",
       "      <td>2.656046</td>\n",
       "      <td>-24.962819</td>\n",
       "      <td>-22.372832</td>\n",
       "      <td>-20.636526</td>\n",
       "      <td>-18.830354</td>\n",
       "      <td>-6.835777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lon</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>-44.913626</td>\n",
       "      <td>3.002970</td>\n",
       "      <td>-51.408637</td>\n",
       "      <td>-47.382549</td>\n",
       "      <td>-44.453785</td>\n",
       "      <td>-42.435750</td>\n",
       "      <td>-38.311583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prcp</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>0.247649</td>\n",
       "      <td>1.652962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>946.454211</td>\n",
       "      <td>40.702848</td>\n",
       "      <td>816.800000</td>\n",
       "      <td>915.400000</td>\n",
       "      <td>946.000000</td>\n",
       "      <td>976.200000</td>\n",
       "      <td>1048.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>946.720094</td>\n",
       "      <td>40.705375</td>\n",
       "      <td>817.100000</td>\n",
       "      <td>915.700000</td>\n",
       "      <td>946.200000</td>\n",
       "      <td>976.500000</td>\n",
       "      <td>1049.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>946.190541</td>\n",
       "      <td>40.701275</td>\n",
       "      <td>816.700000</td>\n",
       "      <td>915.200000</td>\n",
       "      <td>945.700000</td>\n",
       "      <td>975.900000</td>\n",
       "      <td>1046.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>23.887545</td>\n",
       "      <td>4.192058</td>\n",
       "      <td>-2.300000</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>23.400000</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>43.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>18.785615</td>\n",
       "      <td>2.564058</td>\n",
       "      <td>-9.800000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>37.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>24.547936</td>\n",
       "      <td>4.386222</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewp</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>19.363124</td>\n",
       "      <td>2.489044</td>\n",
       "      <td>-9.200000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>37.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmax</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>23.273387</td>\n",
       "      <td>3.988105</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>25.800000</td>\n",
       "      <td>42.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmin</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>18.237477</td>\n",
       "      <td>2.668392</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>20.100000</td>\n",
       "      <td>33.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>75.757650</td>\n",
       "      <td>17.445742</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>78.772250</td>\n",
       "      <td>16.161389</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>72.586839</td>\n",
       "      <td>18.458336</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>1.910764</td>\n",
       "      <td>1.545645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>19.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>153.394449</td>\n",
       "      <td>105.408095</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>4.752383</td>\n",
       "      <td>2.780491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct_1</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>153.389688</td>\n",
       "      <td>105.436005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct_2</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>153.377202</td>\n",
       "      <td>105.457164</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct_3</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>153.357978</td>\n",
       "      <td>105.470091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin_1</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>24.550515</td>\n",
       "      <td>4.384861</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin_2</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>24.550665</td>\n",
       "      <td>4.382639</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin_3</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>24.548231</td>\n",
       "      <td>4.380248</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax_1</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>78.763874</td>\n",
       "      <td>16.154672</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax_2</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>78.766571</td>\n",
       "      <td>16.146264</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax_3</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>78.779875</td>\n",
       "      <td>16.140292</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp_1</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>23.890899</td>\n",
       "      <td>4.191284</td>\n",
       "      <td>-2.300000</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>23.400000</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>43.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust_1</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>4.753486</td>\n",
       "      <td>2.779246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust_2</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>4.753614</td>\n",
       "      <td>2.778208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust_3</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>4.752024</td>\n",
       "      <td>2.777953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax_1</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>18.786028</td>\n",
       "      <td>2.562339</td>\n",
       "      <td>-9.500000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>37.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax_2</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>18.786552</td>\n",
       "      <td>2.561365</td>\n",
       "      <td>-9.700000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>37.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax_3</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>18.787066</td>\n",
       "      <td>2.561243</td>\n",
       "      <td>-9.700000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>37.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax_1</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>946.722920</td>\n",
       "      <td>40.706137</td>\n",
       "      <td>817.100000</td>\n",
       "      <td>915.700000</td>\n",
       "      <td>946.200000</td>\n",
       "      <td>976.500000</td>\n",
       "      <td>1049.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax_2</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>946.725742</td>\n",
       "      <td>40.706918</td>\n",
       "      <td>817.100000</td>\n",
       "      <td>915.700000</td>\n",
       "      <td>946.200000</td>\n",
       "      <td>976.500000</td>\n",
       "      <td>1049.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax_3</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>946.728089</td>\n",
       "      <td>40.707558</td>\n",
       "      <td>817.100000</td>\n",
       "      <td>915.700000</td>\n",
       "      <td>946.200000</td>\n",
       "      <td>976.500000</td>\n",
       "      <td>1049.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy_1</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>75.742604</td>\n",
       "      <td>17.439452</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy_2</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>75.737760</td>\n",
       "      <td>17.430572</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy_3</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>75.744101</td>\n",
       "      <td>17.422011</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewp_1</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>19.363879</td>\n",
       "      <td>2.488450</td>\n",
       "      <td>-8.900000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>37.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewp_2</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>19.364586</td>\n",
       "      <td>2.488114</td>\n",
       "      <td>-9.300000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>37.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewp_3</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>19.365133</td>\n",
       "      <td>2.488429</td>\n",
       "      <td>-9.300000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>37.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp_1</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>1.911429</td>\n",
       "      <td>1.544869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>19.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp_2</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>1.911853</td>\n",
       "      <td>1.544340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>19.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp_3</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>1.911786</td>\n",
       "      <td>1.543932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>19.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp_1</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>946.456987</td>\n",
       "      <td>40.703589</td>\n",
       "      <td>816.800000</td>\n",
       "      <td>915.400000</td>\n",
       "      <td>946.000000</td>\n",
       "      <td>976.200000</td>\n",
       "      <td>1048.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp_2</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>946.460028</td>\n",
       "      <td>40.704428</td>\n",
       "      <td>816.800000</td>\n",
       "      <td>915.400000</td>\n",
       "      <td>946.000000</td>\n",
       "      <td>976.200000</td>\n",
       "      <td>1048.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp_3</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>946.462789</td>\n",
       "      <td>40.705191</td>\n",
       "      <td>816.800000</td>\n",
       "      <td>915.400000</td>\n",
       "      <td>946.000000</td>\n",
       "      <td>976.200000</td>\n",
       "      <td>1048.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin_1</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>946.193581</td>\n",
       "      <td>40.702107</td>\n",
       "      <td>816.700000</td>\n",
       "      <td>915.200000</td>\n",
       "      <td>945.700000</td>\n",
       "      <td>975.900000</td>\n",
       "      <td>1046.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin_2</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>946.196607</td>\n",
       "      <td>40.702952</td>\n",
       "      <td>816.700000</td>\n",
       "      <td>915.200000</td>\n",
       "      <td>945.700000</td>\n",
       "      <td>975.900000</td>\n",
       "      <td>1046.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin_3</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>946.199096</td>\n",
       "      <td>40.703634</td>\n",
       "      <td>816.700000</td>\n",
       "      <td>915.200000</td>\n",
       "      <td>945.700000</td>\n",
       "      <td>975.900000</td>\n",
       "      <td>1046.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmin_1</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>18.237789</td>\n",
       "      <td>2.666128</td>\n",
       "      <td>-9.900000</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>20.100000</td>\n",
       "      <td>33.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmin_2</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>18.238177</td>\n",
       "      <td>2.665441</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>20.100000</td>\n",
       "      <td>33.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmin_3</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>18.238393</td>\n",
       "      <td>2.666972</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>20.100000</td>\n",
       "      <td>33.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmax_1</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>23.275276</td>\n",
       "      <td>3.986859</td>\n",
       "      <td>-2.300000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>25.800000</td>\n",
       "      <td>42.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmax_2</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>23.274645</td>\n",
       "      <td>3.984843</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>25.800000</td>\n",
       "      <td>42.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmax_3</th>\n",
       "      <td>2797897.0</td>\n",
       "      <td>23.271542</td>\n",
       "      <td>3.982931</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>25.800000</td>\n",
       "      <td>42.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            count        mean         std         min         25%         50%  \\\n",
       "wsid    2797897.0  357.492991   38.903906  178.000000  327.000000  354.000000   \n",
       "elvt    2797897.0  594.566203  375.224934    3.000000  288.000000  582.000000   \n",
       "lat     2797897.0  -20.270528    2.656046  -24.962819  -22.372832  -20.636526   \n",
       "lon     2797897.0  -44.913626    3.002970  -51.408637  -47.382549  -44.453785   \n",
       "prcp    2797897.0    0.247649    1.652962    0.000000    0.000000    0.000000   \n",
       "stp     2797897.0  946.454211   40.702848  816.800000  915.400000  946.000000   \n",
       "smax    2797897.0  946.720094   40.705375  817.100000  915.700000  946.200000   \n",
       "smin    2797897.0  946.190541   40.701275  816.700000  915.200000  945.700000   \n",
       "temp    2797897.0   23.887545    4.192058   -2.300000   20.900000   23.400000   \n",
       "tmax    2797897.0   18.785615    2.564058   -9.800000   17.300000   19.000000   \n",
       "tmin    2797897.0   24.547936    4.386222    6.300000   21.300000   24.000000   \n",
       "dewp    2797897.0   19.363124    2.489044   -9.200000   17.900000   19.500000   \n",
       "dmax    2797897.0   23.273387    3.988105   -2.600000   20.500000   22.800000   \n",
       "dmin    2797897.0   18.237477    2.668392  -10.000000   16.700000   18.500000   \n",
       "hmdy    2797897.0   75.757650   17.445742   10.000000   64.000000   80.000000   \n",
       "hmax    2797897.0   78.772250   16.161389   11.000000   68.000000   83.000000   \n",
       "hmin    2797897.0   72.586839   18.458336   10.000000   59.000000   76.000000   \n",
       "wdsp    2797897.0    1.910764    1.545645    0.000000    0.700000    1.700000   \n",
       "wdct    2797897.0  153.394449  105.408095    1.000000   68.000000  123.000000   \n",
       "gust    2797897.0    4.752383    2.780491    0.000000    2.700000    4.500000   \n",
       "wdct_1  2797897.0  153.389688  105.436005    1.000000   68.000000  123.000000   \n",
       "wdct_2  2797897.0  153.377202  105.457164    1.000000   68.000000  123.000000   \n",
       "wdct_3  2797897.0  153.357978  105.470091    1.000000   68.000000  123.000000   \n",
       "tmin_1  2797897.0   24.550515    4.384861    6.300000   21.300000   24.000000   \n",
       "tmin_2  2797897.0   24.550665    4.382639    6.300000   21.300000   24.000000   \n",
       "tmin_3  2797897.0   24.548231    4.380248    6.300000   21.300000   24.000000   \n",
       "hmax_1  2797897.0   78.763874   16.154672   11.000000   68.000000   83.000000   \n",
       "hmax_2  2797897.0   78.766571   16.146264   11.000000   68.000000   83.000000   \n",
       "hmax_3  2797897.0   78.779875   16.140292   11.000000   68.000000   83.000000   \n",
       "temp_1  2797897.0   23.890899    4.191284   -2.300000   20.900000   23.400000   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "gust_1  2797897.0    4.753486    2.779246    0.000000    2.700000    4.500000   \n",
       "gust_2  2797897.0    4.753614    2.778208    0.000000    2.700000    4.500000   \n",
       "gust_3  2797897.0    4.752024    2.777953    0.000000    2.700000    4.500000   \n",
       "tmax_1  2797897.0   18.786028    2.562339   -9.500000   17.300000   19.000000   \n",
       "tmax_2  2797897.0   18.786552    2.561365   -9.700000   17.300000   19.000000   \n",
       "tmax_3  2797897.0   18.787066    2.561243   -9.700000   17.300000   19.000000   \n",
       "smax_1  2797897.0  946.722920   40.706137  817.100000  915.700000  946.200000   \n",
       "smax_2  2797897.0  946.725742   40.706918  817.100000  915.700000  946.200000   \n",
       "smax_3  2797897.0  946.728089   40.707558  817.100000  915.700000  946.200000   \n",
       "hmdy_1  2797897.0   75.742604   17.439452   10.000000   64.000000   80.000000   \n",
       "hmdy_2  2797897.0   75.737760   17.430572   10.000000   64.000000   80.000000   \n",
       "hmdy_3  2797897.0   75.744101   17.422011   10.000000   64.000000   80.000000   \n",
       "dewp_1  2797897.0   19.363879    2.488450   -8.900000   17.900000   19.500000   \n",
       "dewp_2  2797897.0   19.364586    2.488114   -9.300000   17.900000   19.500000   \n",
       "dewp_3  2797897.0   19.365133    2.488429   -9.300000   17.900000   19.500000   \n",
       "wdsp_1  2797897.0    1.911429    1.544869    0.000000    0.700000    1.700000   \n",
       "wdsp_2  2797897.0    1.911853    1.544340    0.000000    0.700000    1.700000   \n",
       "wdsp_3  2797897.0    1.911786    1.543932    0.000000    0.700000    1.700000   \n",
       "stp_1   2797897.0  946.456987   40.703589  816.800000  915.400000  946.000000   \n",
       "stp_2   2797897.0  946.460028   40.704428  816.800000  915.400000  946.000000   \n",
       "stp_3   2797897.0  946.462789   40.705191  816.800000  915.400000  946.000000   \n",
       "smin_1  2797897.0  946.193581   40.702107  816.700000  915.200000  945.700000   \n",
       "smin_2  2797897.0  946.196607   40.702952  816.700000  915.200000  945.700000   \n",
       "smin_3  2797897.0  946.199096   40.703634  816.700000  915.200000  945.700000   \n",
       "dmin_1  2797897.0   18.237789    2.666128   -9.900000   16.700000   18.500000   \n",
       "dmin_2  2797897.0   18.238177    2.665441  -10.000000   16.700000   18.500000   \n",
       "dmin_3  2797897.0   18.238393    2.666972  -10.000000   16.700000   18.500000   \n",
       "dmax_1  2797897.0   23.275276    3.986859   -2.300000   20.500000   22.800000   \n",
       "dmax_2  2797897.0   23.274645    3.984843   -0.800000   20.500000   22.800000   \n",
       "dmax_3  2797897.0   23.271542    3.982931   -0.800000   20.500000   22.800000   \n",
       "\n",
       "               75%          max  \n",
       "wsid    393.000000   423.000000  \n",
       "elvt    875.000000  1758.000000  \n",
       "lat     -18.830354    -6.835777  \n",
       "lon     -42.435750   -38.311583  \n",
       "prcp      0.000000   100.000000  \n",
       "stp     976.200000  1048.300000  \n",
       "smax    976.500000  1049.100000  \n",
       "smin    975.900000  1046.900000  \n",
       "temp     26.700000    43.500000  \n",
       "tmax     20.600000    37.200000  \n",
       "tmin     27.600000    45.000000  \n",
       "dewp     21.100000    37.500000  \n",
       "dmax     25.800000    42.300000  \n",
       "dmin     20.100000    33.600000  \n",
       "hmdy     91.000000   100.000000  \n",
       "hmax     92.000000   100.000000  \n",
       "hmin     89.000000   100.000000  \n",
       "wdsp      2.700000    19.100000  \n",
       "wdct    241.000000   360.000000  \n",
       "gust      6.400000    50.000000  \n",
       "wdct_1  241.000000   360.000000  \n",
       "wdct_2  241.000000   360.000000  \n",
       "wdct_3  241.000000   360.000000  \n",
       "tmin_1   27.600000    45.000000  \n",
       "tmin_2   27.600000    45.000000  \n",
       "tmin_3   27.600000    45.000000  \n",
       "hmax_1   92.000000   100.000000  \n",
       "hmax_2   92.000000   100.000000  \n",
       "hmax_3   92.000000   100.000000  \n",
       "temp_1   26.700000    43.500000  \n",
       "...            ...          ...  \n",
       "gust_1    6.400000    50.000000  \n",
       "gust_2    6.400000    50.000000  \n",
       "gust_3    6.400000    50.000000  \n",
       "tmax_1   20.600000    37.200000  \n",
       "tmax_2   20.600000    37.200000  \n",
       "tmax_3   20.600000    37.200000  \n",
       "smax_1  976.500000  1049.100000  \n",
       "smax_2  976.500000  1049.100000  \n",
       "smax_3  976.500000  1049.100000  \n",
       "hmdy_1   91.000000   100.000000  \n",
       "hmdy_2   91.000000   100.000000  \n",
       "hmdy_3   91.000000   100.000000  \n",
       "dewp_1   21.100000    37.500000  \n",
       "dewp_2   21.100000    37.500000  \n",
       "dewp_3   21.100000    37.500000  \n",
       "wdsp_1    2.700000    19.100000  \n",
       "wdsp_2    2.700000    19.100000  \n",
       "wdsp_3    2.700000    19.100000  \n",
       "stp_1   976.200000  1048.300000  \n",
       "stp_2   976.200000  1048.300000  \n",
       "stp_3   976.200000  1048.300000  \n",
       "smin_1  975.900000  1046.900000  \n",
       "smin_2  975.900000  1046.900000  \n",
       "smin_3  975.900000  1046.900000  \n",
       "dmin_1   20.100000    33.600000  \n",
       "dmin_2   20.100000    33.600000  \n",
       "dmin_3   20.100000    33.600000  \n",
       "dmax_1   25.800000    42.300000  \n",
       "dmax_2   25.800000    42.300000  \n",
       "dmax_3   25.800000    42.300000  \n",
       "\n",
       "[65 rows x 8 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    " dfm = dfm.drop('wsid',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Balanceamento</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Preparação para o balanceamento</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x['prcp'] == 0.0: \n",
    "        return 0\n",
    "    else:        \n",
    "        return 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm['type'] = dfm.apply(f,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elvt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>prcp</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>...</th>\n",
       "      <th>smin_1</th>\n",
       "      <th>smin_2</th>\n",
       "      <th>smin_3</th>\n",
       "      <th>dmin_1</th>\n",
       "      <th>dmin_2</th>\n",
       "      <th>dmin_3</th>\n",
       "      <th>dmax_1</th>\n",
       "      <th>dmax_2</th>\n",
       "      <th>dmax_3</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>985.3</td>\n",
       "      <td>986.0</td>\n",
       "      <td>985.3</td>\n",
       "      <td>30.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>30.4</td>\n",
       "      <td>...</td>\n",
       "      <td>986.0</td>\n",
       "      <td>986.2</td>\n",
       "      <td>985.7</td>\n",
       "      <td>15.6</td>\n",
       "      <td>16.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>26.2</td>\n",
       "      <td>25.1</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>984.5</td>\n",
       "      <td>985.3</td>\n",
       "      <td>984.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.8</td>\n",
       "      <td>31.8</td>\n",
       "      <td>...</td>\n",
       "      <td>985.3</td>\n",
       "      <td>986.0</td>\n",
       "      <td>986.2</td>\n",
       "      <td>14.7</td>\n",
       "      <td>15.6</td>\n",
       "      <td>16.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>26.2</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>983.6</td>\n",
       "      <td>984.5</td>\n",
       "      <td>983.6</td>\n",
       "      <td>32.3</td>\n",
       "      <td>12.4</td>\n",
       "      <td>32.9</td>\n",
       "      <td>...</td>\n",
       "      <td>984.5</td>\n",
       "      <td>985.3</td>\n",
       "      <td>986.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>14.7</td>\n",
       "      <td>15.6</td>\n",
       "      <td>29.9</td>\n",
       "      <td>28.4</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     elvt       lat        lon  prcp    stp   smax   smin  temp  tmax  tmin  \\\n",
       "13  237.0 -6.835777 -38.311583   0.0  985.3  986.0  985.3  30.1  15.4  30.4   \n",
       "14  237.0 -6.835777 -38.311583   0.0  984.5  985.3  984.5  31.1  12.8  31.8   \n",
       "15  237.0 -6.835777 -38.311583   0.0  983.6  984.5  983.6  32.3  12.4  32.9   \n",
       "\n",
       "    ...   smin_1  smin_2  smin_3  dmin_1  dmin_2  dmin_3  dmax_1  dmax_2  \\\n",
       "13  ...    986.0   986.2   985.7    15.6    16.8    17.4    26.2    25.1   \n",
       "14  ...    985.3   986.0   986.2    14.7    15.6    16.8    28.4    26.2   \n",
       "15  ...    984.5   985.3   986.0    12.6    14.7    15.6    29.9    28.4   \n",
       "\n",
       "    dmax_3  type  \n",
       "13    24.3     0  \n",
       "14    25.1     0  \n",
       "15    26.2     0  \n",
       "\n",
       "[3 rows x 65 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando bins sem chuva(0mm), com poquisima chuva( até 0.1mm), chuva fraca (> 0.1 até 1.0) \\\n",
    "#e depois agrupando de 5 em \n",
    "#bins = np.linspace(dfm.prcp.min(), dfm.prcp.max(), 10)\n",
    "#bins = [0,0.1,1,5,10,15,20,25,30] \n",
    "#types = np.digitize(dfm.prcp, bins)  \n",
    "#dfm['type'] = types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "0    2498467\n",
      "1     299430\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "z = dfm['type'].groupby(dfm['type']).count()\n",
    "print (z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mineiração dos dados</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Rede neural</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  \n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error,  median_absolute_error\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfm = dfm.drop('prcp',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfm[[col for col in dfm.columns if col != target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dfm[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elvt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>prcp</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>...</th>\n",
       "      <th>stp_3</th>\n",
       "      <th>smin_1</th>\n",
       "      <th>smin_2</th>\n",
       "      <th>smin_3</th>\n",
       "      <th>dmin_1</th>\n",
       "      <th>dmin_2</th>\n",
       "      <th>dmin_3</th>\n",
       "      <th>dmax_1</th>\n",
       "      <th>dmax_2</th>\n",
       "      <th>dmax_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>985.3</td>\n",
       "      <td>986.0</td>\n",
       "      <td>985.3</td>\n",
       "      <td>30.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>30.4</td>\n",
       "      <td>...</td>\n",
       "      <td>986.3</td>\n",
       "      <td>986.0</td>\n",
       "      <td>986.2</td>\n",
       "      <td>985.7</td>\n",
       "      <td>15.6</td>\n",
       "      <td>16.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>26.2</td>\n",
       "      <td>25.1</td>\n",
       "      <td>24.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>984.5</td>\n",
       "      <td>985.3</td>\n",
       "      <td>984.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.8</td>\n",
       "      <td>31.8</td>\n",
       "      <td>...</td>\n",
       "      <td>986.3</td>\n",
       "      <td>985.3</td>\n",
       "      <td>986.0</td>\n",
       "      <td>986.2</td>\n",
       "      <td>14.7</td>\n",
       "      <td>15.6</td>\n",
       "      <td>16.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>26.2</td>\n",
       "      <td>25.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>983.6</td>\n",
       "      <td>984.5</td>\n",
       "      <td>983.6</td>\n",
       "      <td>32.3</td>\n",
       "      <td>12.4</td>\n",
       "      <td>32.9</td>\n",
       "      <td>...</td>\n",
       "      <td>986.0</td>\n",
       "      <td>984.5</td>\n",
       "      <td>985.3</td>\n",
       "      <td>986.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>14.7</td>\n",
       "      <td>15.6</td>\n",
       "      <td>29.9</td>\n",
       "      <td>28.4</td>\n",
       "      <td>26.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>982.6</td>\n",
       "      <td>983.6</td>\n",
       "      <td>982.6</td>\n",
       "      <td>33.2</td>\n",
       "      <td>12.2</td>\n",
       "      <td>33.7</td>\n",
       "      <td>...</td>\n",
       "      <td>985.3</td>\n",
       "      <td>983.6</td>\n",
       "      <td>984.5</td>\n",
       "      <td>985.3</td>\n",
       "      <td>12.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>14.7</td>\n",
       "      <td>31.1</td>\n",
       "      <td>29.9</td>\n",
       "      <td>28.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>237.0</td>\n",
       "      <td>-6.835777</td>\n",
       "      <td>-38.311583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>981.7</td>\n",
       "      <td>982.6</td>\n",
       "      <td>981.7</td>\n",
       "      <td>34.4</td>\n",
       "      <td>13.2</td>\n",
       "      <td>34.9</td>\n",
       "      <td>...</td>\n",
       "      <td>984.5</td>\n",
       "      <td>982.6</td>\n",
       "      <td>983.6</td>\n",
       "      <td>984.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>12.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.1</td>\n",
       "      <td>29.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     elvt       lat        lon  prcp    stp   smax   smin  temp  tmax  tmin  \\\n",
       "13  237.0 -6.835777 -38.311583   0.0  985.3  986.0  985.3  30.1  15.4  30.4   \n",
       "14  237.0 -6.835777 -38.311583   0.0  984.5  985.3  984.5  31.1  12.8  31.8   \n",
       "15  237.0 -6.835777 -38.311583   0.0  983.6  984.5  983.6  32.3  12.4  32.9   \n",
       "16  237.0 -6.835777 -38.311583   0.0  982.6  983.6  982.6  33.2  12.2  33.7   \n",
       "17  237.0 -6.835777 -38.311583   0.0  981.7  982.6  981.7  34.4  13.2  34.9   \n",
       "\n",
       "     ...    stp_3  smin_1  smin_2  smin_3  dmin_1  dmin_2  dmin_3  dmax_1  \\\n",
       "13   ...    986.3   986.0   986.2   985.7    15.6    16.8    17.4    26.2   \n",
       "14   ...    986.3   985.3   986.0   986.2    14.7    15.6    16.8    28.4   \n",
       "15   ...    986.0   984.5   985.3   986.0    12.6    14.7    15.6    29.9   \n",
       "16   ...    985.3   983.6   984.5   985.3    12.1    12.6    14.7    31.1   \n",
       "17   ...    984.5   982.6   983.6   984.5    11.5    12.1    12.6    32.0   \n",
       "\n",
       "    dmax_2  dmax_3  \n",
       "13    25.1    24.3  \n",
       "14    26.2    25.1  \n",
       "15    28.4    26.2  \n",
       "16    29.9    28.4  \n",
       "17    31.1    29.9  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Separando o conjunto de treinamento e validação (metade dos 30% separados para validação)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.3, random_state=12) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Executando o balanceamento</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vis = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(return_indices=True)\n",
    "X_resampled, y_resampled, idx_resampled = rus.fit_sample(X_train, y_train)\n",
    "X_res_vis = pca.transform(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f405d56c490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "idx_samples_removed = np.setdiff1d(np.arange(X_vis.shape[0]),\n",
    "                                   idx_resampled)\n",
    "\n",
    "idx_class_0 = y_resampled == 0\n",
    "plt.scatter(X_res_vis[idx_class_0, 0], X_res_vis[idx_class_0, 1],\n",
    "            alpha=.8, label=u'Sem precipitação')\n",
    "plt.scatter(X_res_vis[~idx_class_0, 0], X_res_vis[~idx_class_0, 1],\n",
    "            alpha=.8, label=u'Com precipitação')\n",
    "plt.scatter(X_vis[idx_samples_removed, 0], X_vis[idx_samples_removed, 1],\n",
    "            alpha=.8, label='Removidos')\n",
    "\n",
    "# make nice plotting\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.get_xaxis().tick_bottom()\n",
    "ax.get_yaxis().tick_left()\n",
    "ax.spines['left'].set_position(('outward', 10))\n",
    "ax.spines['bottom'].set_position(('outward', 10))\n",
    "#ax.set_xlim([-6, 6])\n",
    "#ax.set_ylim([-6, 6])\n",
    "\n",
    "plt.title('Under-sampling using random under-sampling')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_over, y_train_over =  SMOTE(random_state=12).fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418330, 418330)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_resampled), len(y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Reconstruindo o dataframe</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = pd.DataFrame(X_train_over, columns = X_train.columns)\n",
    "X_train = pd.DataFrame(X_resampled, columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = pd.DataFrame(y_train_over, columns =['type'])\n",
    "y_train = pd.DataFrame(y_resampled, columns =['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elvt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>prcp</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>...</th>\n",
       "      <th>stp_3</th>\n",
       "      <th>smin_1</th>\n",
       "      <th>smin_2</th>\n",
       "      <th>smin_3</th>\n",
       "      <th>dmin_1</th>\n",
       "      <th>dmin_2</th>\n",
       "      <th>dmin_3</th>\n",
       "      <th>dmax_1</th>\n",
       "      <th>dmax_2</th>\n",
       "      <th>dmax_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>525.0</td>\n",
       "      <td>-21.132937</td>\n",
       "      <td>-48.840426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>951.7</td>\n",
       "      <td>951.7</td>\n",
       "      <td>951.5</td>\n",
       "      <td>22.1</td>\n",
       "      <td>20.8</td>\n",
       "      <td>22.6</td>\n",
       "      <td>...</td>\n",
       "      <td>952.9</td>\n",
       "      <td>951.7</td>\n",
       "      <td>952.1</td>\n",
       "      <td>952.9</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>22.4</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>566.0</td>\n",
       "      <td>-22.703132</td>\n",
       "      <td>-47.623317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>947.2</td>\n",
       "      <td>947.4</td>\n",
       "      <td>947.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>947.7</td>\n",
       "      <td>947.2</td>\n",
       "      <td>947.6</td>\n",
       "      <td>947.6</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.1</td>\n",
       "      <td>21.8</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>862.0</td>\n",
       "      <td>-23.228362</td>\n",
       "      <td>-45.417055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>915.9</td>\n",
       "      <td>916.5</td>\n",
       "      <td>915.8</td>\n",
       "      <td>26.2</td>\n",
       "      <td>18.3</td>\n",
       "      <td>26.6</td>\n",
       "      <td>...</td>\n",
       "      <td>917.2</td>\n",
       "      <td>916.5</td>\n",
       "      <td>917.1</td>\n",
       "      <td>917.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>17.3</td>\n",
       "      <td>17.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>734.0</td>\n",
       "      <td>-21.780560</td>\n",
       "      <td>-47.075280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>933.2</td>\n",
       "      <td>933.2</td>\n",
       "      <td>932.5</td>\n",
       "      <td>20.5</td>\n",
       "      <td>19.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>...</td>\n",
       "      <td>931.1</td>\n",
       "      <td>931.9</td>\n",
       "      <td>931.1</td>\n",
       "      <td>930.9</td>\n",
       "      <td>19.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>997.0</td>\n",
       "      <td>-17.561349</td>\n",
       "      <td>-47.199251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>904.2</td>\n",
       "      <td>904.2</td>\n",
       "      <td>904.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>15.6</td>\n",
       "      <td>21.2</td>\n",
       "      <td>...</td>\n",
       "      <td>903.4</td>\n",
       "      <td>903.4</td>\n",
       "      <td>903.3</td>\n",
       "      <td>903.3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>15.6</td>\n",
       "      <td>20.4</td>\n",
       "      <td>21.7</td>\n",
       "      <td>23.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    elvt        lat        lon  prcp    stp   smax   smin  temp  tmax  tmin  \\\n",
       "0  525.0 -21.132937 -48.840426   0.0  951.7  951.7  951.5  22.1  20.8  22.6   \n",
       "1  566.0 -22.703132 -47.623317   0.0  947.2  947.4  947.0  21.8  19.8  22.0   \n",
       "2  862.0 -23.228362 -45.417055   0.0  915.9  916.5  915.8  26.2  18.3  26.6   \n",
       "3  734.0 -21.780560 -47.075280   0.0  933.2  933.2  932.5  20.5  19.3  20.6   \n",
       "4  997.0 -17.561349 -47.199251   0.0  904.2  904.2  904.0  20.8  15.6  21.2   \n",
       "\n",
       "    ...    stp_3  smin_1  smin_2  smin_3  dmin_1  dmin_2  dmin_3  dmax_1  \\\n",
       "0   ...    952.9   951.7   952.1   952.9    20.9    21.0    20.9    22.4   \n",
       "1   ...    947.7   947.2   947.6   947.6    19.6    19.3    19.1    21.8   \n",
       "2   ...    917.2   916.5   917.1   917.0    18.5    17.3    17.1    23.0   \n",
       "3   ...    931.1   931.9   931.1   930.9    19.1    19.0    17.5    20.3   \n",
       "4   ...    903.4   903.4   903.3   903.3    15.0    15.6    15.6    20.4   \n",
       "\n",
       "   dmax_2  dmax_3  \n",
       "0    23.0    23.5  \n",
       "1    22.2    22.5  \n",
       "2    21.9    20.4  \n",
       "3    20.4    20.2  \n",
       "4    21.7    23.5  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como o balanceamento SMOTE não serve valores continuos, eu criei classes de chuvas, \\\n",
    "#mas o objetivo ainda persiste em prever o volume de precipitação. Assim vou colocar como alvo a precipitação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Reconstruindo o datafram para alimnar o tensorflow</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train['prcp'] = X_train['prcp']\n",
    "y_tmp = X_tmp['prcp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.drop('type',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop('prcp',1)\n",
    "X_tmp = X_tmp.drop('prcp',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elvt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>dewp</th>\n",
       "      <th>...</th>\n",
       "      <th>stp_3</th>\n",
       "      <th>smin_1</th>\n",
       "      <th>smin_2</th>\n",
       "      <th>smin_3</th>\n",
       "      <th>dmin_1</th>\n",
       "      <th>dmin_2</th>\n",
       "      <th>dmin_3</th>\n",
       "      <th>dmax_1</th>\n",
       "      <th>dmax_2</th>\n",
       "      <th>dmax_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>704576</th>\n",
       "      <td>283.0</td>\n",
       "      <td>-21.104867</td>\n",
       "      <td>-42.375904</td>\n",
       "      <td>979.6</td>\n",
       "      <td>979.8</td>\n",
       "      <td>979.6</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>21.3</td>\n",
       "      <td>...</td>\n",
       "      <td>980.4</td>\n",
       "      <td>979.6</td>\n",
       "      <td>980.0</td>\n",
       "      <td>980.4</td>\n",
       "      <td>21.1</td>\n",
       "      <td>21.5</td>\n",
       "      <td>21.5</td>\n",
       "      <td>21.9</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403722</th>\n",
       "      <td>641.0</td>\n",
       "      <td>-16.554101</td>\n",
       "      <td>-46.881935</td>\n",
       "      <td>937.9</td>\n",
       "      <td>937.9</td>\n",
       "      <td>937.6</td>\n",
       "      <td>21.9</td>\n",
       "      <td>19.6</td>\n",
       "      <td>21.9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>...</td>\n",
       "      <td>937.3</td>\n",
       "      <td>937.5</td>\n",
       "      <td>937.3</td>\n",
       "      <td>937.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.3</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140621</th>\n",
       "      <td>367.0</td>\n",
       "      <td>-22.358094</td>\n",
       "      <td>-43.695656</td>\n",
       "      <td>975.7</td>\n",
       "      <td>975.8</td>\n",
       "      <td>975.6</td>\n",
       "      <td>25.7</td>\n",
       "      <td>20.9</td>\n",
       "      <td>26.1</td>\n",
       "      <td>21.5</td>\n",
       "      <td>...</td>\n",
       "      <td>975.1</td>\n",
       "      <td>975.3</td>\n",
       "      <td>975.1</td>\n",
       "      <td>974.7</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.2</td>\n",
       "      <td>19.8</td>\n",
       "      <td>22.8</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          elvt        lat        lon    stp   smax   smin  temp  tmax  tmin  \\\n",
       "704576   283.0 -21.104867 -42.375904  979.6  979.8  979.6  22.0  21.0  22.1   \n",
       "1403722  641.0 -16.554101 -46.881935  937.9  937.9  937.6  21.9  19.6  21.9   \n",
       "2140621  367.0 -22.358094 -43.695656  975.7  975.8  975.6  25.7  20.9  26.1   \n",
       "\n",
       "         dewp   ...    stp_3  smin_1  smin_2  smin_3  dmin_1  dmin_2  dmin_3  \\\n",
       "704576   21.3   ...    980.4   979.6   980.0   980.4    21.1    21.5    21.5   \n",
       "1403722  19.7   ...    937.3   937.5   937.3   937.2    19.3    19.4    19.3   \n",
       "2140621  21.5   ...    975.1   975.3   975.1   974.7    20.3    20.2    19.8   \n",
       "\n",
       "         dmax_1  dmax_2  dmax_3  \n",
       "704576     21.9    22.0    22.1  \n",
       "1403722    20.5    20.5    20.5  \n",
       "2140621    22.8    20.9    20.4  \n",
       "\n",
       "[3 rows x 63 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tmp.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Separando o conjunto de testes</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'prcp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_val, y_test, y_val = train_test_split(X_tmp, y_tmp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances   418330, Training features   63\n",
      "Validation instances 419685, Validation features 63\n",
      "Testing instances    419685, Testing features    63\n"
     ]
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_val.shape  \n",
    "print(\"Training instances   {}, Training features   {}\".format(X_train.shape[0], X_train.shape[1]))  \n",
    "print(\"Validation instances {}, Validation features {}\".format(X_val.shape[0], X_val.shape[1]))  \n",
    "print(\"Testing instances    {}, Testing features    {}\".format(X_test.shape[0], X_test.shape[1]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zarate instructions\n",
    "st_units = (X_train.shape[1] * 2) + 1\n",
    "sd_units = X_train.shape[1] \n",
    "#activation_fn = tf.sigmoid\n",
    "batch_size = 10000\n",
    "up = int(len(X_train)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [tf.feature_column.numeric_column(col) for col in X_train.columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f40502756d0>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tf_wx_model-20', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.estimator.DNNRegressor(feature_columns=feature_cols,  \n",
    "                                      hidden_units=[st_units,sd_units],\n",
    "                                     # activation_fn=activation_fn,\n",
    "                                      model_dir='/tmp/tf_wx_model-20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wx_input_fn(X, y=None, num_epochs=None, shuffle=True, batch_size=batch_size):  \n",
    "    return tf.estimator.inputs.pandas_input_fn(x=X,\n",
    "                                               y=y,\n",
    "                                               num_epochs=num_epochs,\n",
    "                                               shuffle=shuffle,\n",
    "                                               batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 257953500.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1.75273\n",
      "INFO:tensorflow:loss = 185197.98, step = 101 (57.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.76548\n",
      "INFO:tensorflow:loss = 334205.12, step = 201 (56.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.74353\n",
      "INFO:tensorflow:loss = 86480.55, step = 301 (57.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.7469\n",
      "INFO:tensorflow:loss = 273508.16, step = 401 (57.245 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 281671.34.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-21:27:31\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-21:27:52\n",
      "INFO:tensorflow:Saving dict for global step 500: average_loss = 15.901667, global_step = 500, loss = 158897.4\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-500\n",
      "INFO:tensorflow:Saving checkpoints for 501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 252587.5, step = 501\n",
      "INFO:tensorflow:global_step/sec: 1.76679\n",
      "INFO:tensorflow:loss = 80531.516, step = 601 (56.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.76638\n",
      "INFO:tensorflow:loss = 52014.85, step = 701 (56.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.77011\n",
      "INFO:tensorflow:loss = 254412.83, step = 801 (56.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.76743\n",
      "INFO:tensorflow:loss = 41315.78, step = 901 (56.579 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 231888.53.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-21:32:39\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-21:33:00\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 12.32026, global_step = 1000, loss = 123110.2\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-1000\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 237079.22, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 1.75887\n",
      "INFO:tensorflow:loss = 249773.12, step = 1101 (56.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.76639\n",
      "INFO:tensorflow:loss = 34620.656, step = 1201 (56.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.7664\n",
      "INFO:tensorflow:loss = 234705.9, step = 1301 (56.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.76505\n",
      "INFO:tensorflow:loss = 32575.766, step = 1401 (56.655 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 31404.379.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-21:37:47\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-1500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-21:38:08\n",
      "INFO:tensorflow:Saving dict for global step 1500: average_loss = 6.148015, global_step = 1500, loss = 61434.043\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-1500\n",
      "INFO:tensorflow:Saving checkpoints for 1501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 324140.75, step = 1501\n",
      "INFO:tensorflow:global_step/sec: 1.76956\n",
      "INFO:tensorflow:loss = 30187.62, step = 1601 (56.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.77172\n",
      "INFO:tensorflow:loss = 227052.72, step = 1701 (56.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.77412\n",
      "INFO:tensorflow:loss = 233452.72, step = 1801 (56.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.77146\n",
      "INFO:tensorflow:loss = 28270.758, step = 1901 (56.451 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 211273.94.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-21:42:54\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-21:43:15\n",
      "INFO:tensorflow:Saving dict for global step 2000: average_loss = 10.557972, global_step = 2000, loss = 105500.54\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-2000\n",
      "INFO:tensorflow:Saving checkpoints for 2001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 89209.84, step = 2001\n",
      "INFO:tensorflow:global_step/sec: 1.758\n",
      "INFO:tensorflow:loss = 26928.273, step = 2101 (56.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.77873\n",
      "INFO:tensorflow:loss = 217818.55, step = 2201 (56.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.75419\n",
      "INFO:tensorflow:loss = 25630.484, step = 2301 (57.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.77184\n",
      "INFO:tensorflow:loss = 222951.17, step = 2401 (56.438 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 123584.7.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-21:48:02\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-2500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-21:48:24\n",
      "INFO:tensorflow:Saving dict for global step 2500: average_loss = 5.4078183, global_step = 2500, loss = 54037.625\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-2500\n",
      "INFO:tensorflow:Saving checkpoints for 2501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 26841.523, step = 2501\n",
      "INFO:tensorflow:global_step/sec: 1.75103\n",
      "INFO:tensorflow:loss = 218681.19, step = 2601 (57.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.75597\n",
      "INFO:tensorflow:loss = 23655.92, step = 2701 (56.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.76387\n",
      "INFO:tensorflow:loss = 23581.27, step = 2801 (56.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.7466\n",
      "INFO:tensorflow:loss = 205306.66, step = 2901 (57.254 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 22720.69.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-21:53:12\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-3000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-21:53:34\n",
      "INFO:tensorflow:Saving dict for global step 3000: average_loss = 5.208531, global_step = 3000, loss = 52046.242\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-3000\n",
      "INFO:tensorflow:Saving checkpoints for 3001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 275468.47, step = 3001\n",
      "INFO:tensorflow:global_step/sec: 1.76212\n",
      "INFO:tensorflow:loss = 22064.594, step = 3101 (56.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.76369\n",
      "INFO:tensorflow:loss = 213621.28, step = 3201 (56.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.77567\n",
      "INFO:tensorflow:loss = 21868.002, step = 3301 (56.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.75868\n",
      "INFO:tensorflow:loss = 21564.047, step = 3401 (56.861 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 240384.78.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-21:58:21\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-3500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-21:58:42\n",
      "INFO:tensorflow:Saving dict for global step 3500: average_loss = 10.170099, global_step = 3500, loss = 101624.71\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-3500\n",
      "INFO:tensorflow:Saving checkpoints for 3501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 229616.92, step = 3501\n",
      "INFO:tensorflow:global_step/sec: 1.75711\n",
      "INFO:tensorflow:loss = 19965.379, step = 3601 (56.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.77318\n",
      "INFO:tensorflow:loss = 214321.2, step = 3701 (56.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.783\n",
      "INFO:tensorflow:loss = 19210.46, step = 3801 (56.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81819\n",
      "INFO:tensorflow:loss = 19508.69, step = 3901 (54.999 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into /tmp/tf_wx_model-20/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 237638.72.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-22:03:25\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-4000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-22:03:46\n",
      "INFO:tensorflow:Saving dict for global step 4000: average_loss = 9.577404, global_step = 4000, loss = 95702.21\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-4000\n",
      "INFO:tensorflow:Saving checkpoints for 4001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 159436.56, step = 4001\n",
      "INFO:tensorflow:global_step/sec: 1.82177\n",
      "INFO:tensorflow:loss = 17737.664, step = 4101 (54.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82508\n",
      "INFO:tensorflow:loss = 219206.1, step = 4201 (54.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83166\n",
      "INFO:tensorflow:loss = 17358.992, step = 4301 (54.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81436\n",
      "INFO:tensorflow:loss = 211979.84, step = 4401 (55.116 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 236533.16.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-22:08:25\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-4500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-22:08:46\n",
      "INFO:tensorflow:Saving dict for global step 4500: average_loss = 9.682644, global_step = 4500, loss = 96753.82\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-4500\n",
      "INFO:tensorflow:Saving checkpoints for 4501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 80873.39, step = 4501\n",
      "INFO:tensorflow:global_step/sec: 1.80742\n",
      "INFO:tensorflow:loss = 17359.84, step = 4601 (55.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82032\n",
      "INFO:tensorflow:loss = 196705.1, step = 4701 (54.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80648\n",
      "INFO:tensorflow:loss = 16598.625, step = 4801 (55.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82574\n",
      "INFO:tensorflow:loss = 211205.1, step = 4901 (54.772 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 146669.4.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-22:13:26\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-5000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-22:13:47\n",
      "INFO:tensorflow:Saving dict for global step 5000: average_loss = 5.12217, global_step = 5000, loss = 51183.285\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-5000\n",
      "INFO:tensorflow:Saving checkpoints for 5001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 27947.645, step = 5001\n",
      "INFO:tensorflow:global_step/sec: 1.83875\n",
      "INFO:tensorflow:loss = 214645.61, step = 5101 (54.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82796\n",
      "INFO:tensorflow:loss = 15033.027, step = 5201 (54.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83357\n",
      "INFO:tensorflow:loss = 205478.53, step = 5301 (54.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8272\n",
      "INFO:tensorflow:loss = 214448.72, step = 5401 (54.728 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 14825.875.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-22:18:24\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-5500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-22:18:45\n",
      "INFO:tensorflow:Saving dict for global step 5500: average_loss = 4.418219, global_step = 5500, loss = 44149.055\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-5500\n",
      "INFO:tensorflow:Saving checkpoints for 5501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 285119.38, step = 5501\n",
      "INFO:tensorflow:global_step/sec: 1.80538\n",
      "INFO:tensorflow:loss = 15005.205, step = 5601 (55.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83371\n",
      "INFO:tensorflow:loss = 236027.67, step = 5701 (54.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82013\n",
      "INFO:tensorflow:loss = 208830.4, step = 5801 (54.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80968\n",
      "INFO:tensorflow:loss = 13982.027, step = 5901 (55.258 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 229577.77.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-22:23:24\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-6000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-22:23:45\n",
      "INFO:tensorflow:Saving dict for global step 6000: average_loss = 8.961094, global_step = 6000, loss = 89543.734\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-6000\n",
      "INFO:tensorflow:Saving checkpoints for 6001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 240402.1, step = 6001\n",
      "INFO:tensorflow:global_step/sec: 1.82448\n",
      "INFO:tensorflow:loss = 189127.34, step = 6101 (54.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82107\n",
      "INFO:tensorflow:loss = 13495.452, step = 6201 (54.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82095\n",
      "INFO:tensorflow:loss = 232511.75, step = 6301 (54.916 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81803\n",
      "INFO:tensorflow:loss = 13252.005, step = 6401 (55.005 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 190874.52.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-22:28:24\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-6500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-22:28:45\n",
      "INFO:tensorflow:Saving dict for global step 6500: average_loss = 8.417417, global_step = 6500, loss = 84111.04\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-6500\n",
      "INFO:tensorflow:Saving checkpoints for 6501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 67167.69, step = 6501\n",
      "INFO:tensorflow:global_step/sec: 1.81285\n",
      "INFO:tensorflow:loss = 223846.1, step = 6601 (55.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83527\n",
      "INFO:tensorflow:loss = 13089.086, step = 6701 (54.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83744\n",
      "INFO:tensorflow:loss = 220188.84, step = 6801 (54.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8262\n",
      "INFO:tensorflow:loss = 128708.5, step = 6901 (54.758 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 12485.757.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-22:33:23\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-7000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-22:33:44\n",
      "INFO:tensorflow:Saving dict for global step 7000: average_loss = 4.1406565, global_step = 7000, loss = 41375.51\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-7000\n",
      "INFO:tensorflow:Saving checkpoints for 7001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 280225.12, step = 7001\n",
      "INFO:tensorflow:global_step/sec: 1.83108\n",
      "INFO:tensorflow:loss = 12497.291, step = 7101 (54.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82282\n",
      "INFO:tensorflow:loss = 222069.53, step = 7201 (54.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81954\n",
      "INFO:tensorflow:loss = 203482.28, step = 7301 (54.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8405\n",
      "INFO:tensorflow:loss = 12148.285, step = 7401 (54.334 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 223389.53.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-22:38:21\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-7500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-22:38:42\n",
      "INFO:tensorflow:Saving dict for global step 7500: average_loss = 8.554747, global_step = 7500, loss = 85483.305\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-7500\n",
      "INFO:tensorflow:Saving checkpoints for 7501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 68881.22, step = 7501\n",
      "INFO:tensorflow:global_step/sec: 1.83302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 220660.89, step = 7601 (54.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.84361\n",
      "INFO:tensorflow:loss = 201207.4, step = 7701 (54.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83658\n",
      "INFO:tensorflow:loss = 11712.539, step = 7801 (54.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81423\n",
      "INFO:tensorflow:loss = 225377.11, step = 7901 (55.120 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 11701.068.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-22:43:19\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-8000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-22:43:41\n",
      "INFO:tensorflow:Saving dict for global step 8000: average_loss = 4.0182004, global_step = 8000, loss = 40151.867\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-8000\n",
      "INFO:tensorflow:Saving checkpoints for 8001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 12068.021, step = 8001\n",
      "INFO:tensorflow:global_step/sec: 1.8381\n",
      "INFO:tensorflow:loss = 203663.66, step = 8101 (54.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81178\n",
      "INFO:tensorflow:loss = 11200.867, step = 8201 (55.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81901\n",
      "INFO:tensorflow:loss = 200057.5, step = 8301 (54.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83168\n",
      "INFO:tensorflow:loss = 211522.22, step = 8401 (54.595 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 11231.727.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-22:48:18\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-8500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-22:48:39\n",
      "INFO:tensorflow:Saving dict for global step 8500: average_loss = 3.9777088, global_step = 8500, loss = 39747.258\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-8500\n",
      "INFO:tensorflow:Saving checkpoints for 8501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 275948.22, step = 8501\n",
      "INFO:tensorflow:global_step/sec: 1.83651\n",
      "INFO:tensorflow:loss = 128528.72, step = 8601 (54.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82316\n",
      "INFO:tensorflow:loss = 10968.921, step = 8701 (54.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81877\n",
      "INFO:tensorflow:loss = 209109.66, step = 8801 (54.982 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83431\n",
      "INFO:tensorflow:loss = 10958.516, step = 8901 (54.516 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 195372.7.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-22:53:16\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-9000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-22:53:37\n",
      "INFO:tensorflow:Saving dict for global step 9000: average_loss = 7.6919165, global_step = 9000, loss = 76861.48\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-9000\n",
      "INFO:tensorflow:Saving checkpoints for 9001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 197430.8, step = 9001\n",
      "INFO:tensorflow:global_step/sec: 1.8268\n",
      "INFO:tensorflow:loss = 10902.763, step = 9101 (54.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83042\n",
      "INFO:tensorflow:loss = 200747.33, step = 9201 (54.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83301\n",
      "INFO:tensorflow:loss = 51459.586, step = 9301 (54.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83534\n",
      "INFO:tensorflow:loss = 10990.927, step = 9401 (54.486 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 222915.69.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-22:58:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-9500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-22:58:36\n",
      "INFO:tensorflow:Saving dict for global step 9500: average_loss = 8.030368, global_step = 9500, loss = 80243.445\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-9500\n",
      "INFO:tensorflow:Saving checkpoints for 9501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 205788.75, step = 9501\n",
      "INFO:tensorflow:global_step/sec: 1.83757\n",
      "INFO:tensorflow:loss = 212622.81, step = 9601 (54.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83828\n",
      "INFO:tensorflow:loss = 10454.949, step = 9701 (54.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.84178\n",
      "INFO:tensorflow:loss = 223248.4, step = 9801 (54.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.84911\n",
      "INFO:tensorflow:loss = 10349.799, step = 9901 (54.081 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 224772.5.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-23:03:11\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-23:03:32\n",
      "INFO:tensorflow:Saving dict for global step 10000: average_loss = 7.141992, global_step = 10000, loss = 71366.36\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-10000\n",
      "INFO:tensorflow:Saving checkpoints for 10001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 223843.69, step = 10001\n",
      "INFO:tensorflow:global_step/sec: 1.81126\n",
      "INFO:tensorflow:loss = 201386.12, step = 10101 (55.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80984\n",
      "INFO:tensorflow:loss = 10109.281, step = 10201 (55.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80594\n",
      "INFO:tensorflow:loss = 212856.53, step = 10301 (55.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8095\n",
      "INFO:tensorflow:loss = 10148.354, step = 10401 (55.264 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 190380.4.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-23:08:12\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-10500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-23:08:33\n",
      "INFO:tensorflow:Saving dict for global step 10500: average_loss = 7.7833633, global_step = 10500, loss = 77775.26\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-10500\n",
      "INFO:tensorflow:Saving checkpoints for 10501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 194394.33, step = 10501\n",
      "INFO:tensorflow:global_step/sec: 1.82855\n",
      "INFO:tensorflow:loss = 34014.76, step = 10601 (54.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83527\n",
      "INFO:tensorflow:loss = 10327.823, step = 10701 (54.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.84213\n",
      "INFO:tensorflow:loss = 206678.31, step = 10801 (54.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8464\n",
      "INFO:tensorflow:loss = 9619.254, step = 10901 (54.159 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 199053.52.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-23:13:09\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-11000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-23:13:30\n",
      "INFO:tensorflow:Saving dict for global step 11000: average_loss = 7.71305, global_step = 11000, loss = 77072.65\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-11000\n",
      "INFO:tensorflow:Saving checkpoints for 11001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 59981.883, step = 11001\n",
      "INFO:tensorflow:global_step/sec: 1.80677\n",
      "INFO:tensorflow:loss = 201727.1, step = 11101 (55.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83452\n",
      "INFO:tensorflow:loss = 39132.387, step = 11201 (54.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8095\n",
      "INFO:tensorflow:loss = 10173.94, step = 11301 (55.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83106\n",
      "INFO:tensorflow:loss = 204017.39, step = 11401 (54.613 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9456.459.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-23:18:09\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-11500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-02-19-23:18:30\n",
      "INFO:tensorflow:Saving dict for global step 11500: average_loss = 3.7260513, global_step = 11500, loss = 37232.57\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-11500\n",
      "INFO:tensorflow:Saving checkpoints for 11501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 9991.637, step = 11501\n",
      "INFO:tensorflow:global_step/sec: 1.83494\n",
      "INFO:tensorflow:loss = 223269.38, step = 11601 (54.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83389\n",
      "INFO:tensorflow:loss = 9782.205, step = 11701 (54.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.84381\n",
      "INFO:tensorflow:loss = 219692.94, step = 11801 (54.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8446\n",
      "INFO:tensorflow:loss = 145165.55, step = 11901 (54.213 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9468.359.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-23:23:06\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-12000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-23:23:27\n",
      "INFO:tensorflow:Saving dict for global step 12000: average_loss = 3.7015011, global_step = 12000, loss = 36987.25\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-12000\n",
      "INFO:tensorflow:Saving checkpoints for 12001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 277248.3, step = 12001\n",
      "INFO:tensorflow:global_step/sec: 1.83834\n",
      "INFO:tensorflow:loss = 9636.385, step = 12101 (54.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.85113\n",
      "INFO:tensorflow:loss = 228858.55, step = 12201 (54.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83467\n",
      "INFO:tensorflow:loss = 164679.72, step = 12301 (54.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.84793\n",
      "INFO:tensorflow:loss = 9212.021, step = 12401 (54.114 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 226853.2.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-23:28:02\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-12500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-23:28:23\n",
      "INFO:tensorflow:Saving dict for global step 12500: average_loss = 7.630326, global_step = 12500, loss = 76246.03\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-12500\n",
      "INFO:tensorflow:Saving checkpoints for 12501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 59935.266, step = 12501\n",
      "INFO:tensorflow:global_step/sec: 1.83191\n",
      "INFO:tensorflow:loss = 222615.38, step = 12601 (54.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.85296\n",
      "INFO:tensorflow:loss = 9426.103, step = 12701 (53.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.84916\n",
      "INFO:tensorflow:loss = 228428.61, step = 12801 (54.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.84256\n",
      "INFO:tensorflow:loss = 160416.73, step = 12901 (54.272 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9005.385.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-23:32:58\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-13000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-23:33:19\n",
      "INFO:tensorflow:Saving dict for global step 13000: average_loss = 3.6468503, global_step = 13000, loss = 36441.152\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-13000\n",
      "INFO:tensorflow:Saving checkpoints for 13001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 9440.558, step = 13001\n",
      "INFO:tensorflow:global_step/sec: 1.80506\n",
      "INFO:tensorflow:loss = 190310.66, step = 13101 (55.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.84829\n",
      "INFO:tensorflow:loss = 9289.742, step = 13201 (54.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.84238\n",
      "INFO:tensorflow:loss = 191686.58, step = 13301 (54.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83742\n",
      "INFO:tensorflow:loss = 9313.937, step = 13401 (54.424 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9277.178.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-23:37:55\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-13500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-23:38:17\n",
      "INFO:tensorflow:Saving dict for global step 13500: average_loss = 3.626685, global_step = 13500, loss = 36239.65\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-13500\n",
      "INFO:tensorflow:Saving checkpoints for 13501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 9123.766, step = 13501\n",
      "INFO:tensorflow:global_step/sec: 1.82735\n",
      "INFO:tensorflow:loss = 9100.471, step = 13601 (54.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82113\n",
      "INFO:tensorflow:loss = 187719.38, step = 13701 (54.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82595\n",
      "INFO:tensorflow:loss = 8945.687, step = 13801 (54.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82973\n",
      "INFO:tensorflow:loss = 193398.69, step = 13901 (54.652 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 62713.395.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-23:42:54\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-14000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-23:43:16\n",
      "INFO:tensorflow:Saving dict for global step 14000: average_loss = 3.646839, global_step = 14000, loss = 36441.04\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-14000\n",
      "INFO:tensorflow:Saving checkpoints for 14001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 9012.934, step = 14001\n",
      "INFO:tensorflow:global_step/sec: 1.82771\n",
      "INFO:tensorflow:loss = 214935.05, step = 14101 (54.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82482\n",
      "INFO:tensorflow:loss = 8549.735, step = 14201 (54.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83571\n",
      "INFO:tensorflow:loss = 191808.86, step = 14301 (54.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8316\n",
      "INFO:tensorflow:loss = 202078.33, step = 14401 (54.597 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8677.047.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-23:47:53\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-14500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-23:48:14\n",
      "INFO:tensorflow:Saving dict for global step 14500: average_loss = 3.586687, global_step = 14500, loss = 35839.97\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-14500\n",
      "INFO:tensorflow:Saving checkpoints for 14501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 9058.469, step = 14501\n",
      "INFO:tensorflow:global_step/sec: 1.82451\n",
      "INFO:tensorflow:loss = 182384.69, step = 14601 (54.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82225\n",
      "INFO:tensorflow:loss = 8957.379, step = 14701 (54.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.84375\n",
      "INFO:tensorflow:loss = 8771.412, step = 14801 (54.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82184\n",
      "INFO:tensorflow:loss = 199227.89, step = 14901 (54.889 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8618.179.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-23:52:52\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-15000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-23:53:13\n",
      "INFO:tensorflow:Saving dict for global step 15000: average_loss = 3.5562785, global_step = 15000, loss = 35536.113\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-15000\n",
      "INFO:tensorflow:Saving checkpoints for 15001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 265096.84, step = 15001\n",
      "INFO:tensorflow:global_step/sec: 1.83421\n",
      "INFO:tensorflow:loss = 8751.084, step = 15101 (54.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 179891.02, step = 15201 (55.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83972\n",
      "INFO:tensorflow:loss = 8843.592, step = 15301 (54.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83993\n",
      "INFO:tensorflow:loss = 8587.682, step = 15401 (54.350 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 183846.94.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-19-23:57:50\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-15500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-19-23:58:11\n",
      "INFO:tensorflow:Saving dict for global step 15500: average_loss = 6.9731035, global_step = 15500, loss = 69678.734\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-15500\n",
      "INFO:tensorflow:Saving checkpoints for 15501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 207380.48, step = 15501\n",
      "INFO:tensorflow:global_step/sec: 1.83969\n",
      "INFO:tensorflow:loss = 8818.525, step = 15601 (54.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.86494\n",
      "INFO:tensorflow:loss = 182345.55, step = 15701 (53.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.86893\n",
      "INFO:tensorflow:loss = 8546.586, step = 15801 (53.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.85\n",
      "INFO:tensorflow:loss = 8561.559, step = 15901 (54.055 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 182958.97.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-00:02:45\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-16000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-00:03:06\n",
      "INFO:tensorflow:Saving dict for global step 16000: average_loss = 6.940877, global_step = 16000, loss = 69356.71\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-16000\n",
      "INFO:tensorflow:Saving checkpoints for 16001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 204808.11, step = 16001\n",
      "INFO:tensorflow:global_step/sec: 1.79828\n",
      "INFO:tensorflow:loss = 8673.455, step = 16101 (55.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81501\n",
      "INFO:tensorflow:loss = 171001.86, step = 16201 (55.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80037\n",
      "INFO:tensorflow:loss = 8367.831, step = 16301 (55.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81421\n",
      "INFO:tensorflow:loss = 8529.668, step = 16401 (55.121 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 215907.16.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-00:07:46\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-16500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-00:08:07\n",
      "INFO:tensorflow:Saving dict for global step 16500: average_loss = 7.087952, global_step = 16500, loss = 70826.36\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-16500\n",
      "INFO:tensorflow:Saving checkpoints for 16501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 223553.25, step = 16501\n",
      "INFO:tensorflow:global_step/sec: 1.8105\n",
      "INFO:tensorflow:loss = 8175.7866, step = 16601 (55.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80411\n",
      "INFO:tensorflow:loss = 208469.98, step = 16701 (55.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81584\n",
      "INFO:tensorflow:loss = 192317.56, step = 16801 (55.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81653\n",
      "INFO:tensorflow:loss = 8143.093, step = 16901 (55.050 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 205912.12.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-00:12:47\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-17000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-00:13:08\n",
      "INFO:tensorflow:Saving dict for global step 17000: average_loss = 7.1385164, global_step = 17000, loss = 71331.625\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-17000\n",
      "INFO:tensorflow:Saving checkpoints for 17001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 209764.83, step = 17001\n",
      "INFO:tensorflow:global_step/sec: 1.7951\n",
      "INFO:tensorflow:loss = 8264.98, step = 17101 (55.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79936\n",
      "INFO:tensorflow:loss = 239594.88, step = 17201 (55.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79819\n",
      "INFO:tensorflow:loss = 200959.7, step = 17301 (55.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80525\n",
      "INFO:tensorflow:loss = 8287.859, step = 17401 (55.394 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 173290.22.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-00:17:50\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-17500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-00:18:11\n",
      "INFO:tensorflow:Saving dict for global step 17500: average_loss = 6.7597322, global_step = 17500, loss = 67546.625\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-17500\n",
      "INFO:tensorflow:Saving checkpoints for 17501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 205228.66, step = 17501\n",
      "INFO:tensorflow:global_step/sec: 1.84474\n",
      "INFO:tensorflow:loss = 8196.648, step = 17601 (54.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82764\n",
      "INFO:tensorflow:loss = 186103.03, step = 17701 (54.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83899\n",
      "INFO:tensorflow:loss = 8207.829, step = 17801 (54.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8441\n",
      "INFO:tensorflow:loss = 8194.16, step = 17901 (54.227 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 205533.17.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-00:22:46\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-18000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-00:23:07\n",
      "INFO:tensorflow:Saving dict for global step 18000: average_loss = 6.9195437, global_step = 18000, loss = 69143.54\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-18000\n",
      "INFO:tensorflow:Saving checkpoints for 18001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 52723.625, step = 18001\n",
      "INFO:tensorflow:global_step/sec: 1.79634\n",
      "INFO:tensorflow:loss = 8193.949, step = 18101 (55.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80003\n",
      "INFO:tensorflow:loss = 224880.56, step = 18201 (55.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79928\n",
      "INFO:tensorflow:loss = 8186.0454, step = 18301 (55.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.77637\n",
      "INFO:tensorflow:loss = 221114.53, step = 18401 (56.295 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 195899.47.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-00:27:50\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-18500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-00:28:10\n",
      "INFO:tensorflow:Saving dict for global step 18500: average_loss = 6.9979205, global_step = 18500, loss = 69926.72\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-18500\n",
      "INFO:tensorflow:Saving checkpoints for 18501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 180048.1, step = 18501\n",
      "INFO:tensorflow:global_step/sec: 1.79905\n",
      "INFO:tensorflow:loss = 7888.292, step = 18601 (55.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79353\n",
      "INFO:tensorflow:loss = 192286.64, step = 18701 (55.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80412\n",
      "INFO:tensorflow:loss = 25411.451, step = 18801 (55.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79409\n",
      "INFO:tensorflow:loss = 8134.594, step = 18901 (55.738 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 199107.08.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-00:32:52\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-19000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-00:33:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 19000: average_loss = 6.776653, global_step = 19000, loss = 67715.7\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-19000\n",
      "INFO:tensorflow:Saving checkpoints for 19001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 199437.66, step = 19001\n",
      "INFO:tensorflow:global_step/sec: 1.80558\n",
      "INFO:tensorflow:loss = 7821.4863, step = 19101 (55.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80895\n",
      "INFO:tensorflow:loss = 211439.53, step = 19201 (55.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80565\n",
      "INFO:tensorflow:loss = 7842.753, step = 19301 (55.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79943\n",
      "INFO:tensorflow:loss = 200674.08, step = 19401 (55.573 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 208444.58.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-00:37:52\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-19500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-00:38:13\n",
      "INFO:tensorflow:Saving dict for global step 19500: average_loss = 6.783027, global_step = 19500, loss = 67779.4\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-19500\n",
      "INFO:tensorflow:Saving checkpoints for 19501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 148963.72, step = 19501\n",
      "INFO:tensorflow:global_step/sec: 1.80778\n",
      "INFO:tensorflow:loss = 7624.8135, step = 19601 (55.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80116\n",
      "INFO:tensorflow:loss = 202231.25, step = 19701 (55.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81348\n",
      "INFO:tensorflow:loss = 7686.901, step = 19801 (55.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79568\n",
      "INFO:tensorflow:loss = 197233.31, step = 19901 (55.689 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 212179.3.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-00:42:54\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-20000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-00:43:14\n",
      "INFO:tensorflow:Saving dict for global step 20000: average_loss = 7.018353, global_step = 20000, loss = 70130.89\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-20000\n",
      "INFO:tensorflow:Saving checkpoints for 20001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 217008.45, step = 20001\n",
      "INFO:tensorflow:global_step/sec: 1.78761\n",
      "INFO:tensorflow:loss = 7976.417, step = 20101 (55.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79047\n",
      "INFO:tensorflow:loss = 223062.88, step = 20201 (55.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.78163\n",
      "INFO:tensorflow:loss = 163143.22, step = 20301 (56.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.7957\n",
      "INFO:tensorflow:loss = 7569.9067, step = 20401 (55.689 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 226898.44.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-00:47:57\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-20500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-00:48:17\n",
      "INFO:tensorflow:Saving dict for global step 20500: average_loss = 6.8556633, global_step = 20500, loss = 68505.21\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-20500\n",
      "INFO:tensorflow:Saving checkpoints for 20501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 52310.844, step = 20501\n",
      "INFO:tensorflow:global_step/sec: 1.82186\n",
      "INFO:tensorflow:loss = 7841.5645, step = 20601 (54.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82599\n",
      "INFO:tensorflow:loss = 212291.38, step = 20701 (54.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82453\n",
      "INFO:tensorflow:loss = 7879.405, step = 20801 (54.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81747\n",
      "INFO:tensorflow:loss = 214309.94, step = 20901 (55.022 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 200725.56.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-00:52:55\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-21000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-00:53:16\n",
      "INFO:tensorflow:Saving dict for global step 21000: average_loss = 6.8378754, global_step = 21000, loss = 68327.47\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-21000\n",
      "INFO:tensorflow:Saving checkpoints for 21001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 51450.14, step = 21001\n",
      "INFO:tensorflow:global_step/sec: 1.79971\n",
      "INFO:tensorflow:loss = 221214.16, step = 21101 (55.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8211\n",
      "INFO:tensorflow:loss = 7704.115, step = 21201 (54.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81163\n",
      "INFO:tensorflow:loss = 174787.69, step = 21301 (55.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81197\n",
      "INFO:tensorflow:loss = 213201.47, step = 21401 (55.188 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7724.0557.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-00:57:55\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-21500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-00:58:16\n",
      "INFO:tensorflow:Saving dict for global step 21500: average_loss = 3.3624725, global_step = 21500, loss = 33599.508\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-21500\n",
      "INFO:tensorflow:Saving checkpoints for 21501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 7669.2627, step = 21501\n",
      "INFO:tensorflow:global_step/sec: 1.81107\n",
      "INFO:tensorflow:loss = 219282.39, step = 21601 (55.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80482\n",
      "INFO:tensorflow:loss = 7660.7705, step = 21701 (55.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81216\n",
      "INFO:tensorflow:loss = 213101.97, step = 21801 (55.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79327\n",
      "INFO:tensorflow:loss = 134616.06, step = 21901 (55.764 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7368.5835.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-01:02:56\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-22000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-01:03:17\n",
      "INFO:tensorflow:Saving dict for global step 22000: average_loss = 3.3488407, global_step = 22000, loss = 33463.293\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-22000\n",
      "INFO:tensorflow:Saving checkpoints for 22001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 261805.27, step = 22001\n",
      "INFO:tensorflow:global_step/sec: 1.78798\n",
      "INFO:tensorflow:loss = 154187.4, step = 22101 (55.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80447\n",
      "INFO:tensorflow:loss = 7413.5986, step = 22201 (55.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79757\n",
      "INFO:tensorflow:loss = 212714.95, step = 22301 (55.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.77009\n",
      "INFO:tensorflow:loss = 7300.375, step = 22401 (56.494 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 171746.95.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-01:07:59\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-22500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-01:08:20\n",
      "INFO:tensorflow:Saving dict for global step 22500: average_loss = 6.1518006, global_step = 22500, loss = 61471.867\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-22500\n",
      "INFO:tensorflow:Saving checkpoints for 22501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 44226.164, step = 22501\n",
      "INFO:tensorflow:global_step/sec: 1.80279\n",
      "INFO:tensorflow:loss = 187300.31, step = 22601 (55.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79926\n",
      "INFO:tensorflow:loss = 7569.7607, step = 22701 (55.578 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.82353\n",
      "INFO:tensorflow:loss = 7403.695, step = 22801 (54.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81269\n",
      "INFO:tensorflow:loss = 193537.19, step = 22901 (55.167 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7437.025.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-01:13:00\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-23000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-01:13:20\n",
      "INFO:tensorflow:Saving dict for global step 23000: average_loss = 3.3217878, global_step = 23000, loss = 33192.965\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-23000\n",
      "INFO:tensorflow:Saving checkpoints for 23001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 214887.34, step = 23001\n",
      "INFO:tensorflow:global_step/sec: 1.82744\n",
      "INFO:tensorflow:loss = 214093.53, step = 23101 (54.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80193\n",
      "INFO:tensorflow:loss = 7710.6562, step = 23201 (55.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82404\n",
      "INFO:tensorflow:loss = 185402.73, step = 23301 (54.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82355\n",
      "INFO:tensorflow:loss = 7513.5977, step = 23401 (54.838 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7509.1245.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-01:17:59\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-23500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-01:18:19\n",
      "INFO:tensorflow:Saving dict for global step 23500: average_loss = 3.312385, global_step = 23500, loss = 33099.008\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-23500\n",
      "INFO:tensorflow:Saving checkpoints for 23501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 7239.6963, step = 23501\n",
      "INFO:tensorflow:global_step/sec: 1.81616\n",
      "INFO:tensorflow:loss = 7488.544, step = 23601 (55.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80247\n",
      "INFO:tensorflow:loss = 181023.1, step = 23701 (55.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80621\n",
      "INFO:tensorflow:loss = 7322.84, step = 23801 (55.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80346\n",
      "INFO:tensorflow:loss = 190493.83, step = 23901 (55.450 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 165209.62.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-01:22:59\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-24000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-01:23:19\n",
      "INFO:tensorflow:Saving dict for global step 24000: average_loss = 5.011866, global_step = 24000, loss = 50081.07\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-24000\n",
      "INFO:tensorflow:Saving checkpoints for 24001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 31189.709, step = 24001\n",
      "INFO:tensorflow:global_step/sec: 1.77756\n",
      "INFO:tensorflow:loss = 7537.9834, step = 24101 (56.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79861\n",
      "INFO:tensorflow:loss = 203579.05, step = 24201 (55.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79022\n",
      "INFO:tensorflow:loss = 7150.703, step = 24301 (55.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.77109\n",
      "INFO:tensorflow:loss = 203263.06, step = 24401 (56.461 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 202728.28.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-01:28:03\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-24500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-01:28:23\n",
      "INFO:tensorflow:Saving dict for global step 24500: average_loss = 6.612239, global_step = 24500, loss = 66072.8\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-24500\n",
      "INFO:tensorflow:Saving checkpoints for 24501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 49212.57, step = 24501\n",
      "INFO:tensorflow:global_step/sec: 1.80249\n",
      "INFO:tensorflow:loss = 214880.62, step = 24601 (55.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79703\n",
      "INFO:tensorflow:loss = 153147.98, step = 24701 (55.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81383\n",
      "INFO:tensorflow:loss = 7152.55, step = 24801 (55.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.78893\n",
      "INFO:tensorflow:loss = 199018.84, step = 24901 (55.899 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7256.0776.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-01:33:04\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-25000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-01:33:25\n",
      "INFO:tensorflow:Saving dict for global step 25000: average_loss = 3.2845943, global_step = 25000, loss = 32821.31\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-25000\n",
      "INFO:tensorflow:Saving checkpoints for 25001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 7354.6836, step = 25001\n",
      "INFO:tensorflow:global_step/sec: 1.78962\n",
      "INFO:tensorflow:loss = 7294.9043, step = 25101 (55.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80881\n",
      "INFO:tensorflow:loss = 210627.58, step = 25201 (55.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81167\n",
      "INFO:tensorflow:loss = 7017.2324, step = 25301 (55.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81511\n",
      "INFO:tensorflow:loss = 185921.53, step = 25401 (55.093 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 198995.6.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-01:38:05\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-25500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-01:38:25\n",
      "INFO:tensorflow:Saving dict for global step 25500: average_loss = 6.470377, global_step = 25500, loss = 64655.242\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-25500\n",
      "INFO:tensorflow:Saving checkpoints for 25501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 198510.22, step = 25501\n",
      "INFO:tensorflow:global_step/sec: 1.81098\n",
      "INFO:tensorflow:loss = 7178.0654, step = 25601 (55.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81221\n",
      "INFO:tensorflow:loss = 187175.48, step = 25701 (55.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81036\n",
      "INFO:tensorflow:loss = 200310.28, step = 25801 (55.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80469\n",
      "INFO:tensorflow:loss = 7040.9395, step = 25901 (55.410 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 176206.89.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-01:43:05\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-26000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-01:43:26\n",
      "INFO:tensorflow:Saving dict for global step 26000: average_loss = 6.069657, global_step = 26000, loss = 60651.047\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-26000\n",
      "INFO:tensorflow:Saving checkpoints for 26001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 43761.266, step = 26001\n",
      "INFO:tensorflow:global_step/sec: 1.78446\n",
      "INFO:tensorflow:loss = 198636.08, step = 26101 (56.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.7964\n",
      "INFO:tensorflow:loss = 191057.53, step = 26201 (55.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79615\n",
      "INFO:tensorflow:loss = 7007.623, step = 26301 (55.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.7847\n",
      "INFO:tensorflow:loss = 217355.31, step = 26401 (56.032 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7078.5117.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-01:48:08\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-26500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-01:48:29\n",
      "INFO:tensorflow:Saving dict for global step 26500: average_loss = 3.2630708, global_step = 26500, loss = 32606.234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-26500\n",
      "INFO:tensorflow:Saving checkpoints for 26501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 203325.22, step = 26501\n",
      "INFO:tensorflow:global_step/sec: 1.79215\n",
      "INFO:tensorflow:loss = 7112.6064, step = 26601 (55.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79219\n",
      "INFO:tensorflow:loss = 7136.355, step = 26701 (55.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8002\n",
      "INFO:tensorflow:loss = 207677.66, step = 26801 (55.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80283\n",
      "INFO:tensorflow:loss = 7194.5547, step = 26901 (55.468 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 201234.1.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-01:53:11\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-27000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-01:53:31\n",
      "INFO:tensorflow:Saving dict for global step 27000: average_loss = 6.311692, global_step = 27000, loss = 63069.582\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-27000\n",
      "INFO:tensorflow:Saving checkpoints for 27001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 195830.9, step = 27001\n",
      "INFO:tensorflow:global_step/sec: 1.7933\n",
      "INFO:tensorflow:loss = 7088.3916, step = 27101 (55.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80057\n",
      "INFO:tensorflow:loss = 190979.83, step = 27201 (55.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.7935\n",
      "INFO:tensorflow:loss = 44707.047, step = 27301 (55.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79816\n",
      "INFO:tensorflow:loss = 7077.883, step = 27401 (55.612 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 196320.72.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-01:58:13\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-27500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-01:58:34\n",
      "INFO:tensorflow:Saving dict for global step 27500: average_loss = 6.1983843, global_step = 27500, loss = 61937.355\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-27500\n",
      "INFO:tensorflow:Saving checkpoints for 27501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 181580.48, step = 27501\n",
      "INFO:tensorflow:global_step/sec: 1.82436\n",
      "INFO:tensorflow:loss = 7114.9634, step = 27601 (54.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82136\n",
      "INFO:tensorflow:loss = 6948.828, step = 27701 (54.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82872\n",
      "INFO:tensorflow:loss = 226264.6, step = 27801 (54.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83078\n",
      "INFO:tensorflow:loss = 7217.124, step = 27901 (54.621 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 193436.22.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-02:03:10\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-28000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-02:03:31\n",
      "INFO:tensorflow:Saving dict for global step 28000: average_loss = 6.2469673, global_step = 28000, loss = 62422.82\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-28000\n",
      "INFO:tensorflow:Saving checkpoints for 28001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 178235.38, step = 28001\n",
      "INFO:tensorflow:global_step/sec: 1.82037\n",
      "INFO:tensorflow:loss = 6925.189, step = 28101 (54.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82473\n",
      "INFO:tensorflow:loss = 7199.5728, step = 28201 (54.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80748\n",
      "INFO:tensorflow:loss = 176875.31, step = 28301 (55.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8186\n",
      "INFO:tensorflow:loss = 6908.696, step = 28401 (54.988 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 218177.14.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-02:08:10\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-28500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-02:08:30\n",
      "INFO:tensorflow:Saving dict for global step 28500: average_loss = 6.3797145, global_step = 28500, loss = 63749.297\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-28500\n",
      "INFO:tensorflow:Saving checkpoints for 28501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 176038.62, step = 28501\n",
      "INFO:tensorflow:global_step/sec: 1.81023\n",
      "INFO:tensorflow:loss = 203375.27, step = 28601 (55.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79879\n",
      "INFO:tensorflow:loss = 6941.917, step = 28701 (55.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83166\n",
      "INFO:tensorflow:loss = 174354.7, step = 28801 (54.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82163\n",
      "INFO:tensorflow:loss = 7029.106, step = 28901 (54.897 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7049.6465.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-02:13:08\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-29000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-02:13:29\n",
      "INFO:tensorflow:Saving dict for global step 29000: average_loss = 3.2207768, global_step = 29000, loss = 32183.613\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-29000\n",
      "INFO:tensorflow:Saving checkpoints for 29001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 212695.8, step = 29001\n",
      "INFO:tensorflow:global_step/sec: 1.82071\n",
      "INFO:tensorflow:loss = 6852.4014, step = 29101 (54.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82354\n",
      "INFO:tensorflow:loss = 7128.953, step = 29201 (54.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82889\n",
      "INFO:tensorflow:loss = 199394.19, step = 29301 (54.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81938\n",
      "INFO:tensorflow:loss = 6919.401, step = 29401 (54.964 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 214038.75.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-02:18:06\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-29500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-02:18:27\n",
      "INFO:tensorflow:Saving dict for global step 29500: average_loss = 6.363341, global_step = 29500, loss = 63585.684\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-29500\n",
      "INFO:tensorflow:Saving checkpoints for 29501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 119441.83, step = 29501\n",
      "INFO:tensorflow:global_step/sec: 1.82566\n",
      "INFO:tensorflow:loss = 204802.67, step = 29601 (54.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81957\n",
      "INFO:tensorflow:loss = 6732.282, step = 29701 (54.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82138\n",
      "INFO:tensorflow:loss = 177541.19, step = 29801 (54.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82702\n",
      "INFO:tensorflow:loss = 6800.907, step = 29901 (54.734 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6875.538.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-02:23:04\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-30000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-02:23:25\n",
      "INFO:tensorflow:Saving dict for global step 30000: average_loss = 3.2047703, global_step = 30000, loss = 32023.666\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-30000\n",
      "INFO:tensorflow:Saving checkpoints for 30001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 6640.673, step = 30001\n",
      "INFO:tensorflow:global_step/sec: 1.81328\n",
      "INFO:tensorflow:loss = 185848.34, step = 30101 (55.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82418\n",
      "INFO:tensorflow:loss = 195008.67, step = 30201 (54.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81666\n",
      "INFO:tensorflow:loss = 6822.607, step = 30301 (55.046 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.8284\n",
      "INFO:tensorflow:loss = 210187.61, step = 30401 (54.693 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6807.593.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-02:28:04\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-30500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-02:28:24\n",
      "INFO:tensorflow:Saving dict for global step 30500: average_loss = 3.2062075, global_step = 30500, loss = 32038.03\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-30500\n",
      "INFO:tensorflow:Saving checkpoints for 30501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 6704.102, step = 30501\n",
      "INFO:tensorflow:global_step/sec: 1.79933\n",
      "INFO:tensorflow:loss = 175757.6, step = 30601 (55.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80742\n",
      "INFO:tensorflow:loss = 6771.338, step = 30701 (55.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82005\n",
      "INFO:tensorflow:loss = 6994.6694, step = 30801 (54.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80921\n",
      "INFO:tensorflow:loss = 197862.9, step = 30901 (55.273 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 31000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7056.4414.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-02:33:04\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-31000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-02:33:24\n",
      "INFO:tensorflow:Saving dict for global step 31000: average_loss = 3.1917703, global_step = 31000, loss = 31893.766\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-31000\n",
      "INFO:tensorflow:Saving checkpoints for 31001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 6842.67, step = 31001\n",
      "INFO:tensorflow:global_step/sec: 1.78947\n",
      "INFO:tensorflow:loss = 202639.31, step = 31101 (55.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80799\n",
      "INFO:tensorflow:loss = 6817.8555, step = 31201 (55.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79078\n",
      "INFO:tensorflow:loss = 206189.53, step = 31301 (55.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80694\n",
      "INFO:tensorflow:loss = 186532.88, step = 31401 (55.342 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 31500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6737.0864.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-02:38:06\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-31500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-02:38:26\n",
      "INFO:tensorflow:Saving dict for global step 31500: average_loss = 3.1812553, global_step = 31500, loss = 31788.693\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-31500\n",
      "INFO:tensorflow:Saving checkpoints for 31501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 6878.532, step = 31501\n",
      "INFO:tensorflow:global_step/sec: 1.80906\n",
      "INFO:tensorflow:loss = 183712.44, step = 31601 (55.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80748\n",
      "INFO:tensorflow:loss = 6892.011, step = 31701 (55.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81917\n",
      "INFO:tensorflow:loss = 6667.344, step = 31801 (54.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80722\n",
      "INFO:tensorflow:loss = 213567.12, step = 31901 (55.334 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6622.9883.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-02:43:05\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-32000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-02:43:26\n",
      "INFO:tensorflow:Saving dict for global step 32000: average_loss = 3.184098, global_step = 32000, loss = 31817.098\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-32000\n",
      "INFO:tensorflow:Saving checkpoints for 32001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 6675.457, step = 32001\n",
      "INFO:tensorflow:global_step/sec: 1.78585\n",
      "INFO:tensorflow:loss = 186352.44, step = 32101 (55.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80896\n",
      "INFO:tensorflow:loss = 6687.3193, step = 32201 (55.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81241\n",
      "INFO:tensorflow:loss = 187746.12, step = 32301 (55.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80747\n",
      "INFO:tensorflow:loss = 202831.75, step = 32401 (55.326 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6785.6963.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-02:48:06\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-32500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-02:48:27\n",
      "INFO:tensorflow:Saving dict for global step 32500: average_loss = 3.1720912, global_step = 32500, loss = 31697.121\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-32500\n",
      "INFO:tensorflow:Saving checkpoints for 32501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 227838.75, step = 32501\n",
      "INFO:tensorflow:global_step/sec: 1.81266\n",
      "INFO:tensorflow:loss = 47279.76, step = 32601 (55.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81729\n",
      "INFO:tensorflow:loss = 6772.8857, step = 32701 (55.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80849\n",
      "INFO:tensorflow:loss = 207140.3, step = 32801 (55.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80913\n",
      "INFO:tensorflow:loss = 6544.0156, step = 32901 (55.276 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 33000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 183346.47.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-02:53:06\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-33000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-02:53:27\n",
      "INFO:tensorflow:Saving dict for global step 33000: average_loss = 5.7605534, global_step = 33000, loss = 57562.33\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-33000\n",
      "INFO:tensorflow:Saving checkpoints for 33001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 184973.28, step = 33001\n",
      "INFO:tensorflow:global_step/sec: 1.80936\n",
      "INFO:tensorflow:loss = 6679.3823, step = 33101 (55.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81478\n",
      "INFO:tensorflow:loss = 6715.203, step = 33201 (55.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81375\n",
      "INFO:tensorflow:loss = 201727.28, step = 33301 (55.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80506\n",
      "INFO:tensorflow:loss = 6885.1445, step = 33401 (55.400 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 33500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 190492.31.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-02:58:07\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-33500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-02:58:27\n",
      "INFO:tensorflow:Saving dict for global step 33500: average_loss = 6.087581, global_step = 33500, loss = 60830.156\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-33500\n",
      "INFO:tensorflow:Saving checkpoints for 33501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 197742.28, step = 33501\n",
      "INFO:tensorflow:global_step/sec: 1.81025\n",
      "INFO:tensorflow:loss = 6537.726, step = 33601 (55.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80224\n",
      "INFO:tensorflow:loss = 183288.1, step = 33701 (55.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81695\n",
      "INFO:tensorflow:loss = 192397.6, step = 33801 (55.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80518\n",
      "INFO:tensorflow:loss = 6634.0156, step = 33901 (55.395 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 184933.84.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-03:03:08\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-34000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-03:03:29\n",
      "INFO:tensorflow:Saving dict for global step 34000: average_loss = 5.7282205, global_step = 34000, loss = 57239.242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-34000\n",
      "INFO:tensorflow:Saving checkpoints for 34001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 172906.84, step = 34001\n",
      "INFO:tensorflow:global_step/sec: 1.78518\n",
      "INFO:tensorflow:loss = 6586.797, step = 34101 (56.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79563\n",
      "INFO:tensorflow:loss = 6805.3555, step = 34201 (55.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.77933\n",
      "INFO:tensorflow:loss = 174909.66, step = 34301 (56.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79319\n",
      "INFO:tensorflow:loss = 6672.294, step = 34401 (55.767 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 213489.06.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-03:08:12\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-34500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-03:08:33\n",
      "INFO:tensorflow:Saving dict for global step 34500: average_loss = 6.1463366, global_step = 34500, loss = 61417.27\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-34500\n",
      "INFO:tensorflow:Saving checkpoints for 34501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 44991.58, step = 34501\n",
      "INFO:tensorflow:global_step/sec: 1.81163\n",
      "INFO:tensorflow:loss = 209919.97, step = 34601 (55.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79758\n",
      "INFO:tensorflow:loss = 196497.38, step = 34701 (55.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81494\n",
      "INFO:tensorflow:loss = 6616.534, step = 34801 (55.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.78931\n",
      "INFO:tensorflow:loss = 183785.31, step = 34901 (55.887 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 35000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6661.478.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-03:13:13\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-35000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-03:13:34\n",
      "INFO:tensorflow:Saving dict for global step 35000: average_loss = 3.145393, global_step = 35000, loss = 31430.34\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-35000\n",
      "INFO:tensorflow:Saving checkpoints for 35001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 179269.25, step = 35001\n",
      "INFO:tensorflow:global_step/sec: 1.79194\n",
      "INFO:tensorflow:loss = 205500.66, step = 35101 (55.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.77283\n",
      "INFO:tensorflow:loss = 6607.424, step = 35201 (56.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.78857\n",
      "INFO:tensorflow:loss = 176539.14, step = 35301 (55.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.78948\n",
      "INFO:tensorflow:loss = 6536.6226, step = 35401 (55.882 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 35500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6536.9683.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-03:18:17\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-35500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-03:18:37\n",
      "INFO:tensorflow:Saving dict for global step 35500: average_loss = 3.1367195, global_step = 35500, loss = 31343.67\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-35500\n",
      "INFO:tensorflow:Saving checkpoints for 35501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 6521.2476, step = 35501\n",
      "INFO:tensorflow:global_step/sec: 1.80483\n",
      "INFO:tensorflow:loss = 183317.4, step = 35601 (55.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8024\n",
      "INFO:tensorflow:loss = 198849.56, step = 35701 (55.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80276\n",
      "INFO:tensorflow:loss = 6474.926, step = 35801 (55.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80051\n",
      "INFO:tensorflow:loss = 192910.22, step = 35901 (55.540 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6593.004.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-03:23:19\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-36000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-03:23:39\n",
      "INFO:tensorflow:Saving dict for global step 36000: average_loss = 3.133091, global_step = 36000, loss = 31307.41\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-36000\n",
      "INFO:tensorflow:Saving checkpoints for 36001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 216575.56, step = 36001\n",
      "INFO:tensorflow:global_step/sec: 1.78833\n",
      "INFO:tensorflow:loss = 192033.9, step = 36101 (55.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.78885\n",
      "INFO:tensorflow:loss = 6476.899, step = 36201 (55.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79166\n",
      "INFO:tensorflow:loss = 202400.97, step = 36301 (55.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.792\n",
      "INFO:tensorflow:loss = 6521.0596, step = 36401 (55.803 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 69482.5.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-03:28:22\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-36500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-03:28:42\n",
      "INFO:tensorflow:Saving dict for global step 36500: average_loss = 3.207593, global_step = 36500, loss = 32051.871\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-36500\n",
      "INFO:tensorflow:Saving checkpoints for 36501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 9681.928, step = 36501\n",
      "INFO:tensorflow:global_step/sec: 1.77257\n",
      "INFO:tensorflow:loss = 6476.9795, step = 36601 (56.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.78991\n",
      "INFO:tensorflow:loss = 219199.06, step = 36701 (55.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.78757\n",
      "INFO:tensorflow:loss = 6649.3716, step = 36801 (55.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.7896\n",
      "INFO:tensorflow:loss = 212770.42, step = 36901 (55.878 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 37000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 180071.6.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-03:33:27\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-37000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-03:33:48\n",
      "INFO:tensorflow:Saving dict for global step 37000: average_loss = 5.8832045, global_step = 37000, loss = 58787.92\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-37000\n",
      "INFO:tensorflow:Saving checkpoints for 37001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 41836.023, step = 37001\n",
      "INFO:tensorflow:global_step/sec: 1.79296\n",
      "INFO:tensorflow:loss = 6467.426, step = 37101 (55.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80488\n",
      "INFO:tensorflow:loss = 174977.72, step = 37201 (55.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81031\n",
      "INFO:tensorflow:loss = 6536.129, step = 37301 (55.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8141\n",
      "INFO:tensorflow:loss = 178403.75, step = 37401 (55.123 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 37500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 27791.871.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-03:38:28\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-37500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-03:38:49\n",
      "INFO:tensorflow:Saving dict for global step 37500: average_loss = 3.1476665, global_step = 37500, loss = 31453.057\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-37500\n",
      "INFO:tensorflow:Saving checkpoints for 37501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 225221.81, step = 37501\n",
      "INFO:tensorflow:global_step/sec: 1.79187\n",
      "INFO:tensorflow:loss = 6475.4644, step = 37601 (55.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80533\n",
      "INFO:tensorflow:loss = 194899.31, step = 37701 (55.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79739\n",
      "INFO:tensorflow:loss = 64580.137, step = 37801 (55.637 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.7926\n",
      "INFO:tensorflow:loss = 6398.5083, step = 37901 (55.785 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 203975.97.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-03:43:30\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-38000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-03:43:51\n",
      "INFO:tensorflow:Saving dict for global step 38000: average_loss = 5.834864, global_step = 38000, loss = 58304.883\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-38000\n",
      "INFO:tensorflow:Saving checkpoints for 38001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 41225.926, step = 38001\n",
      "INFO:tensorflow:global_step/sec: 1.79816\n",
      "INFO:tensorflow:loss = 208832.38, step = 38101 (55.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8011\n",
      "INFO:tensorflow:loss = 149715.73, step = 38201 (55.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79964\n",
      "INFO:tensorflow:loss = 6375.5254, step = 38301 (55.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80242\n",
      "INFO:tensorflow:loss = 197824.6, step = 38401 (55.481 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6496.587.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-03:48:32\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-38500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-03:48:53\n",
      "INFO:tensorflow:Saving dict for global step 38500: average_loss = 3.107387, global_step = 38500, loss = 31050.566\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-38500\n",
      "INFO:tensorflow:Saving checkpoints for 38501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 6469.0044, step = 38501\n",
      "INFO:tensorflow:global_step/sec: 1.8123\n",
      "INFO:tensorflow:loss = 81542.22, step = 38601 (55.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79584\n",
      "INFO:tensorflow:loss = 191351.55, step = 38701 (55.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81132\n",
      "INFO:tensorflow:loss = 6396.093, step = 38801 (55.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81686\n",
      "INFO:tensorflow:loss = 169237.0, step = 38901 (55.039 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 39000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6778.258.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-03:53:33\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-39000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-03:53:54\n",
      "INFO:tensorflow:Saving dict for global step 39000: average_loss = 3.1111524, global_step = 39000, loss = 31088.191\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-39000\n",
      "INFO:tensorflow:Saving checkpoints for 39001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 204081.81, step = 39001\n",
      "INFO:tensorflow:global_step/sec: 1.81165\n",
      "INFO:tensorflow:loss = 6433.4077, step = 39101 (55.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82146\n",
      "INFO:tensorflow:loss = 6393.1104, step = 39201 (54.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81144\n",
      "INFO:tensorflow:loss = 212655.81, step = 39301 (55.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81118\n",
      "INFO:tensorflow:loss = 6586.9775, step = 39401 (55.213 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 39500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 197973.28.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-03:58:33\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-39500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-03:58:54\n",
      "INFO:tensorflow:Saving dict for global step 39500: average_loss = 5.8505435, global_step = 39500, loss = 58461.555\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-39500\n",
      "INFO:tensorflow:Saving checkpoints for 39501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 41327.15, step = 39501\n",
      "INFO:tensorflow:global_step/sec: 1.79909\n",
      "INFO:tensorflow:loss = 198687.06, step = 39601 (55.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80967\n",
      "INFO:tensorflow:loss = 6566.7217, step = 39701 (55.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81622\n",
      "INFO:tensorflow:loss = 208414.53, step = 39801 (55.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83015\n",
      "INFO:tensorflow:loss = 187392.83, step = 39901 (54.640 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6350.908.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-04:03:33\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-40000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-04:03:54\n",
      "INFO:tensorflow:Saving dict for global step 40000: average_loss = 3.0939357, global_step = 40000, loss = 30916.152\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-40000\n",
      "INFO:tensorflow:Saving checkpoints for 40001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 6605.5845, step = 40001\n",
      "INFO:tensorflow:global_step/sec: 1.81539\n",
      "INFO:tensorflow:loss = 206876.92, step = 40101 (55.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80513\n",
      "INFO:tensorflow:loss = 169419.77, step = 40201 (55.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79569\n",
      "INFO:tensorflow:loss = 6290.22, step = 40301 (55.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79578\n",
      "INFO:tensorflow:loss = 205306.2, step = 40401 (55.686 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6408.777.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-04:08:34\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-40500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-04:08:55\n",
      "INFO:tensorflow:Saving dict for global step 40500: average_loss = 3.0865533, global_step = 40500, loss = 30842.385\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-40500\n",
      "INFO:tensorflow:Saving checkpoints for 40501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 6252.13, step = 40501\n",
      "INFO:tensorflow:global_step/sec: 1.80713\n",
      "INFO:tensorflow:loss = 198858.19, step = 40601 (55.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81902\n",
      "INFO:tensorflow:loss = 6341.752, step = 40701 (54.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81642\n",
      "INFO:tensorflow:loss = 184161.28, step = 40801 (55.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80019\n",
      "INFO:tensorflow:loss = 199587.38, step = 40901 (55.554 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 41000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6576.0156.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-04:13:35\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-41000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-04:13:55\n",
      "INFO:tensorflow:Saving dict for global step 41000: average_loss = 3.085033, global_step = 41000, loss = 30827.191\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-41000\n",
      "INFO:tensorflow:Saving checkpoints for 41001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 6448.792, step = 41001\n",
      "INFO:tensorflow:global_step/sec: 1.79531\n",
      "INFO:tensorflow:loss = 184584.47, step = 41101 (55.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.7975\n",
      "INFO:tensorflow:loss = 6298.282, step = 41201 (55.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82266\n",
      "INFO:tensorflow:loss = 6501.877, step = 41301 (54.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80075\n",
      "INFO:tensorflow:loss = 173078.56, step = 41401 (55.532 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 41500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6453.777.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-04:18:36\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-41500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-04:18:56\n",
      "INFO:tensorflow:Saving dict for global step 41500: average_loss = 3.077388, global_step = 41500, loss = 30750.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-41500\n",
      "INFO:tensorflow:Saving checkpoints for 41501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 220891.78, step = 41501\n",
      "INFO:tensorflow:global_step/sec: 1.81621\n",
      "INFO:tensorflow:loss = 43558.523, step = 41601 (55.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.78854\n",
      "INFO:tensorflow:loss = 6293.789, step = 41701 (55.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81719\n",
      "INFO:tensorflow:loss = 201916.34, step = 41801 (55.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79998\n",
      "INFO:tensorflow:loss = 6173.673, step = 41901 (55.557 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 42000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 183451.38.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-04:23:36\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-42000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-04:23:57\n",
      "INFO:tensorflow:Saving dict for global step 42000: average_loss = 5.520181, global_step = 42000, loss = 55160.41\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-42000\n",
      "INFO:tensorflow:Saving checkpoints for 42001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 37962.46, step = 42001\n",
      "INFO:tensorflow:global_step/sec: 1.79493\n",
      "INFO:tensorflow:loss = 220004.0, step = 42101 (55.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79484\n",
      "INFO:tensorflow:loss = 155556.42, step = 42201 (55.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81004\n",
      "INFO:tensorflow:loss = 6313.626, step = 42301 (55.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80655\n",
      "INFO:tensorflow:loss = 200820.0, step = 42401 (55.353 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 42500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6378.8506.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-04:28:38\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-42500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-04:28:58\n",
      "INFO:tensorflow:Saving dict for global step 42500: average_loss = 3.0693345, global_step = 42500, loss = 30670.324\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-42500\n",
      "INFO:tensorflow:Saving checkpoints for 42501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 199288.98, step = 42501\n",
      "INFO:tensorflow:global_step/sec: 1.8047\n",
      "INFO:tensorflow:loss = 206504.83, step = 42601 (55.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81501\n",
      "INFO:tensorflow:loss = 6210.733, step = 42701 (55.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81047\n",
      "INFO:tensorflow:loss = 175396.22, step = 42801 (55.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81257\n",
      "INFO:tensorflow:loss = 6424.3125, step = 42901 (55.170 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 43000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6340.5938.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-04:33:38\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-43000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-04:33:58\n",
      "INFO:tensorflow:Saving dict for global step 43000: average_loss = 3.0656517, global_step = 43000, loss = 30633.523\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-43000\n",
      "INFO:tensorflow:Saving checkpoints for 43001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 219379.97, step = 43001\n",
      "INFO:tensorflow:global_step/sec: 1.81814\n",
      "INFO:tensorflow:loss = 6315.5957, step = 43101 (55.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80529\n",
      "INFO:tensorflow:loss = 6175.3906, step = 43201 (55.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81524\n",
      "INFO:tensorflow:loss = 216274.89, step = 43301 (55.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81285\n",
      "INFO:tensorflow:loss = 6468.784, step = 43401 (55.162 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 43500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 178867.78.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-04:38:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-43500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-04:38:58\n",
      "INFO:tensorflow:Saving dict for global step 43500: average_loss = 5.597789, global_step = 43500, loss = 55935.906\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-43500\n",
      "INFO:tensorflow:Saving checkpoints for 43501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 38964.977, step = 43501\n",
      "INFO:tensorflow:global_step/sec: 1.81813\n",
      "INFO:tensorflow:loss = 194891.77, step = 43601 (55.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81238\n",
      "INFO:tensorflow:loss = 6193.1816, step = 43701 (55.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79052\n",
      "INFO:tensorflow:loss = 181817.75, step = 43801 (55.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80382\n",
      "INFO:tensorflow:loss = 205229.03, step = 43901 (55.438 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 44000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6157.3574.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-04:43:38\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-44000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-04:43:58\n",
      "INFO:tensorflow:Saving dict for global step 44000: average_loss = 3.0603426, global_step = 44000, loss = 30580.473\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-44000\n",
      "INFO:tensorflow:Saving checkpoints for 44001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 229273.97, step = 44001\n",
      "INFO:tensorflow:global_step/sec: 1.80952\n",
      "INFO:tensorflow:loss = 76417.164, step = 44101 (55.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79142\n",
      "INFO:tensorflow:loss = 6189.7515, step = 44201 (55.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82426\n",
      "INFO:tensorflow:loss = 198010.73, step = 44301 (54.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80394\n",
      "INFO:tensorflow:loss = 6204.4795, step = 44401 (55.434 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 44500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 177320.6.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-04:48:38\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-44500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-04:48:59\n",
      "INFO:tensorflow:Saving dict for global step 44500: average_loss = 5.3234487, global_step = 44500, loss = 53194.56\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-44500\n",
      "INFO:tensorflow:Saving checkpoints for 44501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 65754.41, step = 44501\n",
      "INFO:tensorflow:global_step/sec: 1.81086\n",
      "INFO:tensorflow:loss = 190776.1, step = 44601 (55.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81937\n",
      "INFO:tensorflow:loss = 6188.272, step = 44701 (54.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80457\n",
      "INFO:tensorflow:loss = 161389.62, step = 44801 (55.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81944\n",
      "INFO:tensorflow:loss = 6257.9043, step = 44901 (54.962 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 45000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6352.957.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-04:53:38\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-45000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-04:53:58\n",
      "INFO:tensorflow:Saving dict for global step 45000: average_loss = 3.0504906, global_step = 45000, loss = 30482.027\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-45000\n",
      "INFO:tensorflow:Saving checkpoints for 45001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 6258.1807, step = 45001\n",
      "INFO:tensorflow:global_step/sec: 1.81536\n",
      "INFO:tensorflow:loss = 198340.14, step = 45101 (55.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81732\n",
      "INFO:tensorflow:loss = 178864.06, step = 45201 (55.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82092\n",
      "INFO:tensorflow:loss = 6097.6846, step = 45301 (54.917 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.80916\n",
      "INFO:tensorflow:loss = 208755.94, step = 45401 (55.274 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 45500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6196.798.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-04:58:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-45500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-04:58:57\n",
      "INFO:tensorflow:Saving dict for global step 45500: average_loss = 3.0491266, global_step = 45500, loss = 30468.398\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-45500\n",
      "INFO:tensorflow:Saving checkpoints for 45501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 219338.72, step = 45501\n",
      "INFO:tensorflow:global_step/sec: 1.78554\n",
      "INFO:tensorflow:loss = 194863.97, step = 45601 (56.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80341\n",
      "INFO:tensorflow:loss = 6376.908, step = 45701 (55.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80806\n",
      "INFO:tensorflow:loss = 176026.69, step = 45801 (55.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82526\n",
      "INFO:tensorflow:loss = 6256.6943, step = 45901 (54.787 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 46000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6312.0166.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-05:03:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-46000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-05:03:58\n",
      "INFO:tensorflow:Saving dict for global step 46000: average_loss = 3.042857, global_step = 46000, loss = 30405.746\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-46000\n",
      "INFO:tensorflow:Saving checkpoints for 46001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 183191.25, step = 46001\n",
      "INFO:tensorflow:global_step/sec: 1.82084\n",
      "INFO:tensorflow:loss = 6093.9595, step = 46101 (54.921 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81046\n",
      "INFO:tensorflow:loss = 203069.0, step = 46201 (55.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81449\n",
      "INFO:tensorflow:loss = 6031.5996, step = 46301 (55.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8023\n",
      "INFO:tensorflow:loss = 183527.5, step = 46401 (55.484 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 46500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 202837.88.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-05:08:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-46500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-05:08:57\n",
      "INFO:tensorflow:Saving dict for global step 46500: average_loss = 5.770901, global_step = 46500, loss = 57665.73\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-46500\n",
      "INFO:tensorflow:Saving checkpoints for 46501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 179372.34, step = 46501\n",
      "INFO:tensorflow:global_step/sec: 1.80388\n",
      "INFO:tensorflow:loss = 194499.64, step = 46601 (55.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81113\n",
      "INFO:tensorflow:loss = 6155.1055, step = 46701 (55.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81093\n",
      "INFO:tensorflow:loss = 189087.64, step = 46801 (55.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82379\n",
      "INFO:tensorflow:loss = 6177.347, step = 46901 (54.832 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 47000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 14818.64.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-05:13:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-47000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-05:13:58\n",
      "INFO:tensorflow:Saving dict for global step 47000: average_loss = 3.0119414, global_step = 47000, loss = 30096.824\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-47000\n",
      "INFO:tensorflow:Saving checkpoints for 47001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 6161.5737, step = 47001\n",
      "INFO:tensorflow:global_step/sec: 1.81308\n",
      "INFO:tensorflow:loss = 198086.78, step = 47101 (55.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81251\n",
      "INFO:tensorflow:loss = 6221.6914, step = 47201 (55.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81703\n",
      "INFO:tensorflow:loss = 198015.66, step = 47301 (55.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.79647\n",
      "INFO:tensorflow:loss = 88626.35, step = 47401 (55.664 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 47500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6053.038.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-05:18:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-47500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-05:18:58\n",
      "INFO:tensorflow:Saving dict for global step 47500: average_loss = 3.0329685, global_step = 47500, loss = 30306.938\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-47500\n",
      "INFO:tensorflow:Saving checkpoints for 47501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 6069.939, step = 47501\n",
      "INFO:tensorflow:global_step/sec: 1.80637\n",
      "INFO:tensorflow:loss = 184495.44, step = 47601 (55.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80973\n",
      "INFO:tensorflow:loss = 6160.9775, step = 47701 (55.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80997\n",
      "INFO:tensorflow:loss = 172507.36, step = 47801 (55.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81077\n",
      "INFO:tensorflow:loss = 6170.35, step = 47901 (55.226 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 48000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6280.7734.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-05:23:38\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-48000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-05:23:58\n",
      "INFO:tensorflow:Saving dict for global step 48000: average_loss = 3.031626, global_step = 48000, loss = 30293.523\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-48000\n",
      "INFO:tensorflow:Saving checkpoints for 48001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 230101.55, step = 48001\n",
      "INFO:tensorflow:global_step/sec: 1.83073\n",
      "INFO:tensorflow:loss = 6097.269, step = 48101 (54.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82458\n",
      "INFO:tensorflow:loss = 186120.12, step = 48201 (54.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81634\n",
      "INFO:tensorflow:loss = 180137.56, step = 48301 (55.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81006\n",
      "INFO:tensorflow:loss = 5936.843, step = 48401 (55.247 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 48500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 198586.53.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-05:28:36\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-48500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-05:28:56\n",
      "INFO:tensorflow:Saving dict for global step 48500: average_loss = 5.719184, global_step = 48500, loss = 57148.945\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-48500\n",
      "INFO:tensorflow:Saving checkpoints for 48501 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 179926.5, step = 48501\n",
      "INFO:tensorflow:global_step/sec: 1.81893\n",
      "INFO:tensorflow:loss = 6084.0166, step = 48601 (54.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83123\n",
      "INFO:tensorflow:loss = 5992.4355, step = 48701 (54.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8231\n",
      "INFO:tensorflow:loss = 208223.25, step = 48801 (54.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82606\n",
      "INFO:tensorflow:loss = 6266.2827, step = 48901 (54.763 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 49000 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 182395.38.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-05:33:35\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-49000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-05:33:55\n",
      "INFO:tensorflow:Saving dict for global step 49000: average_loss = 5.527114, global_step = 49000, loss = 55229.684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-49000\n",
      "INFO:tensorflow:Saving checkpoints for 49001 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:loss = 180022.05, step = 49001\n",
      "INFO:tensorflow:global_step/sec: 1.81893\n",
      "INFO:tensorflow:loss = 6190.7974, step = 49101 (54.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81329\n",
      "INFO:tensorflow:loss = 6058.918, step = 49201 (55.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.7971\n",
      "INFO:tensorflow:loss = 184009.75, step = 49301 (55.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.80761\n",
      "INFO:tensorflow:loss = 6170.292, step = 49401 (55.321 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 49500 into /tmp/tf_wx_model-20/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 188999.56.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-20-05:38:35\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-20/model.ckpt-49500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-20-05:38:55\n",
      "INFO:tensorflow:Saving dict for global step 49500: average_loss = 5.5013437, global_step = 49500, loss = 54972.18\n"
     ]
    }
   ],
   "source": [
    "evaluations = []  \n",
    "STEPS = 500  \n",
    "for i in range(1, 100):  \n",
    "    regressor.train(input_fn=wx_input_fn(X_train, y=y_train), steps=STEPS)\n",
    "    evaluations.append(regressor.evaluate(input_fn=wx_input_fn(X_val,\n",
    "                                                               y_val,\n",
    "                                                               num_epochs=1,\n",
    "                                                               shuffle=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f40dc560850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "loss_values = [ev['loss'] for ev in evaluations]  \n",
    "training_steps = [ev['global_step'] for ev in evaluations]\n",
    "\n",
    "plt.scatter(x=training_steps, y=loss_values)  \n",
    "plt.xlabel('Training steps')  \n",
    "plt.ylabel('Loss (SSE)')  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-18/model.ckpt-40500\n"
     ]
    }
   ],
   "source": [
    "pred = regressor.predict(input_fn=wx_input_fn(X_test,  \n",
    "                                              num_epochs=1,\n",
    "                                              shuffle=False))\n",
    "\n",
    "predictions = np.array([p['predictions'][0] for p in pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Explained Variance: -0.03\n",
      "The Mean Absolute Error: 0.62 mm \n",
      "The Median Absolute Error: 0.35 mm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"The Explained Variance: %.2f\" % explained_variance_score(  \n",
    "                                            y_test, predictions))  \n",
    "print(\"The Mean Absolute Error: %.2f mm \" % mean_absolute_error(  \n",
    "                                            y_test, predictions))  \n",
    "print(\"The Median Absolute Error: %.2f mm\" % median_absolute_error(  \n",
    "                                            y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.66619366,  0.19342299,  0.6047084 , ...,  0.552241  ,\n",
       "        0.39023083, -0.64644367], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419685"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f40499ee910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, predictions, edgecolors=(0, 0, 0))\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=1)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
