{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, integrate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import shutil\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAABLCAYAAABEDTEaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAAkNJREFUeJzt3L+OjGEYxuHnw2SxFISIKDYSpUZQ6ZyEYvupHIsDcAJqidoR0CGi0hKRFcGKlVej0dg/yXu/M99eVzfJV9xP9fsyk8zUWisA6O3E6AEAHA+CA0CE4AAQITgARAgOABGCA0CE4AAQITgARAgOABGn9ntgmqZlVS2rqqbF6dsbF651HzXK+XMboyd0dfHsYvSErjYXM35/2v06ekFXezs7oyd09ePz99ETuvnw62d9+b03HeTZ6TB/bXPmyo12ffvRkYetuvv3tkZP6OrBrfm+LFRV3b26OXpCNyffPB89oauPz56OntDV6ycvR0/o5uH7t/Vu99uBgjPjV0IAVongABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEVNr7f8PTNOyqpZ/P96sqle9Rw10qao+jR7RyZxvq3LfunPf+tpqrV0+yIP7Buefh6fpRWvtzpFnrbg53zfn26rct+7cdzz4Sg2ACMEBIOKwwXncZcXqmPN9c76tyn3rzn3HwKF+wwGAo/KVGgARggNAhOAAECE4AEQIDgARfwD+T1i7/7LiygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4bbc5c0f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.palplot(sns.color_palette(\"RdBu_r\", 7))\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Base com todos os dados do sudeste</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9779168\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/sudeste.csv',low_memory=False)\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Base com todas chuvas EXTREMAS com inicio e fim de cada chuva extrema (> 50mm em 24 horas)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31710\n"
     ]
    }
   ],
   "source": [
    "dfhr = pd.read_csv('../data/extreme_prcp_evolution.csv')\n",
    "print len(dfhr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Subconjunto da base principal considerando o inicio e fim das chuvas extremas (> 50mm em 24 horas)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761040\n"
     ]
    }
   ],
   "source": [
    "dfext = pd.read_csv('../data/sudeste_extreme_prcp.csv', index_col=0)\n",
    "print len(dfext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Limpeza dos dados</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Campos não numericos e campos derivados\n",
    "DES= ['wsid','wsnm','elvt','lat','lon','inme','city','prov']\n",
    "INT = ['yr','mo','da','hr']\n",
    "DAT = ['mdct','date']\n",
    "DER = ['smax','smin','tmax','tmin','dmax','dmin','hmax','hmin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe apenas com os dados continuos\n",
    "dfcont = df\n",
    "for f in DES + INT + DAT:    \n",
    "    dfcont = dfcont.drop(f, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcont = dfcont.apply(pd.to_numeric, errors='coerce')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9779168 entries, 0 to 9779167\n",
      "Data columns (total 17 columns):\n",
      "prcp    float64\n",
      "stp     float64\n",
      "smax    float64\n",
      "smin    float64\n",
      "gbrd    float64\n",
      "temp    float64\n",
      "tmax    float64\n",
      "tmin    float64\n",
      "dewp    float64\n",
      "dmax    float64\n",
      "dmin    float64\n",
      "hmdy    float64\n",
      "hmax    float64\n",
      "hmin    float64\n",
      "wdsp    float64\n",
      "wdct    float64\n",
      "gust    float64\n",
      "dtypes: float64(17)\n",
      "memory usage: 1.2 GB\n"
     ]
    }
   ],
   "source": [
    "dfcont.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prcp</th>\n",
       "      <td>1407984.0</td>\n",
       "      <td>0.936654</td>\n",
       "      <td>2.923291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>880.429177</td>\n",
       "      <td>248.264986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.3</td>\n",
       "      <td>944.200</td>\n",
       "      <td>973.1</td>\n",
       "      <td>1050.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>880.303394</td>\n",
       "      <td>248.917148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.5</td>\n",
       "      <td>944.400</td>\n",
       "      <td>973.3</td>\n",
       "      <td>1050.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>879.833097</td>\n",
       "      <td>248.771557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>943.900</td>\n",
       "      <td>972.8</td>\n",
       "      <td>1050.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbrd</th>\n",
       "      <td>5670348.0</td>\n",
       "      <td>1176.371062</td>\n",
       "      <td>1138.753521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>863.427</td>\n",
       "      <td>2103.0</td>\n",
       "      <td>11586.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>9779137.0</td>\n",
       "      <td>20.474225</td>\n",
       "      <td>7.331125</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>17.7</td>\n",
       "      <td>21.400</td>\n",
       "      <td>24.9</td>\n",
       "      <td>44.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax</th>\n",
       "      <td>9778693.0</td>\n",
       "      <td>14.726810</td>\n",
       "      <td>5.805413</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>16.100</td>\n",
       "      <td>18.9</td>\n",
       "      <td>42.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin</th>\n",
       "      <td>9779142.0</td>\n",
       "      <td>21.105026</td>\n",
       "      <td>7.545549</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>21.900</td>\n",
       "      <td>25.8</td>\n",
       "      <td>45.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewp</th>\n",
       "      <td>9778858.0</td>\n",
       "      <td>15.240249</td>\n",
       "      <td>5.866811</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>16.600</td>\n",
       "      <td>19.4</td>\n",
       "      <td>44.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmax</th>\n",
       "      <td>9779134.0</td>\n",
       "      <td>19.864175</td>\n",
       "      <td>7.134849</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>17.2</td>\n",
       "      <td>20.800</td>\n",
       "      <td>24.2</td>\n",
       "      <td>45.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmin</th>\n",
       "      <td>9778361.0</td>\n",
       "      <td>14.220885</td>\n",
       "      <td>5.777089</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>15.600</td>\n",
       "      <td>18.4</td>\n",
       "      <td>44.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>67.266673</td>\n",
       "      <td>26.542125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>74.000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax</th>\n",
       "      <td>9779156.0</td>\n",
       "      <td>69.969913</td>\n",
       "      <td>26.433711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>78.000</td>\n",
       "      <td>91.0</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin</th>\n",
       "      <td>9779124.0</td>\n",
       "      <td>64.419647</td>\n",
       "      <td>26.565504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>70.000</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp</th>\n",
       "      <td>8853607.0</td>\n",
       "      <td>1.998156</td>\n",
       "      <td>1.618531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.700</td>\n",
       "      <td>2.9</td>\n",
       "      <td>19.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>138.599091</td>\n",
       "      <td>105.201791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.000</td>\n",
       "      <td>216.0</td>\n",
       "      <td>360.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust</th>\n",
       "      <td>9462694.0</td>\n",
       "      <td>4.494015</td>\n",
       "      <td>2.981790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.200</td>\n",
       "      <td>6.3</td>\n",
       "      <td>50.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count         mean          std   min    25%      50%     75%  \\\n",
       "prcp  1407984.0     0.936654     2.923291   0.0    0.0    0.000     0.6   \n",
       "stp   9779168.0   880.429177   248.264986   0.0  911.3  944.200   973.1   \n",
       "smax  9779168.0   880.303394   248.917148   0.0  911.5  944.400   973.3   \n",
       "smin  9779168.0   879.833097   248.771557   0.0  911.0  943.900   972.8   \n",
       "gbrd  5670348.0  1176.371062  1138.753521   0.0   65.0  863.427  2103.0   \n",
       "temp  9779137.0    20.474225     7.331125  -3.8   17.7   21.400    24.9   \n",
       "tmax  9778693.0    14.726810     5.805413 -10.0   12.1   16.100    18.9   \n",
       "tmin  9779142.0    21.105026     7.545549  -3.2   18.2   21.900    25.8   \n",
       "dewp  9778858.0    15.240249     5.866811 -10.0   12.7   16.600    19.4   \n",
       "dmax  9779134.0    19.864175     7.134849  -8.5   17.2   20.800    24.2   \n",
       "dmin  9778361.0    14.220885     5.777089 -10.0   11.6   15.600    18.4   \n",
       "hmdy  9779168.0    67.266673    26.542125   0.0   53.0   74.000    89.0   \n",
       "hmax  9779156.0    69.969913    26.433711   0.0   58.0   78.000    91.0   \n",
       "hmin  9779124.0    64.419647    26.565504   0.0   49.0   70.000    86.0   \n",
       "wdsp  8853607.0     1.998156     1.618531   0.0    0.8    1.700     2.9   \n",
       "wdct  9779168.0   138.599091   105.201791   0.0   56.0  114.000   216.0   \n",
       "gust  9462694.0     4.494015     2.981790   0.0    2.3    4.200     6.3   \n",
       "\n",
       "            max  \n",
       "prcp    100.000  \n",
       "stp    1050.000  \n",
       "smax   1050.000  \n",
       "smin   1050.000  \n",
       "gbrd  11586.491  \n",
       "temp     44.900  \n",
       "tmax     42.700  \n",
       "tmin     45.000  \n",
       "dewp     44.800  \n",
       "dmax     45.000  \n",
       "dmin     44.900  \n",
       "hmdy    100.000  \n",
       "hmax    100.000  \n",
       "hmin    100.000  \n",
       "wdsp     19.800  \n",
       "wdct    360.000  \n",
       "gust     50.000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcont.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> A variável gbbr(radiação global) apresenta massivamente números nulos e não pode ser recuperada. Vamos retirar esta variável.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcont =  dfcont.drop('gbrd',1)\n",
    "df = df.drop('gbrd',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Para as precipitações nulas foi inputado 0.0 mm. Também para o vento e rajada de vento.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAN_BE_NULL = ['wdsp','prcp','gust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in CAN_BE_NULL:\n",
    "    df[v] = df[v].fillna(0.0)\n",
    "    dfcont[v] = dfcont[v].fillna(0.0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Vamos ver como os dados contínuos estão organizados: MÍNIMOS, MÁXIMOS, MEDIAS</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prcp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>0.134858</td>\n",
       "      <td>1.156940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>880.429177</td>\n",
       "      <td>248.264986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.3</td>\n",
       "      <td>944.2</td>\n",
       "      <td>973.1</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>880.303394</td>\n",
       "      <td>248.917148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.5</td>\n",
       "      <td>944.4</td>\n",
       "      <td>973.3</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>879.833097</td>\n",
       "      <td>248.771557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>943.9</td>\n",
       "      <td>972.8</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>9779137.0</td>\n",
       "      <td>20.474225</td>\n",
       "      <td>7.331125</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>17.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>24.9</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax</th>\n",
       "      <td>9778693.0</td>\n",
       "      <td>14.726810</td>\n",
       "      <td>5.805413</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>16.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>42.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin</th>\n",
       "      <td>9779142.0</td>\n",
       "      <td>21.105026</td>\n",
       "      <td>7.545549</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>21.9</td>\n",
       "      <td>25.8</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewp</th>\n",
       "      <td>9778858.0</td>\n",
       "      <td>15.240249</td>\n",
       "      <td>5.866811</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>16.6</td>\n",
       "      <td>19.4</td>\n",
       "      <td>44.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmax</th>\n",
       "      <td>9779134.0</td>\n",
       "      <td>19.864175</td>\n",
       "      <td>7.134849</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>17.2</td>\n",
       "      <td>20.8</td>\n",
       "      <td>24.2</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmin</th>\n",
       "      <td>9778361.0</td>\n",
       "      <td>14.220885</td>\n",
       "      <td>5.777089</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>15.6</td>\n",
       "      <td>18.4</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>67.266673</td>\n",
       "      <td>26.542125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax</th>\n",
       "      <td>9779156.0</td>\n",
       "      <td>69.969913</td>\n",
       "      <td>26.433711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin</th>\n",
       "      <td>9779124.0</td>\n",
       "      <td>64.419647</td>\n",
       "      <td>26.565504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>1.809038</td>\n",
       "      <td>1.647369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>138.599091</td>\n",
       "      <td>105.201791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>4.348580</td>\n",
       "      <td>3.039042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count        mean         std   min    25%    50%    75%     max\n",
       "prcp  9779168.0    0.134858    1.156940   0.0    0.0    0.0    0.0   100.0\n",
       "stp   9779168.0  880.429177  248.264986   0.0  911.3  944.2  973.1  1050.0\n",
       "smax  9779168.0  880.303394  248.917148   0.0  911.5  944.4  973.3  1050.0\n",
       "smin  9779168.0  879.833097  248.771557   0.0  911.0  943.9  972.8  1050.0\n",
       "temp  9779137.0   20.474225    7.331125  -3.8   17.7   21.4   24.9    44.9\n",
       "tmax  9778693.0   14.726810    5.805413 -10.0   12.1   16.1   18.9    42.7\n",
       "tmin  9779142.0   21.105026    7.545549  -3.2   18.2   21.9   25.8    45.0\n",
       "dewp  9778858.0   15.240249    5.866811 -10.0   12.7   16.6   19.4    44.8\n",
       "dmax  9779134.0   19.864175    7.134849  -8.5   17.2   20.8   24.2    45.0\n",
       "dmin  9778361.0   14.220885    5.777089 -10.0   11.6   15.6   18.4    44.9\n",
       "hmdy  9779168.0   67.266673   26.542125   0.0   53.0   74.0   89.0   100.0\n",
       "hmax  9779156.0   69.969913   26.433711   0.0   58.0   78.0   91.0   100.0\n",
       "hmin  9779124.0   64.419647   26.565504   0.0   49.0   70.0   86.0   100.0\n",
       "wdsp  9779168.0    1.809038    1.647369   0.0    0.4    1.5    2.7    19.8\n",
       "wdct  9779168.0  138.599091  105.201791   0.0   56.0  114.0  216.0   360.0\n",
       "gust  9779168.0    4.348580    3.039042   0.0    2.1    4.1    6.3    50.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcont.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>A temperatura será inputada pela média</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = ['temp','dewp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in MEAN:\n",
    "    df[v] = df[v].fillna(value=df[v].median())\n",
    "    dfcont[v] = dfcont[v].fillna(value=dfcont[v].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prcp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>0.134858</td>\n",
       "      <td>1.156940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>880.429177</td>\n",
       "      <td>248.264986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.3</td>\n",
       "      <td>944.2</td>\n",
       "      <td>973.1</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>880.303394</td>\n",
       "      <td>248.917148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.5</td>\n",
       "      <td>944.4</td>\n",
       "      <td>973.3</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>879.833097</td>\n",
       "      <td>248.771557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>943.9</td>\n",
       "      <td>972.8</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>20.474228</td>\n",
       "      <td>7.331113</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>17.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>24.9</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax</th>\n",
       "      <td>9778693.0</td>\n",
       "      <td>14.726810</td>\n",
       "      <td>5.805413</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>16.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>42.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin</th>\n",
       "      <td>9779142.0</td>\n",
       "      <td>21.105026</td>\n",
       "      <td>7.545549</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>21.9</td>\n",
       "      <td>25.8</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>15.240292</td>\n",
       "      <td>5.866723</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>16.6</td>\n",
       "      <td>19.4</td>\n",
       "      <td>44.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmax</th>\n",
       "      <td>9779134.0</td>\n",
       "      <td>19.864175</td>\n",
       "      <td>7.134849</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>17.2</td>\n",
       "      <td>20.8</td>\n",
       "      <td>24.2</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmin</th>\n",
       "      <td>9778361.0</td>\n",
       "      <td>14.220885</td>\n",
       "      <td>5.777089</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>15.6</td>\n",
       "      <td>18.4</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>67.266673</td>\n",
       "      <td>26.542125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax</th>\n",
       "      <td>9779156.0</td>\n",
       "      <td>69.969913</td>\n",
       "      <td>26.433711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin</th>\n",
       "      <td>9779124.0</td>\n",
       "      <td>64.419647</td>\n",
       "      <td>26.565504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>1.809038</td>\n",
       "      <td>1.647369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>138.599091</td>\n",
       "      <td>105.201791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>4.348580</td>\n",
       "      <td>3.039042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count        mean         std   min    25%    50%    75%     max\n",
       "prcp  9779168.0    0.134858    1.156940   0.0    0.0    0.0    0.0   100.0\n",
       "stp   9779168.0  880.429177  248.264986   0.0  911.3  944.2  973.1  1050.0\n",
       "smax  9779168.0  880.303394  248.917148   0.0  911.5  944.4  973.3  1050.0\n",
       "smin  9779168.0  879.833097  248.771557   0.0  911.0  943.9  972.8  1050.0\n",
       "temp  9779168.0   20.474228    7.331113  -3.8   17.7   21.4   24.9    44.9\n",
       "tmax  9778693.0   14.726810    5.805413 -10.0   12.1   16.1   18.9    42.7\n",
       "tmin  9779142.0   21.105026    7.545549  -3.2   18.2   21.9   25.8    45.0\n",
       "dewp  9779168.0   15.240292    5.866723 -10.0   12.7   16.6   19.4    44.8\n",
       "dmax  9779134.0   19.864175    7.134849  -8.5   17.2   20.8   24.2    45.0\n",
       "dmin  9778361.0   14.220885    5.777089 -10.0   11.6   15.6   18.4    44.9\n",
       "hmdy  9779168.0   67.266673   26.542125   0.0   53.0   74.0   89.0   100.0\n",
       "hmax  9779156.0   69.969913   26.433711   0.0   58.0   78.0   91.0   100.0\n",
       "hmin  9779124.0   64.419647   26.565504   0.0   49.0   70.0   86.0   100.0\n",
       "wdsp  9779168.0    1.809038    1.647369   0.0    0.4    1.5    2.7    19.8\n",
       "wdct  9779168.0  138.599091  105.201791   0.0   56.0  114.0  216.0   360.0\n",
       "gust  9779168.0    4.348580    3.039042   0.0    2.1    4.1    6.3    50.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcont.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in ['tmax','tmin']:\n",
    "    dfcont[v] = dfcont[v].fillna(value=dfcont['temp'])\n",
    "    df[v] = df[v].fillna(value=df['temp'])\n",
    "for v in ['dmax','dmin']:\n",
    "    dfcont[v] = dfcont[v].fillna(value=dfcont['dewp'])\n",
    "    df[v] = df[v].fillna(value=df['dewp'])\n",
    "for v in ['hmax','hmin']:\n",
    "    dfcont[v] = dfcont[v].fillna(value=dfcont['hmdy'])\n",
    "    df[v] = df[v].fillna(value=df['hmdy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prcp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>0.134858</td>\n",
       "      <td>1.156940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>880.429177</td>\n",
       "      <td>248.264986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.3</td>\n",
       "      <td>944.2</td>\n",
       "      <td>973.1</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>880.303394</td>\n",
       "      <td>248.917148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.5</td>\n",
       "      <td>944.4</td>\n",
       "      <td>973.3</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>879.833097</td>\n",
       "      <td>248.771557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>943.9</td>\n",
       "      <td>972.8</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>20.474228</td>\n",
       "      <td>7.331113</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>17.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>24.9</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>14.727113</td>\n",
       "      <td>5.805794</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>16.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>42.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>21.104973</td>\n",
       "      <td>7.545616</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>21.9</td>\n",
       "      <td>25.8</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>15.240292</td>\n",
       "      <td>5.866723</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>16.6</td>\n",
       "      <td>19.4</td>\n",
       "      <td>44.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmax</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>19.864112</td>\n",
       "      <td>7.134923</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>17.2</td>\n",
       "      <td>20.8</td>\n",
       "      <td>24.2</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmin</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>14.219949</td>\n",
       "      <td>5.777816</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>15.6</td>\n",
       "      <td>18.4</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>67.266673</td>\n",
       "      <td>26.542125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>69.969827</td>\n",
       "      <td>26.433808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>64.419357</td>\n",
       "      <td>26.565795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>1.809038</td>\n",
       "      <td>1.647369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>138.599091</td>\n",
       "      <td>105.201791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>4.348580</td>\n",
       "      <td>3.039042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count        mean         std   min    25%    50%    75%     max\n",
       "prcp  9779168.0    0.134858    1.156940   0.0    0.0    0.0    0.0   100.0\n",
       "stp   9779168.0  880.429177  248.264986   0.0  911.3  944.2  973.1  1050.0\n",
       "smax  9779168.0  880.303394  248.917148   0.0  911.5  944.4  973.3  1050.0\n",
       "smin  9779168.0  879.833097  248.771557   0.0  911.0  943.9  972.8  1050.0\n",
       "temp  9779168.0   20.474228    7.331113  -3.8   17.7   21.4   24.9    44.9\n",
       "tmax  9779168.0   14.727113    5.805794 -10.0   12.1   16.1   18.9    42.7\n",
       "tmin  9779168.0   21.104973    7.545616  -3.2   18.2   21.9   25.8    45.0\n",
       "dewp  9779168.0   15.240292    5.866723 -10.0   12.7   16.6   19.4    44.8\n",
       "dmax  9779168.0   19.864112    7.134923  -8.5   17.2   20.8   24.2    45.0\n",
       "dmin  9779168.0   14.219949    5.777816 -10.0   11.6   15.6   18.4    44.9\n",
       "hmdy  9779168.0   67.266673   26.542125   0.0   53.0   74.0   89.0   100.0\n",
       "hmax  9779168.0   69.969827   26.433808   0.0   58.0   78.0   91.0   100.0\n",
       "hmin  9779168.0   64.419357   26.565795   0.0   49.0   70.0   86.0   100.0\n",
       "wdsp  9779168.0    1.809038    1.647369   0.0    0.4    1.5    2.7    19.8\n",
       "wdct  9779168.0  138.599091  105.201791   0.0   56.0  114.0  216.0   360.0\n",
       "gust  9779168.0    4.348580    3.039042   0.0    2.1    4.1    6.3    50.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcont.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Derivando novas variáveis</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>O objetivo é derivar cada variável climática contínua em uma nova variável t-1, t-2, t-3... t-n, onde n é o numeros de horas antes do momento t. Vamos primeiramente derivá-las para depois verificar quais quando massivamente as variávies estão zeradas, o que pode indicar que a estação falhou.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Utilizando um exemplo especifico de uma estação, depois verificamos o conjunto maior</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87456"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm = df[(df.wsid==329)]\n",
    "len(dfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wsid</th>\n",
       "      <th>wsnm</th>\n",
       "      <th>elvt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>inme</th>\n",
       "      <th>city</th>\n",
       "      <th>prov</th>\n",
       "      <th>mdct</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>tmin</th>\n",
       "      <th>dewp</th>\n",
       "      <th>dmax</th>\n",
       "      <th>dmin</th>\n",
       "      <th>hmdy</th>\n",
       "      <th>hmax</th>\n",
       "      <th>hmin</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>wdct</th>\n",
       "      <th>gust</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdct</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-10-10 00:00:00</th>\n",
       "      <td>329</td>\n",
       "      <td>BELO HOR. (PAMPULHA)</td>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>A521</td>\n",
       "      <td>Belo Horizonte</td>\n",
       "      <td>MG</td>\n",
       "      <td>2006-10-10 00:00:00</td>\n",
       "      <td>2006-10-10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-10 01:00:00</th>\n",
       "      <td>329</td>\n",
       "      <td>BELO HOR. (PAMPULHA)</td>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>A521</td>\n",
       "      <td>Belo Horizonte</td>\n",
       "      <td>MG</td>\n",
       "      <td>2006-10-10 01:00:00</td>\n",
       "      <td>2006-10-10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-10 02:00:00</th>\n",
       "      <td>329</td>\n",
       "      <td>BELO HOR. (PAMPULHA)</td>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>A521</td>\n",
       "      <td>Belo Horizonte</td>\n",
       "      <td>MG</td>\n",
       "      <td>2006-10-10 02:00:00</td>\n",
       "      <td>2006-10-10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-10 03:00:00</th>\n",
       "      <td>329</td>\n",
       "      <td>BELO HOR. (PAMPULHA)</td>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>A521</td>\n",
       "      <td>Belo Horizonte</td>\n",
       "      <td>MG</td>\n",
       "      <td>2006-10-10 03:00:00</td>\n",
       "      <td>2006-10-10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     wsid                  wsnm   elvt        lat        lon  \\\n",
       "mdct                                                                           \n",
       "2006-10-10 00:00:00   329  BELO HOR. (PAMPULHA)  854.0 -19.883945 -43.969397   \n",
       "2006-10-10 01:00:00   329  BELO HOR. (PAMPULHA)  854.0 -19.883945 -43.969397   \n",
       "2006-10-10 02:00:00   329  BELO HOR. (PAMPULHA)  854.0 -19.883945 -43.969397   \n",
       "2006-10-10 03:00:00   329  BELO HOR. (PAMPULHA)  854.0 -19.883945 -43.969397   \n",
       "\n",
       "                     inme            city prov                 mdct  \\\n",
       "mdct                                                                  \n",
       "2006-10-10 00:00:00  A521  Belo Horizonte   MG  2006-10-10 00:00:00   \n",
       "2006-10-10 01:00:00  A521  Belo Horizonte   MG  2006-10-10 01:00:00   \n",
       "2006-10-10 02:00:00  A521  Belo Horizonte   MG  2006-10-10 02:00:00   \n",
       "2006-10-10 03:00:00  A521  Belo Horizonte   MG  2006-10-10 03:00:00   \n",
       "\n",
       "                           date  ...   tmin  dewp  dmax  dmin  hmdy  hmax  \\\n",
       "mdct                             ...                                        \n",
       "2006-10-10 00:00:00  2006-10-10  ...    0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2006-10-10 01:00:00  2006-10-10  ...    0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2006-10-10 02:00:00  2006-10-10  ...    0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2006-10-10 03:00:00  2006-10-10  ...    0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "                     hmin  wdsp  wdct  gust  \n",
       "mdct                                         \n",
       "2006-10-10 00:00:00   0.0   0.0   0.0   0.0  \n",
       "2006-10-10 01:00:00   0.0   0.0   0.0   0.0  \n",
       "2006-10-10 02:00:00   0.0   0.0   0.0   0.0  \n",
       "2006-10-10 03:00:00   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.index = pd.to_datetime(dfm.mdct)\n",
    "dfm.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elvt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>prcp</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>dewp</th>\n",
       "      <th>dmax</th>\n",
       "      <th>dmin</th>\n",
       "      <th>hmdy</th>\n",
       "      <th>hmax</th>\n",
       "      <th>hmin</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>wdct</th>\n",
       "      <th>gust</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdct</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-10-10 00:00:00</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-10 01:00:00</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-10 02:00:00</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-10 03:00:00</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-10 04:00:00</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      elvt        lat        lon  prcp  stp  smax  smin  temp  \\\n",
       "mdct                                                                            \n",
       "2006-10-10 00:00:00  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   \n",
       "2006-10-10 01:00:00  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   \n",
       "2006-10-10 02:00:00  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   \n",
       "2006-10-10 03:00:00  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   \n",
       "2006-10-10 04:00:00  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   \n",
       "\n",
       "                     tmax  tmin  dewp  dmax  dmin  hmdy  hmax  hmin  wdsp  \\\n",
       "mdct                                                                        \n",
       "2006-10-10 00:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2006-10-10 01:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2006-10-10 02:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2006-10-10 03:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2006-10-10 04:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "                     wdct  gust  \n",
       "mdct                             \n",
       "2006-10-10 00:00:00   0.0   0.0  \n",
       "2006-10-10 01:00:00   0.0   0.0  \n",
       "2006-10-10 02:00:00   0.0   0.0  \n",
       "2006-10-10 03:00:00   0.0   0.0  \n",
       "2006-10-10 04:00:00   0.0   0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLEAN = ['wsnm','inme','city','prov','mdct','date']\n",
    "REMOVE = ['wsid','yr', 'mo', 'da', 'hr']\n",
    "for v in CLEAN + REMOVE:\n",
    "    dfm = dfm.drop(v,1)\n",
    "dfm.head(5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_nth_hour_feature(df, feature, N):  \n",
    "    rows = df.shape[0]\n",
    "    nth_prior_measurements = [None]*N + [df[feature][i-N] for i in range(N, rows)]\n",
    "    col_name = \"{}_{}\".format(feature, N)\n",
    "    df[col_name] = np.nan\n",
    "    df.loc[:][col_name] = nth_prior_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_DER = ['wsid','elvt','lat', 'lon', 'yr', 'mo', 'da', 'hr']\n",
    "\n",
    "for feature in dfm.columns:\n",
    "    if feature not in NON_DER:\n",
    "        for h in range(1,6):\n",
    "            derive_nth_hour_feature(dfm, feature, h) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOVE = [u'prcp_1', u'prcp_2', u'prcp_3', u'prcp_4', u'prcp_5']\n",
    "for v in REMOVE:\n",
    "    dfm = dfm.drop(v,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'elvt', u'lat', u'lon', u'prcp', u'stp', u'smax', u'smin', u'temp',\n",
       "       u'tmax', u'tmin', u'dewp', u'dmax', u'dmin', u'hmdy', u'hmax', u'hmin',\n",
       "       u'wdsp', u'wdct', u'gust', u'stp_1', u'stp_2', u'stp_3', u'stp_4',\n",
       "       u'stp_5', u'smax_1', u'smax_2', u'smax_3', u'smax_4', u'smax_5',\n",
       "       u'smin_1', u'smin_2', u'smin_3', u'smin_4', u'smin_5', u'temp_1',\n",
       "       u'temp_2', u'temp_3', u'temp_4', u'temp_5', u'tmax_1', u'tmax_2',\n",
       "       u'tmax_3', u'tmax_4', u'tmax_5', u'tmin_1', u'tmin_2', u'tmin_3',\n",
       "       u'tmin_4', u'tmin_5', u'dewp_1', u'dewp_2', u'dewp_3', u'dewp_4',\n",
       "       u'dewp_5', u'dmax_1', u'dmax_2', u'dmax_3', u'dmax_4', u'dmax_5',\n",
       "       u'dmin_1', u'dmin_2', u'dmin_3', u'dmin_4', u'dmin_5', u'hmdy_1',\n",
       "       u'hmdy_2', u'hmdy_3', u'hmdy_4', u'hmdy_5', u'hmax_1', u'hmax_2',\n",
       "       u'hmax_3', u'hmax_4', u'hmax_5', u'hmin_1', u'hmin_2', u'hmin_3',\n",
       "       u'hmin_4', u'hmin_5', u'wdsp_1', u'wdsp_2', u'wdsp_3', u'wdsp_4',\n",
       "       u'wdsp_5', u'wdct_1', u'wdct_2', u'wdct_3', u'wdct_4', u'wdct_5',\n",
       "       u'gust_1', u'gust_2', u'gust_3', u'gust_4', u'gust_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = dfm.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = dfm.dropna()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elvt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>prcp</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>...</th>\n",
       "      <th>wdct_1</th>\n",
       "      <th>wdct_2</th>\n",
       "      <th>wdct_3</th>\n",
       "      <th>wdct_4</th>\n",
       "      <th>wdct_5</th>\n",
       "      <th>gust_1</th>\n",
       "      <th>gust_2</th>\n",
       "      <th>gust_3</th>\n",
       "      <th>gust_4</th>\n",
       "      <th>gust_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    elvt        lat        lon  prcp  stp  smax  smin  temp  tmax  tmin  \\\n",
       "5  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "6  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "7  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "8  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "9  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "    ...    wdct_1  wdct_2  wdct_3  wdct_4  wdct_5  gust_1  gust_2  gust_3  \\\n",
       "5   ...       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "6   ...       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "7   ...       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "8   ...       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "9   ...       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   gust_4  gust_5  \n",
       "5     0.0     0.0  \n",
       "6     0.0     0.0  \n",
       "7     0.0     0.0  \n",
       "8     0.0     0.0  \n",
       "9     0.0     0.0  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como esta rede é especifica para a BH, vamos remover elvt, lat, lon\n",
    "REMOVE = ['elvt','lat', 'lon']\n",
    "for v in REMOVE:\n",
    "    dfm = dfm.drop(v,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prcp</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>dewp</th>\n",
       "      <th>dmax</th>\n",
       "      <th>dmin</th>\n",
       "      <th>...</th>\n",
       "      <th>wdct_1</th>\n",
       "      <th>wdct_2</th>\n",
       "      <th>wdct_3</th>\n",
       "      <th>wdct_4</th>\n",
       "      <th>wdct_5</th>\n",
       "      <th>gust_1</th>\n",
       "      <th>gust_2</th>\n",
       "      <th>gust_3</th>\n",
       "      <th>gust_4</th>\n",
       "      <th>gust_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   prcp  stp  smax  smin  temp  tmax  tmin  dewp  dmax  dmin   ...    wdct_1  \\\n",
       "5   0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   ...       0.0   \n",
       "6   0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   ...       0.0   \n",
       "7   0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   ...       0.0   \n",
       "8   0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   ...       0.0   \n",
       "9   0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   ...       0.0   \n",
       "\n",
       "   wdct_2  wdct_3  wdct_4  wdct_5  gust_1  gust_2  gust_3  gust_4  gust_5  \n",
       "5     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "6     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "7     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "8     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "9     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wdsp', 'prcp', 'gust']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAN_BE_NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preparando a base</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Removendo registros que não pode ser nulos e prejudicariam o treinamento</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(dfm.columns)\n",
    "\n",
    "COLS_BE_NULL = ['prcp','wdsp','wdsp_1','wdsp_2','wdsp_3','wdsp_4','wdsp_5',\\\n",
    "                'gust','gust_1','gust_2','gust_3','gust_4','gust_5']\n",
    "for v in COLS_BE_NULL:\n",
    "    cols.remove(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prcp</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>dewp</th>\n",
       "      <th>dmax</th>\n",
       "      <th>dmin</th>\n",
       "      <th>...</th>\n",
       "      <th>wdct_1</th>\n",
       "      <th>wdct_2</th>\n",
       "      <th>wdct_3</th>\n",
       "      <th>wdct_4</th>\n",
       "      <th>wdct_5</th>\n",
       "      <th>gust_1</th>\n",
       "      <th>gust_2</th>\n",
       "      <th>gust_3</th>\n",
       "      <th>gust_4</th>\n",
       "      <th>gust_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   prcp  stp  smax  smin  temp  tmax  tmin  dewp  dmax  dmin   ...    wdct_1  \\\n",
       "5   0.0  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   ...       NaN   \n",
       "6   0.0  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   ...       NaN   \n",
       "7   0.0  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   ...       NaN   \n",
       "8   0.0  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   ...       NaN   \n",
       "9   0.0  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   ...       NaN   \n",
       "\n",
       "   wdct_2  wdct_3  wdct_4  wdct_5  gust_1  gust_2  gust_3  gust_4  gust_5  \n",
       "5     NaN     NaN     NaN     NaN     0.0     0.0     0.0     0.0     0.0  \n",
       "6     NaN     NaN     NaN     NaN     0.0     0.0     0.0     0.0     0.0  \n",
       "7     NaN     NaN     NaN     NaN     0.0     0.0     0.0     0.0     0.0  \n",
       "8     NaN     NaN     NaN     NaN     0.0     0.0     0.0     0.0     0.0  \n",
       "9     NaN     NaN     NaN     NaN     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm[cols] = dfm[cols].replace({0.0:np.nan})\n",
    "dfm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = dfm.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86007"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prcp</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>dewp</th>\n",
       "      <th>dmax</th>\n",
       "      <th>dmin</th>\n",
       "      <th>...</th>\n",
       "      <th>wdct_1</th>\n",
       "      <th>wdct_2</th>\n",
       "      <th>wdct_3</th>\n",
       "      <th>wdct_4</th>\n",
       "      <th>wdct_5</th>\n",
       "      <th>gust_1</th>\n",
       "      <th>gust_2</th>\n",
       "      <th>gust_3</th>\n",
       "      <th>gust_4</th>\n",
       "      <th>gust_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>922.2</td>\n",
       "      <td>922.0</td>\n",
       "      <td>21.4</td>\n",
       "      <td>14.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>13.7</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>922.1</td>\n",
       "      <td>922.2</td>\n",
       "      <td>922.0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>14.8</td>\n",
       "      <td>21.4</td>\n",
       "      <td>14.9</td>\n",
       "      <td>20.7</td>\n",
       "      <td>14.2</td>\n",
       "      <td>...</td>\n",
       "      <td>118.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>921.9</td>\n",
       "      <td>922.1</td>\n",
       "      <td>921.8</td>\n",
       "      <td>20.3</td>\n",
       "      <td>14.9</td>\n",
       "      <td>20.8</td>\n",
       "      <td>15.1</td>\n",
       "      <td>20.3</td>\n",
       "      <td>14.7</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>921.6</td>\n",
       "      <td>922.1</td>\n",
       "      <td>921.6</td>\n",
       "      <td>20.1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>20.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>...</td>\n",
       "      <td>118.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>921.8</td>\n",
       "      <td>921.8</td>\n",
       "      <td>921.5</td>\n",
       "      <td>19.8</td>\n",
       "      <td>13.9</td>\n",
       "      <td>20.2</td>\n",
       "      <td>14.2</td>\n",
       "      <td>19.8</td>\n",
       "      <td>13.7</td>\n",
       "      <td>...</td>\n",
       "      <td>102.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    prcp    stp   smax   smin  temp  tmax  tmin  dewp  dmax  dmin   ...    \\\n",
       "19   0.0  922.0  922.2  922.0  21.4  14.2  22.0  15.0  21.3  13.7   ...     \n",
       "20   0.0  922.1  922.2  922.0  20.7  14.8  21.4  14.9  20.7  14.2   ...     \n",
       "21   0.0  921.9  922.1  921.8  20.3  14.9  20.8  15.1  20.3  14.7   ...     \n",
       "22   0.0  921.6  922.1  921.6  20.1  14.2  20.4  15.0  20.0  14.2   ...     \n",
       "23   0.0  921.8  921.8  921.5  19.8  13.9  20.2  14.2  19.8  13.7   ...     \n",
       "\n",
       "    wdct_1  wdct_2  wdct_3  wdct_4  wdct_5  gust_1  gust_2  gust_3  gust_4  \\\n",
       "19    59.0    61.0    69.0    98.0    75.0     6.9     8.0     7.3     8.8   \n",
       "20   118.0    59.0    61.0    69.0    98.0     7.5     6.9     8.0     7.3   \n",
       "21   108.0   118.0    59.0    61.0    69.0     7.7     7.5     6.9     8.0   \n",
       "22   118.0   108.0   118.0    59.0    61.0     7.6     7.7     7.5     6.9   \n",
       "23   102.0   118.0   108.0   118.0    59.0     7.3     7.6     7.7     7.5   \n",
       "\n",
       "    gust_5  \n",
       "19     8.8  \n",
       "20     8.8  \n",
       "21     7.3  \n",
       "22     8.0  \n",
       "23     6.9  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mineiração dos dados</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Rede neural</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  \n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error,  median_absolute_error\n",
    "from sklearn.model_selection import train_test_split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'prcp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfm[[col for col in dfm.columns if col != target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dfm[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>dewp</th>\n",
       "      <th>dmax</th>\n",
       "      <th>dmin</th>\n",
       "      <th>hmdy</th>\n",
       "      <th>...</th>\n",
       "      <th>wdct_1</th>\n",
       "      <th>wdct_2</th>\n",
       "      <th>wdct_3</th>\n",
       "      <th>wdct_4</th>\n",
       "      <th>wdct_5</th>\n",
       "      <th>gust_1</th>\n",
       "      <th>gust_2</th>\n",
       "      <th>gust_3</th>\n",
       "      <th>gust_4</th>\n",
       "      <th>gust_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>922.0</td>\n",
       "      <td>922.2</td>\n",
       "      <td>922.0</td>\n",
       "      <td>21.4</td>\n",
       "      <td>14.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>13.7</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>922.1</td>\n",
       "      <td>922.2</td>\n",
       "      <td>922.0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>14.8</td>\n",
       "      <td>21.4</td>\n",
       "      <td>14.9</td>\n",
       "      <td>20.7</td>\n",
       "      <td>14.2</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>118.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>921.9</td>\n",
       "      <td>922.1</td>\n",
       "      <td>921.8</td>\n",
       "      <td>20.3</td>\n",
       "      <td>14.9</td>\n",
       "      <td>20.8</td>\n",
       "      <td>15.1</td>\n",
       "      <td>20.3</td>\n",
       "      <td>14.7</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>921.6</td>\n",
       "      <td>922.1</td>\n",
       "      <td>921.6</td>\n",
       "      <td>20.1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>20.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>118.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>921.8</td>\n",
       "      <td>921.8</td>\n",
       "      <td>921.5</td>\n",
       "      <td>19.8</td>\n",
       "      <td>13.9</td>\n",
       "      <td>20.2</td>\n",
       "      <td>14.2</td>\n",
       "      <td>19.8</td>\n",
       "      <td>13.7</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>102.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stp   smax   smin  temp  tmax  tmin  dewp  dmax  dmin  hmdy   ...    \\\n",
       "19  922.0  922.2  922.0  21.4  14.2  22.0  15.0  21.3  13.7  64.0   ...     \n",
       "20  922.1  922.2  922.0  20.7  14.8  21.4  14.9  20.7  14.2  69.0   ...     \n",
       "21  921.9  922.1  921.8  20.3  14.9  20.8  15.1  20.3  14.7  71.0   ...     \n",
       "22  921.6  922.1  921.6  20.1  14.2  20.4  15.0  20.0  14.2  69.0   ...     \n",
       "23  921.8  921.8  921.5  19.8  13.9  20.2  14.2  19.8  13.7  69.0   ...     \n",
       "\n",
       "    wdct_1  wdct_2  wdct_3  wdct_4  wdct_5  gust_1  gust_2  gust_3  gust_4  \\\n",
       "19    59.0    61.0    69.0    98.0    75.0     6.9     8.0     7.3     8.8   \n",
       "20   118.0    59.0    61.0    69.0    98.0     7.5     6.9     8.0     7.3   \n",
       "21   108.0   118.0    59.0    61.0    69.0     7.7     7.5     6.9     8.0   \n",
       "22   118.0   108.0   118.0    59.0    61.0     7.6     7.7     7.5     6.9   \n",
       "23   102.0   118.0   108.0   118.0    59.0     7.3     7.6     7.7     7.5   \n",
       "\n",
       "    gust_5  \n",
       "19     8.8  \n",
       "20     8.8  \n",
       "21     7.3  \n",
       "22     8.0  \n",
       "23     6.9  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Separando o conjunto de treinamento e validação</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Separando o conjunto de testes (metade dos 30% separados para validação)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_val, y_test, y_val = train_test_split(X_tmp, y_tmp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances   60204, Training features   90\n",
      "Validation instances 12902, Validation features 90\n",
      "Testing instances    12901, Testing features    90\n"
     ]
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_val.shape  \n",
    "print(\"Training instances   {}, Training features   {}\".format(X_train.shape[0], X_train.shape[1]))  \n",
    "print(\"Validation instances {}, Validation features {}\".format(X_val.shape[0], X_val.shape[1]))  \n",
    "print(\"Testing instances    {}, Testing features    {}\".format(X_test.shape[0], X_test.shape[1]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zarate instructions\n",
    "st_units = (X_train.shape[1] * 2) + 1\n",
    "sd_units = X_train.shape[1] \n",
    "activation_fn = tf.sigmoid\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [tf.feature_column.numeric_column(col) for col in X.columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4ba71f6450>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tf_wx_model-4', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.estimator.DNNRegressor(feature_columns=feature_cols,  \n",
    "                                      hidden_units=[st_units,sd_units],\n",
    "                                      activation_fn=activation_fn,\n",
    "                                      model_dir='/tmp/tf_wx_model-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wx_input_fn(X, y=None, num_epochs=None, shuffle=True, batch_size=batch_size):  \n",
    "    return tf.estimator.inputs.pandas_input_fn(x=X,\n",
    "                                               y=y,\n",
    "                                               num_epochs=num_epochs,\n",
    "                                               shuffle=shuffle,\n",
    "                                               batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 2847.8013, step = 1\n",
      "INFO:tensorflow:global_step/sec: 10.4885\n",
      "INFO:tensorflow:loss = 5916.834, step = 101 (9.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8862\n",
      "INFO:tensorflow:loss = 1407.6049, step = 201 (9.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9546\n",
      "INFO:tensorflow:loss = 1852.291, step = 301 (9.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9103\n",
      "INFO:tensorflow:loss = 2092.1833, step = 401 (9.167 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3728.1875.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:28:45\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:28:47\n",
      "INFO:tensorflow:Saving dict for global step 500: average_loss = 1.8468792, global_step = 500, loss = 1832.9565\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-500\n",
      "INFO:tensorflow:Saving checkpoints for 501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 4847.694, step = 501\n",
      "INFO:tensorflow:global_step/sec: 10.8884\n",
      "INFO:tensorflow:loss = 813.1563, step = 601 (9.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0074\n",
      "INFO:tensorflow:loss = 2243.876, step = 701 (9.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2555\n",
      "INFO:tensorflow:loss = 2827.8762, step = 801 (8.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0644\n",
      "INFO:tensorflow:loss = 1419.2925, step = 901 (9.033 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4127.2935.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:29:36\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:29:37\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 1.8557099, global_step = 1000, loss = 1841.7207\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-1000\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 2149.861, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 10.6806\n",
      "INFO:tensorflow:loss = 1444.9526, step = 1101 (9.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0725\n",
      "INFO:tensorflow:loss = 6857.311, step = 1201 (9.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9205\n",
      "INFO:tensorflow:loss = 1655.5836, step = 1301 (9.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8366\n",
      "INFO:tensorflow:loss = 3679.25, step = 1401 (9.228 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1964.2671.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:30:27\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-1500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:30:28\n",
      "INFO:tensorflow:Saving dict for global step 1500: average_loss = 1.8476968, global_step = 1500, loss = 1833.7681\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-1500\n",
      "INFO:tensorflow:Saving checkpoints for 1501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 2731.6792, step = 1501\n",
      "INFO:tensorflow:global_step/sec: 10.667\n",
      "INFO:tensorflow:loss = 5451.1006, step = 1601 (9.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9503\n",
      "INFO:tensorflow:loss = 3220.0208, step = 1701 (9.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2004\n",
      "INFO:tensorflow:loss = 1910.2341, step = 1801 (8.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8347\n",
      "INFO:tensorflow:loss = 3015.8975, step = 1901 (9.231 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1259.364.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:31:17\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:31:19\n",
      "INFO:tensorflow:Saving dict for global step 2000: average_loss = 1.8485402, global_step = 2000, loss = 1834.605\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-2000\n",
      "INFO:tensorflow:Saving checkpoints for 2001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 5022.1357, step = 2001\n",
      "INFO:tensorflow:global_step/sec: 10.961\n",
      "INFO:tensorflow:loss = 817.9922, step = 2101 (9.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8973\n",
      "INFO:tensorflow:loss = 2643.3179, step = 2201 (9.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0432\n",
      "INFO:tensorflow:loss = 1341.2825, step = 2301 (9.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2334\n",
      "INFO:tensorflow:loss = 1046.0203, step = 2401 (8.903 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3771.6992.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:32:08\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-2500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:32:09\n",
      "INFO:tensorflow:Saving dict for global step 2500: average_loss = 1.8522139, global_step = 2500, loss = 1838.2511\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-2500\n",
      "INFO:tensorflow:Saving checkpoints for 2501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 889.91895, step = 2501\n",
      "INFO:tensorflow:global_step/sec: 11.0135\n",
      "INFO:tensorflow:loss = 3657.0457, step = 2601 (9.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2562\n",
      "INFO:tensorflow:loss = 4109.58, step = 2701 (8.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0137\n",
      "INFO:tensorflow:loss = 1533.9062, step = 2801 (9.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7465\n",
      "INFO:tensorflow:loss = 5110.253, step = 2901 (9.306 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4176.9463.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:32:58\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-3000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:32:59\n",
      "INFO:tensorflow:Saving dict for global step 3000: average_loss = 1.8491666, global_step = 3000, loss = 1835.2267\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-3000\n",
      "INFO:tensorflow:Saving checkpoints for 3001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 3252.0278, step = 3001\n",
      "INFO:tensorflow:global_step/sec: 10.9161\n",
      "INFO:tensorflow:loss = 2890.2183, step = 3101 (9.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1156\n",
      "INFO:tensorflow:loss = 6193.792, step = 3201 (8.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3592\n",
      "INFO:tensorflow:loss = 1298.5674, step = 3301 (8.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0333\n",
      "INFO:tensorflow:loss = 2674.087, step = 3401 (9.064 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4011.232.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:33:48\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-3500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:33:49\n",
      "INFO:tensorflow:Saving dict for global step 3500: average_loss = 1.8481841, global_step = 3500, loss = 1834.2517\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-3500\n",
      "INFO:tensorflow:Saving checkpoints for 3501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 5155.454, step = 3501\n",
      "INFO:tensorflow:global_step/sec: 10.8577\n",
      "INFO:tensorflow:loss = 3310.379, step = 3601 (9.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0954\n",
      "INFO:tensorflow:loss = 1378.8407, step = 3701 (9.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.049\n",
      "INFO:tensorflow:loss = 4128.804, step = 3801 (9.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8863\n",
      "INFO:tensorflow:loss = 3261.425, step = 3901 (9.186 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 463.6473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:34:38\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-4000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:34:40\n",
      "INFO:tensorflow:Saving dict for global step 4000: average_loss = 1.8479578, global_step = 4000, loss = 1834.0271\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-4000\n",
      "INFO:tensorflow:Saving checkpoints for 4001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 685.4769, step = 4001\n",
      "INFO:tensorflow:global_step/sec: 10.9946\n",
      "INFO:tensorflow:loss = 4463.831, step = 4101 (9.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1536\n",
      "INFO:tensorflow:loss = 1814.4872, step = 4201 (8.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8291\n",
      "INFO:tensorflow:loss = 3237.623, step = 4301 (9.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0885\n",
      "INFO:tensorflow:loss = 7650.471, step = 4401 (9.018 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1622.3955.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:35:29\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-4500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:35:30\n",
      "INFO:tensorflow:Saving dict for global step 4500: average_loss = 1.8475368, global_step = 4500, loss = 1833.6093\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-4500\n",
      "INFO:tensorflow:Saving checkpoints for 4501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 4239.1924, step = 4501\n",
      "INFO:tensorflow:global_step/sec: 10.7879\n",
      "INFO:tensorflow:loss = 2719.4531, step = 4601 (9.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7594\n",
      "INFO:tensorflow:loss = 3187.849, step = 4701 (9.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.971\n",
      "INFO:tensorflow:loss = 4138.912, step = 4801 (9.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2061\n",
      "INFO:tensorflow:loss = 4096.662, step = 4901 (8.923 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1131.5298.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:36:19\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-5000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:36:21\n",
      "INFO:tensorflow:Saving dict for global step 5000: average_loss = 1.8468843, global_step = 5000, loss = 1832.9615\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-5000\n",
      "INFO:tensorflow:Saving checkpoints for 5001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 1151.3265, step = 5001\n",
      "INFO:tensorflow:global_step/sec: 10.8152\n",
      "INFO:tensorflow:loss = 2850.7324, step = 5101 (9.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0514\n",
      "INFO:tensorflow:loss = 9452.142, step = 5201 (9.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0901\n",
      "INFO:tensorflow:loss = 1109.8661, step = 5301 (9.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0779\n",
      "INFO:tensorflow:loss = 3496.785, step = 5401 (9.028 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4299.3794.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:37:10\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-5500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:37:11\n",
      "INFO:tensorflow:Saving dict for global step 5500: average_loss = 1.8482642, global_step = 5500, loss = 1834.3312\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-5500\n",
      "INFO:tensorflow:Saving checkpoints for 5501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 4031.1577, step = 5501\n",
      "INFO:tensorflow:global_step/sec: 10.9459\n",
      "INFO:tensorflow:loss = 1889.9878, step = 5601 (9.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1405\n",
      "INFO:tensorflow:loss = 1272.384, step = 5701 (8.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9563\n",
      "INFO:tensorflow:loss = 3645.3962, step = 5801 (9.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8565\n",
      "INFO:tensorflow:loss = 1087.3632, step = 5901 (9.211 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 539.3425.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:38:00\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-6000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:38:02\n",
      "INFO:tensorflow:Saving dict for global step 6000: average_loss = 1.8466713, global_step = 6000, loss = 1832.7502\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-6000\n",
      "INFO:tensorflow:Saving checkpoints for 6001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 3346.6733, step = 6001\n",
      "INFO:tensorflow:global_step/sec: 10.9783\n",
      "INFO:tensorflow:loss = 4564.534, step = 6101 (9.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8324\n",
      "INFO:tensorflow:loss = 5562.3384, step = 6201 (9.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2017\n",
      "INFO:tensorflow:loss = 1032.3733, step = 6301 (8.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8376\n",
      "INFO:tensorflow:loss = 2711.9111, step = 6401 (9.227 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5886.006.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:38:51\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-6500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:38:52\n",
      "INFO:tensorflow:Saving dict for global step 6500: average_loss = 1.8492503, global_step = 6500, loss = 1835.3098\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-6500\n",
      "INFO:tensorflow:Saving checkpoints for 6501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 1533.5957, step = 6501\n",
      "INFO:tensorflow:global_step/sec: 10.9968\n",
      "INFO:tensorflow:loss = 3047.3528, step = 6601 (9.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7478\n",
      "INFO:tensorflow:loss = 2407.1826, step = 6701 (9.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9293\n",
      "INFO:tensorflow:loss = 1408.355, step = 6801 (9.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1446\n",
      "INFO:tensorflow:loss = 2792.609, step = 6901 (8.973 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2345.3025.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:39:42\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-7000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:39:43\n",
      "INFO:tensorflow:Saving dict for global step 7000: average_loss = 1.8473624, global_step = 7000, loss = 1833.4362\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-7000\n",
      "INFO:tensorflow:Saving checkpoints for 7001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 1657.1062, step = 7001\n",
      "INFO:tensorflow:global_step/sec: 10.8621\n",
      "INFO:tensorflow:loss = 2447.594, step = 7101 (9.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9653\n",
      "INFO:tensorflow:loss = 5254.359, step = 7201 (9.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1957\n",
      "INFO:tensorflow:loss = 1675.837, step = 7301 (8.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.171\n",
      "INFO:tensorflow:loss = 2228.106, step = 7401 (8.952 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3167.3599.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:40:32\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-7500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:40:33\n",
      "INFO:tensorflow:Saving dict for global step 7500: average_loss = 1.8471714, global_step = 7500, loss = 1833.2466\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-7500\n",
      "INFO:tensorflow:Saving checkpoints for 7501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 549.7821, step = 7501\n",
      "INFO:tensorflow:global_step/sec: 11.103\n",
      "INFO:tensorflow:loss = 4996.5664, step = 7601 (9.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4779.628, step = 7701 (9.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0762\n",
      "INFO:tensorflow:loss = 1321.1809, step = 7801 (9.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9271\n",
      "INFO:tensorflow:loss = 2470.9387, step = 7901 (9.149 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5578.8857.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:41:22\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-8000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:41:23\n",
      "INFO:tensorflow:Saving dict for global step 8000: average_loss = 1.8490335, global_step = 8000, loss = 1835.0946\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-8000\n",
      "INFO:tensorflow:Saving checkpoints for 8001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 2026.7012, step = 8001\n",
      "INFO:tensorflow:global_step/sec: 10.7845\n",
      "INFO:tensorflow:loss = 5447.6895, step = 8101 (9.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9671\n",
      "INFO:tensorflow:loss = 2692.2178, step = 8201 (9.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0351\n",
      "INFO:tensorflow:loss = 2815.35, step = 8301 (9.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2518\n",
      "INFO:tensorflow:loss = 1490.8647, step = 8401 (8.888 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2159.7512.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:42:12\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-8500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:42:14\n",
      "INFO:tensorflow:Saving dict for global step 8500: average_loss = 1.8477376, global_step = 8500, loss = 1833.8085\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-8500\n",
      "INFO:tensorflow:Saving checkpoints for 8501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 446.96442, step = 8501\n",
      "INFO:tensorflow:global_step/sec: 10.8225\n",
      "INFO:tensorflow:loss = 4361.414, step = 8601 (9.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0162\n",
      "INFO:tensorflow:loss = 3732.1958, step = 8701 (9.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9173\n",
      "INFO:tensorflow:loss = 2587.341, step = 8801 (9.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9821\n",
      "INFO:tensorflow:loss = 4611.861, step = 8901 (9.108 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5716.3735.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:43:03\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-9000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:43:04\n",
      "INFO:tensorflow:Saving dict for global step 9000: average_loss = 1.8465786, global_step = 9000, loss = 1832.6582\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-9000\n",
      "INFO:tensorflow:Saving checkpoints for 9001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 3369.984, step = 9001\n",
      "INFO:tensorflow:global_step/sec: 10.8688\n",
      "INFO:tensorflow:loss = 1669.0374, step = 9101 (9.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7736\n",
      "INFO:tensorflow:loss = 1451.323, step = 9201 (9.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0483\n",
      "INFO:tensorflow:loss = 4035.2927, step = 9301 (9.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2025\n",
      "INFO:tensorflow:loss = 1666.2716, step = 9401 (8.926 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2640.5752.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:43:54\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-9500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:43:55\n",
      "INFO:tensorflow:Saving dict for global step 9500: average_loss = 1.8473448, global_step = 9500, loss = 1833.4186\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-9500\n",
      "INFO:tensorflow:Saving checkpoints for 9501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 6081.839, step = 9501\n",
      "INFO:tensorflow:global_step/sec: 11.0368\n",
      "INFO:tensorflow:loss = 1028.0, step = 9601 (9.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0477\n",
      "INFO:tensorflow:loss = 4949.363, step = 9701 (9.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2227\n",
      "INFO:tensorflow:loss = 2329.103, step = 9801 (8.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0888\n",
      "INFO:tensorflow:loss = 889.1655, step = 9901 (9.018 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5574.5977.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:44:44\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:44:45\n",
      "INFO:tensorflow:Saving dict for global step 10000: average_loss = 1.8480247, global_step = 10000, loss = 1834.0935\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-10000\n",
      "INFO:tensorflow:Saving checkpoints for 10001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 4332.2373, step = 10001\n",
      "INFO:tensorflow:global_step/sec: 10.8864\n",
      "INFO:tensorflow:loss = 2328.7942, step = 10101 (9.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0346\n",
      "INFO:tensorflow:loss = 1624.0061, step = 10201 (9.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.904\n",
      "INFO:tensorflow:loss = 1924.604, step = 10301 (9.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9743\n",
      "INFO:tensorflow:loss = 7384.671, step = 10401 (9.112 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2447.2925.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:45:34\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-10500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:45:36\n",
      "INFO:tensorflow:Saving dict for global step 10500: average_loss = 1.8466915, global_step = 10500, loss = 1832.7703\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-10500\n",
      "INFO:tensorflow:Saving checkpoints for 10501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 3124.5398, step = 10501\n",
      "INFO:tensorflow:global_step/sec: 10.8738\n",
      "INFO:tensorflow:loss = 522.37646, step = 10601 (9.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0753\n",
      "INFO:tensorflow:loss = 2543.9526, step = 10701 (9.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0105\n",
      "INFO:tensorflow:loss = 3005.6306, step = 10801 (9.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2083\n",
      "INFO:tensorflow:loss = 3458.3987, step = 10901 (8.922 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 616.2256.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:46:25\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-11000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:46:26\n",
      "INFO:tensorflow:Saving dict for global step 11000: average_loss = 1.847493, global_step = 11000, loss = 1833.5658\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-11000\n",
      "INFO:tensorflow:Saving checkpoints for 11001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 1427.5117, step = 11001\n",
      "INFO:tensorflow:global_step/sec: 10.8959\n",
      "INFO:tensorflow:loss = 2446.8193, step = 11101 (9.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2771\n",
      "INFO:tensorflow:loss = 1416.2742, step = 11201 (8.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8705\n",
      "INFO:tensorflow:loss = 1791.53, step = 11301 (9.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8601\n",
      "INFO:tensorflow:loss = 6608.543, step = 11401 (9.208 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2668.3262.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:47:16\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-11500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:47:17\n",
      "INFO:tensorflow:Saving dict for global step 11500: average_loss = 1.847827, global_step = 11500, loss = 1833.8972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-11500\n",
      "INFO:tensorflow:Saving checkpoints for 11501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 1469.0344, step = 11501\n",
      "INFO:tensorflow:global_step/sec: 10.9287\n",
      "INFO:tensorflow:loss = 4147.156, step = 11601 (9.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9202\n",
      "INFO:tensorflow:loss = 2733.621, step = 11701 (9.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0572\n",
      "INFO:tensorflow:loss = 559.93445, step = 11801 (9.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1953\n",
      "INFO:tensorflow:loss = 5352.1753, step = 11901 (8.932 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1360.8098.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:48:06\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-12000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:48:08\n",
      "INFO:tensorflow:Saving dict for global step 12000: average_loss = 1.8465893, global_step = 12000, loss = 1832.6688\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-12000\n",
      "INFO:tensorflow:Saving checkpoints for 12001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 1354.8187, step = 12001\n",
      "INFO:tensorflow:global_step/sec: 10.9055\n",
      "INFO:tensorflow:loss = 2410.1587, step = 12101 (9.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2691\n",
      "INFO:tensorflow:loss = 3291.751, step = 12201 (8.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2325\n",
      "INFO:tensorflow:loss = 2168.0066, step = 12301 (8.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0144\n",
      "INFO:tensorflow:loss = 2790.0286, step = 12401 (9.080 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7447.0537.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:48:56\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-12500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:48:58\n",
      "INFO:tensorflow:Saving dict for global step 12500: average_loss = 1.8470992, global_step = 12500, loss = 1833.1749\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-12500\n",
      "INFO:tensorflow:Saving checkpoints for 12501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 1296.01, step = 12501\n",
      "INFO:tensorflow:global_step/sec: 10.8395\n",
      "INFO:tensorflow:loss = 1416.4717, step = 12601 (9.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3889\n",
      "INFO:tensorflow:loss = 4591.256, step = 12701 (8.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2437\n",
      "INFO:tensorflow:loss = 9334.555, step = 12801 (8.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0595\n",
      "INFO:tensorflow:loss = 1385.9882, step = 12901 (9.042 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1527.0127.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:49:46\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-13000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:49:48\n",
      "INFO:tensorflow:Saving dict for global step 13000: average_loss = 1.8471794, global_step = 13000, loss = 1833.2545\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-13000\n",
      "INFO:tensorflow:Saving checkpoints for 13001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 2019.7238, step = 13001\n",
      "INFO:tensorflow:global_step/sec: 10.7977\n",
      "INFO:tensorflow:loss = 5270.3115, step = 13101 (9.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9407\n",
      "INFO:tensorflow:loss = 916.2666, step = 13201 (9.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2753\n",
      "INFO:tensorflow:loss = 1808.4823, step = 13301 (8.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1253\n",
      "INFO:tensorflow:loss = 3683.8396, step = 13401 (8.989 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 758.75635.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:50:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-13500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:50:38\n",
      "INFO:tensorflow:Saving dict for global step 13500: average_loss = 1.8465726, global_step = 13500, loss = 1832.6523\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-13500\n",
      "INFO:tensorflow:Saving checkpoints for 13501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 1099.9402, step = 13501\n",
      "INFO:tensorflow:global_step/sec: 10.608\n",
      "INFO:tensorflow:loss = 1971.4786, step = 13601 (9.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8313\n",
      "INFO:tensorflow:loss = 1222.7646, step = 13701 (9.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7175\n",
      "INFO:tensorflow:loss = 5024.4736, step = 13801 (9.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.54\n",
      "INFO:tensorflow:loss = 2010.3395, step = 13901 (9.484 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3955.7935.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:51:28\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-14000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:51:30\n",
      "INFO:tensorflow:Saving dict for global step 14000: average_loss = 1.8478588, global_step = 14000, loss = 1833.9288\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-14000\n",
      "INFO:tensorflow:Saving checkpoints for 14001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 3624.8848, step = 14001\n",
      "INFO:tensorflow:global_step/sec: 10.7383\n",
      "INFO:tensorflow:loss = 574.9038, step = 14101 (9.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6767\n",
      "INFO:tensorflow:loss = 2303.855, step = 14201 (9.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8436\n",
      "INFO:tensorflow:loss = 946.1458, step = 14301 (9.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6653\n",
      "INFO:tensorflow:loss = 1685.0481, step = 14401 (9.376 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5345.6323.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:52:20\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-14500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:52:21\n",
      "INFO:tensorflow:Saving dict for global step 14500: average_loss = 1.8484433, global_step = 14500, loss = 1834.5089\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-14500\n",
      "INFO:tensorflow:Saving checkpoints for 14501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 250.92014, step = 14501\n",
      "INFO:tensorflow:global_step/sec: 10.6186\n",
      "INFO:tensorflow:loss = 8220.613, step = 14601 (9.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7533\n",
      "INFO:tensorflow:loss = 6609.7646, step = 14701 (9.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7951\n",
      "INFO:tensorflow:loss = 1793.6669, step = 14801 (9.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8462\n",
      "INFO:tensorflow:loss = 3812.4556, step = 14901 (9.219 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3159.96.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:53:12\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-15000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:53:14\n",
      "INFO:tensorflow:Saving dict for global step 15000: average_loss = 1.8477285, global_step = 15000, loss = 1833.7994\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-15000\n",
      "INFO:tensorflow:Saving checkpoints for 15001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 798.81, step = 15001\n",
      "INFO:tensorflow:global_step/sec: 10.4044\n",
      "INFO:tensorflow:loss = 4075.648, step = 15101 (9.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7493\n",
      "INFO:tensorflow:loss = 1321.3257, step = 15201 (9.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7742\n",
      "INFO:tensorflow:loss = 2948.6887, step = 15301 (9.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4804.6104, step = 15401 (9.179 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2154.1318.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:54:04\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-15500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:54:05\n",
      "INFO:tensorflow:Saving dict for global step 15500: average_loss = 1.8476561, global_step = 15500, loss = 1833.7277\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-15500\n",
      "INFO:tensorflow:Saving checkpoints for 15501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 2908.2236, step = 15501\n",
      "INFO:tensorflow:global_step/sec: 10.4944\n",
      "INFO:tensorflow:loss = 2610.5708, step = 15601 (9.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5471\n",
      "INFO:tensorflow:loss = 815.10254, step = 15701 (9.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8641\n",
      "INFO:tensorflow:loss = 3097.0618, step = 15801 (9.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5614\n",
      "INFO:tensorflow:loss = 6654.3003, step = 15901 (9.473 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1620.2085.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:54:56\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-16000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:54:57\n",
      "INFO:tensorflow:Saving dict for global step 16000: average_loss = 1.8465972, global_step = 16000, loss = 1832.6766\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-16000\n",
      "INFO:tensorflow:Saving checkpoints for 16001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 1145.0322, step = 16001\n",
      "INFO:tensorflow:global_step/sec: 10.0995\n",
      "INFO:tensorflow:loss = 5382.031, step = 16101 (9.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1905\n",
      "INFO:tensorflow:loss = 3669.0083, step = 16201 (8.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.061\n",
      "INFO:tensorflow:loss = 1846.436, step = 16301 (9.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9249\n",
      "INFO:tensorflow:loss = 1787.3347, step = 16401 (9.154 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 870.96564.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:55:47\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-16500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:55:49\n",
      "INFO:tensorflow:Saving dict for global step 16500: average_loss = 1.846604, global_step = 16500, loss = 1832.6835\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-16500\n",
      "INFO:tensorflow:Saving checkpoints for 16501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 1227.0614, step = 16501\n",
      "INFO:tensorflow:global_step/sec: 10.4355\n",
      "INFO:tensorflow:loss = 8071.3784, step = 16601 (9.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6172\n",
      "INFO:tensorflow:loss = 3560.5142, step = 16701 (9.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6511\n",
      "INFO:tensorflow:loss = 2381.7383, step = 16801 (9.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7729\n",
      "INFO:tensorflow:loss = 2440.9531, step = 16901 (9.283 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4503.35.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:56:39\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-17000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:56:40\n",
      "INFO:tensorflow:Saving dict for global step 17000: average_loss = 1.8477483, global_step = 17000, loss = 1833.8191\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-17000\n",
      "INFO:tensorflow:Saving checkpoints for 17001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 1601.7954, step = 17001\n",
      "INFO:tensorflow:global_step/sec: 10.5618\n",
      "INFO:tensorflow:loss = 1841.0387, step = 17101 (9.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6283\n",
      "INFO:tensorflow:loss = 829.93933, step = 17201 (9.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6429\n",
      "INFO:tensorflow:loss = 5222.741, step = 17301 (9.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9235\n",
      "INFO:tensorflow:loss = 2485.5562, step = 17401 (9.156 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2820.4045.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:57:31\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-17500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:57:33\n",
      "INFO:tensorflow:Saving dict for global step 17500: average_loss = 1.8474873, global_step = 17500, loss = 1833.56\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-17500\n",
      "INFO:tensorflow:Saving checkpoints for 17501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 3065.0488, step = 17501\n",
      "INFO:tensorflow:global_step/sec: 10.8408\n",
      "INFO:tensorflow:loss = 1127.3257, step = 17601 (9.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.871\n",
      "INFO:tensorflow:loss = 5975.623, step = 17701 (9.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9613\n",
      "INFO:tensorflow:loss = 5231.1807, step = 17801 (9.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.635\n",
      "INFO:tensorflow:loss = 1760.7114, step = 17901 (9.403 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 996.44855.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:58:22\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-18000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:58:24\n",
      "INFO:tensorflow:Saving dict for global step 18000: average_loss = 1.8466007, global_step = 18000, loss = 1832.6802\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-18000\n",
      "INFO:tensorflow:Saving checkpoints for 18001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 3083.96, step = 18001\n",
      "INFO:tensorflow:global_step/sec: 10.6458\n",
      "INFO:tensorflow:loss = 2612.645, step = 18101 (9.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8831\n",
      "INFO:tensorflow:loss = 4685.976, step = 18201 (9.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7831\n",
      "INFO:tensorflow:loss = 4226.1055, step = 18301 (9.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2515\n",
      "INFO:tensorflow:loss = 7725.0703, step = 18401 (8.888 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2765.0234.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-19:59:13\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-18500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-19:59:15\n",
      "INFO:tensorflow:Saving dict for global step 18500: average_loss = 1.8467494, global_step = 18500, loss = 1832.8279\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-18500\n",
      "INFO:tensorflow:Saving checkpoints for 18501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 6078.9834, step = 18501\n",
      "INFO:tensorflow:global_step/sec: 11.0067\n",
      "INFO:tensorflow:loss = 2813.9836, step = 18601 (9.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.898\n",
      "INFO:tensorflow:loss = 4228.798, step = 18701 (9.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0115\n",
      "INFO:tensorflow:loss = 1244.2307, step = 18801 (9.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0747\n",
      "INFO:tensorflow:loss = 966.58997, step = 18901 (9.030 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 481.72318.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:00:04\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-19000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:00:05\n",
      "INFO:tensorflow:Saving dict for global step 19000: average_loss = 1.8478273, global_step = 19000, loss = 1833.8976\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-19000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 19001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 5109.6396, step = 19001\n",
      "INFO:tensorflow:global_step/sec: 10.7089\n",
      "INFO:tensorflow:loss = 3090.7065, step = 19101 (9.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0901\n",
      "INFO:tensorflow:loss = 2475.3633, step = 19201 (9.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9351\n",
      "INFO:tensorflow:loss = 5274.248, step = 19301 (9.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6976\n",
      "INFO:tensorflow:loss = 2271.805, step = 19401 (9.348 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 760.1849.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:00:56\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-19500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:00:57\n",
      "INFO:tensorflow:Saving dict for global step 19500: average_loss = 1.8469272, global_step = 19500, loss = 1833.0042\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-19500\n",
      "INFO:tensorflow:Saving checkpoints for 19501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 565.6509, step = 19501\n",
      "INFO:tensorflow:global_step/sec: 11.0162\n",
      "INFO:tensorflow:loss = 3403.7153, step = 19601 (9.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.993\n",
      "INFO:tensorflow:loss = 4284.8457, step = 19701 (9.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9063\n",
      "INFO:tensorflow:loss = 3231.8738, step = 19801 (9.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6013\n",
      "INFO:tensorflow:loss = 3607.9998, step = 19901 (9.432 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5806.615.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:01:46\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-20000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:01:47\n",
      "INFO:tensorflow:Saving dict for global step 20000: average_loss = 1.8465728, global_step = 20000, loss = 1832.6525\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-20000\n",
      "INFO:tensorflow:Saving checkpoints for 20001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 4273.4644, step = 20001\n",
      "INFO:tensorflow:global_step/sec: 11.3728\n",
      "INFO:tensorflow:loss = 1744.7236, step = 20101 (8.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6902\n",
      "INFO:tensorflow:loss = 2796.268, step = 20201 (8.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6147\n",
      "INFO:tensorflow:loss = 5032.343, step = 20301 (8.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.538\n",
      "INFO:tensorflow:loss = 3574.99, step = 20401 (8.667 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3688.0142.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:02:34\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-20500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:02:35\n",
      "INFO:tensorflow:Saving dict for global step 20500: average_loss = 1.8472166, global_step = 20500, loss = 1833.2915\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-20500\n",
      "INFO:tensorflow:Saving checkpoints for 20501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 7229.917, step = 20501\n",
      "INFO:tensorflow:global_step/sec: 11.2647\n",
      "INFO:tensorflow:loss = 2363.7378, step = 20601 (8.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4809\n",
      "INFO:tensorflow:loss = 1558.2156, step = 20701 (8.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3366\n",
      "INFO:tensorflow:loss = 1122.262, step = 20801 (8.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1683\n",
      "INFO:tensorflow:loss = 1137.508, step = 20901 (8.954 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2542.4814.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:03:23\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-21000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:03:24\n",
      "INFO:tensorflow:Saving dict for global step 21000: average_loss = 1.846978, global_step = 21000, loss = 1833.0546\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-21000\n",
      "INFO:tensorflow:Saving checkpoints for 21001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 532.8761, step = 21001\n",
      "INFO:tensorflow:global_step/sec: 10.0432\n",
      "INFO:tensorflow:loss = 3488.9678, step = 21101 (9.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5505\n",
      "INFO:tensorflow:loss = 6585.9536, step = 21201 (9.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9657\n",
      "INFO:tensorflow:loss = 882.61145, step = 21301 (9.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5278\n",
      "INFO:tensorflow:loss = 4479.962, step = 21401 (8.675 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1567.3203.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:04:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-21500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:04:15\n",
      "INFO:tensorflow:Saving dict for global step 21500: average_loss = 1.8477938, global_step = 21500, loss = 1833.8644\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-21500\n",
      "INFO:tensorflow:Saving checkpoints for 21501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 1471.8704, step = 21501\n",
      "INFO:tensorflow:global_step/sec: 11.4614\n",
      "INFO:tensorflow:loss = 5932.392, step = 21601 (8.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2201\n",
      "INFO:tensorflow:loss = 1639.0044, step = 21701 (8.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.266\n",
      "INFO:tensorflow:loss = 2523.8123, step = 21801 (8.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0426\n",
      "INFO:tensorflow:loss = 1747.8717, step = 21901 (9.056 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3548.317.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:05:03\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-22000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:05:04\n",
      "INFO:tensorflow:Saving dict for global step 22000: average_loss = 1.8467889, global_step = 22000, loss = 1832.867\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-22000\n",
      "INFO:tensorflow:Saving checkpoints for 22001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 4700.042, step = 22001\n",
      "INFO:tensorflow:global_step/sec: 11.1684\n",
      "INFO:tensorflow:loss = 530.7778, step = 22101 (8.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4878\n",
      "INFO:tensorflow:loss = 429.19266, step = 22201 (8.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0659\n",
      "INFO:tensorflow:loss = 2761.9624, step = 22301 (9.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6955\n",
      "INFO:tensorflow:loss = 1204.4904, step = 22401 (9.350 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1783.476.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:05:53\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-22500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:05:54\n",
      "INFO:tensorflow:Saving dict for global step 22500: average_loss = 1.8478336, global_step = 22500, loss = 1833.9038\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-22500\n",
      "INFO:tensorflow:Saving checkpoints for 22501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 4374.698, step = 22501\n",
      "INFO:tensorflow:global_step/sec: 11.2987\n",
      "INFO:tensorflow:loss = 1331.3093, step = 22601 (8.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0935\n",
      "INFO:tensorflow:loss = 4270.665, step = 22701 (9.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8539\n",
      "INFO:tensorflow:loss = 2417.6738, step = 22801 (9.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2586\n",
      "INFO:tensorflow:loss = 813.06384, step = 22901 (8.882 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23000 into /tmp/tf_wx_model-4/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 7154.9565.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:06:42\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-23000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:06:44\n",
      "INFO:tensorflow:Saving dict for global step 23000: average_loss = 1.8475851, global_step = 23000, loss = 1833.6571\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-23000\n",
      "INFO:tensorflow:Saving checkpoints for 23001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 9053.396, step = 23001\n",
      "INFO:tensorflow:global_step/sec: 11.5433\n",
      "INFO:tensorflow:loss = 1315.8197, step = 23101 (8.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2609\n",
      "INFO:tensorflow:loss = 4860.8423, step = 23201 (8.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1022\n",
      "INFO:tensorflow:loss = 2302.1404, step = 23301 (9.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0962\n",
      "INFO:tensorflow:loss = 1176.9631, step = 23401 (9.012 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3265.701.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:07:32\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-23500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:07:33\n",
      "INFO:tensorflow:Saving dict for global step 23500: average_loss = 1.8472396, global_step = 23500, loss = 1833.3143\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-23500\n",
      "INFO:tensorflow:Saving checkpoints for 23501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 1233.7192, step = 23501\n",
      "INFO:tensorflow:global_step/sec: 10.643\n",
      "INFO:tensorflow:loss = 2828.8625, step = 23601 (9.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7351\n",
      "INFO:tensorflow:loss = 3680.4033, step = 23701 (9.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.235\n",
      "INFO:tensorflow:loss = 609.9897, step = 23801 (8.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2016\n",
      "INFO:tensorflow:loss = 6344.3594, step = 23901 (8.928 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2886.9343.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:08:22\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-24000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:08:24\n",
      "INFO:tensorflow:Saving dict for global step 24000: average_loss = 1.8478615, global_step = 24000, loss = 1833.9315\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-24000\n",
      "INFO:tensorflow:Saving checkpoints for 24001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 587.6852, step = 24001\n",
      "INFO:tensorflow:global_step/sec: 11.0513\n",
      "INFO:tensorflow:loss = 4105.8047, step = 24101 (9.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7075\n",
      "INFO:tensorflow:loss = 4996.31, step = 24201 (9.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7831\n",
      "INFO:tensorflow:loss = 3970.105, step = 24301 (9.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1856\n",
      "INFO:tensorflow:loss = 473.03775, step = 24401 (8.940 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5863.6426.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:09:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-24500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:09:15\n",
      "INFO:tensorflow:Saving dict for global step 24500: average_loss = 1.8466011, global_step = 24500, loss = 1832.6805\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-24500\n",
      "INFO:tensorflow:Saving checkpoints for 24501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 2395.6138, step = 24501\n",
      "INFO:tensorflow:global_step/sec: 11.463\n",
      "INFO:tensorflow:loss = 1776.6667, step = 24601 (8.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3727\n",
      "INFO:tensorflow:loss = 2034.7069, step = 24701 (8.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4916\n",
      "INFO:tensorflow:loss = 711.08704, step = 24801 (8.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0965\n",
      "INFO:tensorflow:loss = 2835.1147, step = 24901 (9.012 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5363.9727.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:10:03\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-25000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:10:04\n",
      "INFO:tensorflow:Saving dict for global step 25000: average_loss = 1.8466762, global_step = 25000, loss = 1832.7551\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-25000\n",
      "INFO:tensorflow:Saving checkpoints for 25001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 813.40283, step = 25001\n",
      "INFO:tensorflow:global_step/sec: 10.9769\n",
      "INFO:tensorflow:loss = 6733.814, step = 25101 (9.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3538\n",
      "INFO:tensorflow:loss = 5088.278, step = 25201 (8.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.8441\n",
      "INFO:tensorflow:loss = 2671.1455, step = 25301 (8.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7639\n",
      "INFO:tensorflow:loss = 3025.221, step = 25401 (8.500 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3496.9915.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:10:52\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-25500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:10:53\n",
      "INFO:tensorflow:Saving dict for global step 25500: average_loss = 1.8477947, global_step = 25500, loss = 1833.8651\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-25500\n",
      "INFO:tensorflow:Saving checkpoints for 25501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 1208.2937, step = 25501\n",
      "INFO:tensorflow:global_step/sec: 11.3591\n",
      "INFO:tensorflow:loss = 1111.74, step = 25601 (8.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.207\n",
      "INFO:tensorflow:loss = 1022.18896, step = 25701 (8.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.047\n",
      "INFO:tensorflow:loss = 5967.374, step = 25801 (9.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2951\n",
      "INFO:tensorflow:loss = 926.74725, step = 25901 (9.712 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1889.9365.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:11:44\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-26000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:11:46\n",
      "INFO:tensorflow:Saving dict for global step 26000: average_loss = 1.8487494, global_step = 26000, loss = 1834.8126\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-26000\n",
      "INFO:tensorflow:Saving checkpoints for 26001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 4863.486, step = 26001\n",
      "INFO:tensorflow:global_step/sec: 10.2808\n",
      "INFO:tensorflow:loss = 2873.7412, step = 26101 (9.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9623\n",
      "INFO:tensorflow:loss = 1133.5603, step = 26201 (9.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8878\n",
      "INFO:tensorflow:loss = 5858.825, step = 26301 (9.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5337\n",
      "INFO:tensorflow:loss = 3033.3447, step = 26401 (9.493 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1173.0527.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:12:36\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-26500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:12:38\n",
      "INFO:tensorflow:Saving dict for global step 26500: average_loss = 1.8468254, global_step = 26500, loss = 1832.9031\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-26500\n",
      "INFO:tensorflow:Saving checkpoints for 26501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 5045.669, step = 26501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 9.81942\n",
      "INFO:tensorflow:loss = 2201.0757, step = 26601 (10.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2485\n",
      "INFO:tensorflow:loss = 2811.58, step = 26701 (9.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3192\n",
      "INFO:tensorflow:loss = 3191.7192, step = 26801 (9.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5226\n",
      "INFO:tensorflow:loss = 3756.1025, step = 26901 (9.505 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 465.38766.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:13:30\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-27000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:13:32\n",
      "INFO:tensorflow:Saving dict for global step 27000: average_loss = 1.8474739, global_step = 27000, loss = 1833.5468\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-27000\n",
      "INFO:tensorflow:Saving checkpoints for 27001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 2272.8, step = 27001\n",
      "INFO:tensorflow:global_step/sec: 10.0483\n",
      "INFO:tensorflow:loss = 8235.879, step = 27101 (9.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4177\n",
      "INFO:tensorflow:loss = 2743.079, step = 27201 (9.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2455\n",
      "INFO:tensorflow:loss = 4012.3752, step = 27301 (9.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9436\n",
      "INFO:tensorflow:loss = 2731.226, step = 27401 (9.138 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2589.655.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:14:23\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-27500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:14:25\n",
      "INFO:tensorflow:Saving dict for global step 27500: average_loss = 1.8475955, global_step = 27500, loss = 1833.6674\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-27500\n",
      "INFO:tensorflow:Saving checkpoints for 27501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 4009.2593, step = 27501\n",
      "INFO:tensorflow:global_step/sec: 10.6349\n",
      "INFO:tensorflow:loss = 982.7575, step = 27601 (9.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.424\n",
      "INFO:tensorflow:loss = 4556.0034, step = 27701 (8.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2895\n",
      "INFO:tensorflow:loss = 2840.2734, step = 27801 (8.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0178\n",
      "INFO:tensorflow:loss = 1024.7925, step = 27901 (9.076 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5755.589.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:15:13\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-28000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:15:15\n",
      "INFO:tensorflow:Saving dict for global step 28000: average_loss = 1.8473563, global_step = 28000, loss = 1833.4302\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-28000\n",
      "INFO:tensorflow:Saving checkpoints for 28001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 978.3119, step = 28001\n",
      "INFO:tensorflow:global_step/sec: 11.2051\n",
      "INFO:tensorflow:loss = 3519.5056, step = 28101 (8.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0583\n",
      "INFO:tensorflow:loss = 2925.1633, step = 28201 (9.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1295\n",
      "INFO:tensorflow:loss = 2181.6514, step = 28301 (8.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7472\n",
      "INFO:tensorflow:loss = 5133.5513, step = 28401 (9.305 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2720.8877.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:16:04\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-28500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:16:05\n",
      "INFO:tensorflow:Saving dict for global step 28500: average_loss = 1.847611, global_step = 28500, loss = 1833.6829\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-28500\n",
      "INFO:tensorflow:Saving checkpoints for 28501 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 1734.0933, step = 28501\n",
      "INFO:tensorflow:global_step/sec: 10.6949\n",
      "INFO:tensorflow:loss = 4952.7124, step = 28601 (9.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3215\n",
      "INFO:tensorflow:loss = 1522.6257, step = 28701 (8.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3581\n",
      "INFO:tensorflow:loss = 2677.5596, step = 28801 (8.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3247\n",
      "INFO:tensorflow:loss = 3864.62, step = 28901 (8.830 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29000 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1432.6693.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:16:54\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-29000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:16:55\n",
      "INFO:tensorflow:Saving dict for global step 29000: average_loss = 1.8467617, global_step = 29000, loss = 1832.84\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-29000\n",
      "INFO:tensorflow:Saving checkpoints for 29001 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:loss = 727.12897, step = 29001\n",
      "INFO:tensorflow:global_step/sec: 10.124\n",
      "INFO:tensorflow:loss = 1957.0436, step = 29101 (9.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9752\n",
      "INFO:tensorflow:loss = 858.3282, step = 29201 (9.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9212\n",
      "INFO:tensorflow:loss = 4958.687, step = 29301 (9.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0337\n",
      "INFO:tensorflow:loss = 1416.2278, step = 29401 (9.063 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29500 into /tmp/tf_wx_model-4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5082.191.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-15-20:17:45\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-29500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-15-20:17:46\n",
      "INFO:tensorflow:Saving dict for global step 29500: average_loss = 1.8481979, global_step = 29500, loss = 1834.2654\n"
     ]
    }
   ],
   "source": [
    "evaluations = []  \n",
    "STEPS = 500  \n",
    "for i in range(1, int(X_train.shape[0]/1000)):  \n",
    "    regressor.train(input_fn=wx_input_fn(X_train, y=y_train), steps=STEPS)\n",
    "    evaluations.append(regressor.evaluate(input_fn=wx_input_fn(X_val,\n",
    "                                                               y_val,\n",
    "                                                               num_epochs=1,\n",
    "                                                               shuffle=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'average_loss': 1.8468792, 'global_step': 500, 'loss': 1832.9565},\n",
       " {'average_loss': 1.8557099, 'global_step': 1000, 'loss': 1841.7207},\n",
       " {'average_loss': 1.8476968, 'global_step': 1500, 'loss': 1833.7681},\n",
       " {'average_loss': 1.8485402, 'global_step': 2000, 'loss': 1834.605},\n",
       " {'average_loss': 1.8522139, 'global_step': 2500, 'loss': 1838.2511},\n",
       " {'average_loss': 1.8491666, 'global_step': 3000, 'loss': 1835.2267},\n",
       " {'average_loss': 1.8481841, 'global_step': 3500, 'loss': 1834.2517},\n",
       " {'average_loss': 1.8479578, 'global_step': 4000, 'loss': 1834.0271},\n",
       " {'average_loss': 1.8475368, 'global_step': 4500, 'loss': 1833.6093},\n",
       " {'average_loss': 1.8468843, 'global_step': 5000, 'loss': 1832.9615},\n",
       " {'average_loss': 1.8482642, 'global_step': 5500, 'loss': 1834.3312},\n",
       " {'average_loss': 1.8466713, 'global_step': 6000, 'loss': 1832.7502},\n",
       " {'average_loss': 1.8492503, 'global_step': 6500, 'loss': 1835.3098},\n",
       " {'average_loss': 1.8473624, 'global_step': 7000, 'loss': 1833.4362},\n",
       " {'average_loss': 1.8471714, 'global_step': 7500, 'loss': 1833.2466},\n",
       " {'average_loss': 1.8490335, 'global_step': 8000, 'loss': 1835.0946},\n",
       " {'average_loss': 1.8477376, 'global_step': 8500, 'loss': 1833.8085},\n",
       " {'average_loss': 1.8465786, 'global_step': 9000, 'loss': 1832.6582},\n",
       " {'average_loss': 1.8473448, 'global_step': 9500, 'loss': 1833.4186},\n",
       " {'average_loss': 1.8480247, 'global_step': 10000, 'loss': 1834.0935},\n",
       " {'average_loss': 1.8466915, 'global_step': 10500, 'loss': 1832.7703},\n",
       " {'average_loss': 1.847493, 'global_step': 11000, 'loss': 1833.5658},\n",
       " {'average_loss': 1.847827, 'global_step': 11500, 'loss': 1833.8972},\n",
       " {'average_loss': 1.8465893, 'global_step': 12000, 'loss': 1832.6688},\n",
       " {'average_loss': 1.8470992, 'global_step': 12500, 'loss': 1833.1749},\n",
       " {'average_loss': 1.8471794, 'global_step': 13000, 'loss': 1833.2545},\n",
       " {'average_loss': 1.8465726, 'global_step': 13500, 'loss': 1832.6523},\n",
       " {'average_loss': 1.8478588, 'global_step': 14000, 'loss': 1833.9288},\n",
       " {'average_loss': 1.8484433, 'global_step': 14500, 'loss': 1834.5089},\n",
       " {'average_loss': 1.8477285, 'global_step': 15000, 'loss': 1833.7994},\n",
       " {'average_loss': 1.8476561, 'global_step': 15500, 'loss': 1833.7277},\n",
       " {'average_loss': 1.8465972, 'global_step': 16000, 'loss': 1832.6766},\n",
       " {'average_loss': 1.846604, 'global_step': 16500, 'loss': 1832.6835},\n",
       " {'average_loss': 1.8477483, 'global_step': 17000, 'loss': 1833.8191},\n",
       " {'average_loss': 1.8474873, 'global_step': 17500, 'loss': 1833.56},\n",
       " {'average_loss': 1.8466007, 'global_step': 18000, 'loss': 1832.6802},\n",
       " {'average_loss': 1.8467494, 'global_step': 18500, 'loss': 1832.8279},\n",
       " {'average_loss': 1.8478273, 'global_step': 19000, 'loss': 1833.8976},\n",
       " {'average_loss': 1.8469272, 'global_step': 19500, 'loss': 1833.0042},\n",
       " {'average_loss': 1.8465728, 'global_step': 20000, 'loss': 1832.6525},\n",
       " {'average_loss': 1.8472166, 'global_step': 20500, 'loss': 1833.2915},\n",
       " {'average_loss': 1.846978, 'global_step': 21000, 'loss': 1833.0546},\n",
       " {'average_loss': 1.8477938, 'global_step': 21500, 'loss': 1833.8644},\n",
       " {'average_loss': 1.8467889, 'global_step': 22000, 'loss': 1832.867},\n",
       " {'average_loss': 1.8478336, 'global_step': 22500, 'loss': 1833.9038},\n",
       " {'average_loss': 1.8475851, 'global_step': 23000, 'loss': 1833.6571},\n",
       " {'average_loss': 1.8472396, 'global_step': 23500, 'loss': 1833.3143},\n",
       " {'average_loss': 1.8478615, 'global_step': 24000, 'loss': 1833.9315},\n",
       " {'average_loss': 1.8466011, 'global_step': 24500, 'loss': 1832.6805},\n",
       " {'average_loss': 1.8466762, 'global_step': 25000, 'loss': 1832.7551},\n",
       " {'average_loss': 1.8477947, 'global_step': 25500, 'loss': 1833.8651},\n",
       " {'average_loss': 1.8487494, 'global_step': 26000, 'loss': 1834.8126},\n",
       " {'average_loss': 1.8468254, 'global_step': 26500, 'loss': 1832.9031},\n",
       " {'average_loss': 1.8474739, 'global_step': 27000, 'loss': 1833.5468},\n",
       " {'average_loss': 1.8475955, 'global_step': 27500, 'loss': 1833.6674},\n",
       " {'average_loss': 1.8473563, 'global_step': 28000, 'loss': 1833.4302},\n",
       " {'average_loss': 1.847611, 'global_step': 28500, 'loss': 1833.6829},\n",
       " {'average_loss': 1.8467617, 'global_step': 29000, 'loss': 1832.84},\n",
       " {'average_loss': 1.8481979, 'global_step': 29500, 'loss': 1834.2654}]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ba9ba7450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "loss_values = [ev['loss'] for ev in evaluations]  \n",
    "training_steps = [ev['global_step'] for ev in evaluations]\n",
    "\n",
    "plt.scatter(x=training_steps, y=loss_values)  \n",
    "plt.xlabel('Training steps (Epochs = steps / 2)')  \n",
    "plt.ylabel('Loss (SSE)')  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-4/model.ckpt-29500\n"
     ]
    }
   ],
   "source": [
    "pred = regressor.predict(input_fn=wx_input_fn(X_test,  \n",
    "                                              num_epochs=1,\n",
    "                                              shuffle=False))\n",
    "\n",
    "predictions = np.array([p['predictions'][0] for p in pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Explained Variance: -0.00\n",
      "The Mean Absolute Error: 0.40 mm \n",
      "The Median Absolute Error: 0.22 mm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"The Explained Variance: %.2f\" % explained_variance_score(  \n",
    "                                            y_test, predictions))  \n",
    "print(\"The Mean Absolute Error: %.2f mm \" % mean_absolute_error(  \n",
    "                                            y_test, predictions))  \n",
    "print(\"The Median Absolute Error: %.2f mm\" % median_absolute_error(  \n",
    "                                            y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2192689, 0.2192689, 0.2192689, ..., 0.2192689, 0.2192689,\n",
       "       0.2192689], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2192689, 0.2192689, 0.2192689, 0.2192689, 0.2192689, 0.2192689,\n",
       "       0.2192689, 0.2192689, 0.2192689, 0.2192689], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
