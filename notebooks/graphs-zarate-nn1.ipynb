{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, integrate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import shutil\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAABLCAYAAABEDTEaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAAkNJREFUeJzt3L+OjGEYxuHnw2SxFISIKDYSpUZQ6ZyEYvupHIsDcAJqidoR0CGi0hKRFcGKlVej0dg/yXu/M99eVzfJV9xP9fsyk8zUWisA6O3E6AEAHA+CA0CE4AAQITgARAgOABGCA0CE4AAQITgARAgOABGn9ntgmqZlVS2rqqbF6dsbF651HzXK+XMboyd0dfHsYvSErjYXM35/2v06ekFXezs7oyd09ePz99ETuvnw62d9+b03HeTZ6TB/bXPmyo12ffvRkYetuvv3tkZP6OrBrfm+LFRV3b26OXpCNyffPB89oauPz56OntDV6ycvR0/o5uH7t/Vu99uBgjPjV0IAVongABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEVNr7f8PTNOyqpZ/P96sqle9Rw10qao+jR7RyZxvq3LfunPf+tpqrV0+yIP7Buefh6fpRWvtzpFnrbg53zfn26rct+7cdzz4Sg2ACMEBIOKwwXncZcXqmPN9c76tyn3rzn3HwKF+wwGAo/KVGgARggNAhOAAECE4AEQIDgARfwD+T1i7/7LiygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4bbc5c0f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.palplot(sns.color_palette(\"RdBu_r\", 7))\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Base com todos os dados do sudeste</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9779168\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/sudeste.csv',low_memory=False)\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Base com todas chuvas EXTREMAS com inicio e fim de cada chuva extrema (> 50mm em 24 horas)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31710\n"
     ]
    }
   ],
   "source": [
    "dfhr = pd.read_csv('../data/extreme_prcp_evolution.csv')\n",
    "print len(dfhr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Subconjunto da base principal considerando o inicio e fim das chuvas extremas (> 50mm em 24 horas)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761040\n"
     ]
    }
   ],
   "source": [
    "dfext = pd.read_csv('../data/sudeste_extreme_prcp.csv', index_col=0)\n",
    "print len(dfext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Limpeza dos dados</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Campos não numericos e campos derivados\n",
    "DES= ['wsid','wsnm','elvt','lat','lon','inme','city','prov']\n",
    "INT = ['yr','mo','da','hr']\n",
    "DAT = ['mdct','date']\n",
    "DER = ['smax','smin','tmax','tmin','dmax','dmin','hmax','hmin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe apenas com os dados continuos\n",
    "dfcont = df\n",
    "for f in DES + INT + DAT:    \n",
    "    dfcont = dfcont.drop(f, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcont = dfcont.apply(pd.to_numeric, errors='coerce')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9779168 entries, 0 to 9779167\n",
      "Data columns (total 17 columns):\n",
      "prcp    float64\n",
      "stp     float64\n",
      "smax    float64\n",
      "smin    float64\n",
      "gbrd    float64\n",
      "temp    float64\n",
      "tmax    float64\n",
      "tmin    float64\n",
      "dewp    float64\n",
      "dmax    float64\n",
      "dmin    float64\n",
      "hmdy    float64\n",
      "hmax    float64\n",
      "hmin    float64\n",
      "wdsp    float64\n",
      "wdct    float64\n",
      "gust    float64\n",
      "dtypes: float64(17)\n",
      "memory usage: 1.2 GB\n"
     ]
    }
   ],
   "source": [
    "dfcont.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prcp</th>\n",
       "      <td>1407984.0</td>\n",
       "      <td>0.936654</td>\n",
       "      <td>2.923291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>880.429177</td>\n",
       "      <td>248.264986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.3</td>\n",
       "      <td>944.200</td>\n",
       "      <td>973.1</td>\n",
       "      <td>1050.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>880.303394</td>\n",
       "      <td>248.917148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.5</td>\n",
       "      <td>944.400</td>\n",
       "      <td>973.3</td>\n",
       "      <td>1050.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>879.833097</td>\n",
       "      <td>248.771557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>943.900</td>\n",
       "      <td>972.8</td>\n",
       "      <td>1050.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbrd</th>\n",
       "      <td>5670348.0</td>\n",
       "      <td>1176.371062</td>\n",
       "      <td>1138.753521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>863.427</td>\n",
       "      <td>2103.0</td>\n",
       "      <td>11586.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>9779137.0</td>\n",
       "      <td>20.474225</td>\n",
       "      <td>7.331125</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>17.7</td>\n",
       "      <td>21.400</td>\n",
       "      <td>24.9</td>\n",
       "      <td>44.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax</th>\n",
       "      <td>9778693.0</td>\n",
       "      <td>14.726810</td>\n",
       "      <td>5.805413</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>16.100</td>\n",
       "      <td>18.9</td>\n",
       "      <td>42.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin</th>\n",
       "      <td>9779142.0</td>\n",
       "      <td>21.105026</td>\n",
       "      <td>7.545549</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>21.900</td>\n",
       "      <td>25.8</td>\n",
       "      <td>45.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewp</th>\n",
       "      <td>9778858.0</td>\n",
       "      <td>15.240249</td>\n",
       "      <td>5.866811</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>16.600</td>\n",
       "      <td>19.4</td>\n",
       "      <td>44.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmax</th>\n",
       "      <td>9779134.0</td>\n",
       "      <td>19.864175</td>\n",
       "      <td>7.134849</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>17.2</td>\n",
       "      <td>20.800</td>\n",
       "      <td>24.2</td>\n",
       "      <td>45.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmin</th>\n",
       "      <td>9778361.0</td>\n",
       "      <td>14.220885</td>\n",
       "      <td>5.777089</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>15.600</td>\n",
       "      <td>18.4</td>\n",
       "      <td>44.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>67.266673</td>\n",
       "      <td>26.542125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>74.000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax</th>\n",
       "      <td>9779156.0</td>\n",
       "      <td>69.969913</td>\n",
       "      <td>26.433711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>78.000</td>\n",
       "      <td>91.0</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin</th>\n",
       "      <td>9779124.0</td>\n",
       "      <td>64.419647</td>\n",
       "      <td>26.565504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>70.000</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp</th>\n",
       "      <td>8853607.0</td>\n",
       "      <td>1.998156</td>\n",
       "      <td>1.618531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.700</td>\n",
       "      <td>2.9</td>\n",
       "      <td>19.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>138.599091</td>\n",
       "      <td>105.201791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.000</td>\n",
       "      <td>216.0</td>\n",
       "      <td>360.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust</th>\n",
       "      <td>9462694.0</td>\n",
       "      <td>4.494015</td>\n",
       "      <td>2.981790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.200</td>\n",
       "      <td>6.3</td>\n",
       "      <td>50.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count         mean          std   min    25%      50%     75%  \\\n",
       "prcp  1407984.0     0.936654     2.923291   0.0    0.0    0.000     0.6   \n",
       "stp   9779168.0   880.429177   248.264986   0.0  911.3  944.200   973.1   \n",
       "smax  9779168.0   880.303394   248.917148   0.0  911.5  944.400   973.3   \n",
       "smin  9779168.0   879.833097   248.771557   0.0  911.0  943.900   972.8   \n",
       "gbrd  5670348.0  1176.371062  1138.753521   0.0   65.0  863.427  2103.0   \n",
       "temp  9779137.0    20.474225     7.331125  -3.8   17.7   21.400    24.9   \n",
       "tmax  9778693.0    14.726810     5.805413 -10.0   12.1   16.100    18.9   \n",
       "tmin  9779142.0    21.105026     7.545549  -3.2   18.2   21.900    25.8   \n",
       "dewp  9778858.0    15.240249     5.866811 -10.0   12.7   16.600    19.4   \n",
       "dmax  9779134.0    19.864175     7.134849  -8.5   17.2   20.800    24.2   \n",
       "dmin  9778361.0    14.220885     5.777089 -10.0   11.6   15.600    18.4   \n",
       "hmdy  9779168.0    67.266673    26.542125   0.0   53.0   74.000    89.0   \n",
       "hmax  9779156.0    69.969913    26.433711   0.0   58.0   78.000    91.0   \n",
       "hmin  9779124.0    64.419647    26.565504   0.0   49.0   70.000    86.0   \n",
       "wdsp  8853607.0     1.998156     1.618531   0.0    0.8    1.700     2.9   \n",
       "wdct  9779168.0   138.599091   105.201791   0.0   56.0  114.000   216.0   \n",
       "gust  9462694.0     4.494015     2.981790   0.0    2.3    4.200     6.3   \n",
       "\n",
       "            max  \n",
       "prcp    100.000  \n",
       "stp    1050.000  \n",
       "smax   1050.000  \n",
       "smin   1050.000  \n",
       "gbrd  11586.491  \n",
       "temp     44.900  \n",
       "tmax     42.700  \n",
       "tmin     45.000  \n",
       "dewp     44.800  \n",
       "dmax     45.000  \n",
       "dmin     44.900  \n",
       "hmdy    100.000  \n",
       "hmax    100.000  \n",
       "hmin    100.000  \n",
       "wdsp     19.800  \n",
       "wdct    360.000  \n",
       "gust     50.000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcont.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> A variável gbbr(radiação global) apresenta massivamente números nulos e não pode ser recuperada. Vamos retirar esta variável.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcont =  dfcont.drop('gbrd',1)\n",
    "df = df.drop('gbrd',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Para as precipitações nulas foi inputado 0.0 mm. Também para o vento e rajada de vento.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAN_BE_NULL = ['wdsp','prcp','gust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in CAN_BE_NULL:\n",
    "    df[v] = df[v].fillna(0.0)\n",
    "    dfcont[v] = dfcont[v].fillna(0.0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Vamos ver como os dados contínuos estão organizados: MÍNIMOS, MÁXIMOS, MEDIAS</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prcp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>0.134858</td>\n",
       "      <td>1.156940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>880.429177</td>\n",
       "      <td>248.264986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.3</td>\n",
       "      <td>944.2</td>\n",
       "      <td>973.1</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>880.303394</td>\n",
       "      <td>248.917148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.5</td>\n",
       "      <td>944.4</td>\n",
       "      <td>973.3</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>879.833097</td>\n",
       "      <td>248.771557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>943.9</td>\n",
       "      <td>972.8</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>9779137.0</td>\n",
       "      <td>20.474225</td>\n",
       "      <td>7.331125</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>17.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>24.9</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax</th>\n",
       "      <td>9778693.0</td>\n",
       "      <td>14.726810</td>\n",
       "      <td>5.805413</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>16.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>42.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin</th>\n",
       "      <td>9779142.0</td>\n",
       "      <td>21.105026</td>\n",
       "      <td>7.545549</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>21.9</td>\n",
       "      <td>25.8</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewp</th>\n",
       "      <td>9778858.0</td>\n",
       "      <td>15.240249</td>\n",
       "      <td>5.866811</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>16.6</td>\n",
       "      <td>19.4</td>\n",
       "      <td>44.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmax</th>\n",
       "      <td>9779134.0</td>\n",
       "      <td>19.864175</td>\n",
       "      <td>7.134849</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>17.2</td>\n",
       "      <td>20.8</td>\n",
       "      <td>24.2</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmin</th>\n",
       "      <td>9778361.0</td>\n",
       "      <td>14.220885</td>\n",
       "      <td>5.777089</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>15.6</td>\n",
       "      <td>18.4</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>67.266673</td>\n",
       "      <td>26.542125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax</th>\n",
       "      <td>9779156.0</td>\n",
       "      <td>69.969913</td>\n",
       "      <td>26.433711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin</th>\n",
       "      <td>9779124.0</td>\n",
       "      <td>64.419647</td>\n",
       "      <td>26.565504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>1.809038</td>\n",
       "      <td>1.647369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>138.599091</td>\n",
       "      <td>105.201791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>4.348580</td>\n",
       "      <td>3.039042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count        mean         std   min    25%    50%    75%     max\n",
       "prcp  9779168.0    0.134858    1.156940   0.0    0.0    0.0    0.0   100.0\n",
       "stp   9779168.0  880.429177  248.264986   0.0  911.3  944.2  973.1  1050.0\n",
       "smax  9779168.0  880.303394  248.917148   0.0  911.5  944.4  973.3  1050.0\n",
       "smin  9779168.0  879.833097  248.771557   0.0  911.0  943.9  972.8  1050.0\n",
       "temp  9779137.0   20.474225    7.331125  -3.8   17.7   21.4   24.9    44.9\n",
       "tmax  9778693.0   14.726810    5.805413 -10.0   12.1   16.1   18.9    42.7\n",
       "tmin  9779142.0   21.105026    7.545549  -3.2   18.2   21.9   25.8    45.0\n",
       "dewp  9778858.0   15.240249    5.866811 -10.0   12.7   16.6   19.4    44.8\n",
       "dmax  9779134.0   19.864175    7.134849  -8.5   17.2   20.8   24.2    45.0\n",
       "dmin  9778361.0   14.220885    5.777089 -10.0   11.6   15.6   18.4    44.9\n",
       "hmdy  9779168.0   67.266673   26.542125   0.0   53.0   74.0   89.0   100.0\n",
       "hmax  9779156.0   69.969913   26.433711   0.0   58.0   78.0   91.0   100.0\n",
       "hmin  9779124.0   64.419647   26.565504   0.0   49.0   70.0   86.0   100.0\n",
       "wdsp  9779168.0    1.809038    1.647369   0.0    0.4    1.5    2.7    19.8\n",
       "wdct  9779168.0  138.599091  105.201791   0.0   56.0  114.0  216.0   360.0\n",
       "gust  9779168.0    4.348580    3.039042   0.0    2.1    4.1    6.3    50.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcont.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>A temperatura será inputada pela média</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = ['temp','dewp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in MEAN:\n",
    "    df[v] = df[v].fillna(value=df[v].median())\n",
    "    dfcont[v] = dfcont[v].fillna(value=dfcont[v].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prcp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>0.134858</td>\n",
       "      <td>1.156940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>880.429177</td>\n",
       "      <td>248.264986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.3</td>\n",
       "      <td>944.2</td>\n",
       "      <td>973.1</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>880.303394</td>\n",
       "      <td>248.917148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.5</td>\n",
       "      <td>944.4</td>\n",
       "      <td>973.3</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>879.833097</td>\n",
       "      <td>248.771557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>943.9</td>\n",
       "      <td>972.8</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>20.474228</td>\n",
       "      <td>7.331113</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>17.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>24.9</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax</th>\n",
       "      <td>9778693.0</td>\n",
       "      <td>14.726810</td>\n",
       "      <td>5.805413</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>16.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>42.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin</th>\n",
       "      <td>9779142.0</td>\n",
       "      <td>21.105026</td>\n",
       "      <td>7.545549</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>21.9</td>\n",
       "      <td>25.8</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>15.240292</td>\n",
       "      <td>5.866723</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>16.6</td>\n",
       "      <td>19.4</td>\n",
       "      <td>44.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmax</th>\n",
       "      <td>9779134.0</td>\n",
       "      <td>19.864175</td>\n",
       "      <td>7.134849</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>17.2</td>\n",
       "      <td>20.8</td>\n",
       "      <td>24.2</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmin</th>\n",
       "      <td>9778361.0</td>\n",
       "      <td>14.220885</td>\n",
       "      <td>5.777089</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>15.6</td>\n",
       "      <td>18.4</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>67.266673</td>\n",
       "      <td>26.542125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax</th>\n",
       "      <td>9779156.0</td>\n",
       "      <td>69.969913</td>\n",
       "      <td>26.433711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin</th>\n",
       "      <td>9779124.0</td>\n",
       "      <td>64.419647</td>\n",
       "      <td>26.565504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>1.809038</td>\n",
       "      <td>1.647369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>138.599091</td>\n",
       "      <td>105.201791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>4.348580</td>\n",
       "      <td>3.039042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count        mean         std   min    25%    50%    75%     max\n",
       "prcp  9779168.0    0.134858    1.156940   0.0    0.0    0.0    0.0   100.0\n",
       "stp   9779168.0  880.429177  248.264986   0.0  911.3  944.2  973.1  1050.0\n",
       "smax  9779168.0  880.303394  248.917148   0.0  911.5  944.4  973.3  1050.0\n",
       "smin  9779168.0  879.833097  248.771557   0.0  911.0  943.9  972.8  1050.0\n",
       "temp  9779168.0   20.474228    7.331113  -3.8   17.7   21.4   24.9    44.9\n",
       "tmax  9778693.0   14.726810    5.805413 -10.0   12.1   16.1   18.9    42.7\n",
       "tmin  9779142.0   21.105026    7.545549  -3.2   18.2   21.9   25.8    45.0\n",
       "dewp  9779168.0   15.240292    5.866723 -10.0   12.7   16.6   19.4    44.8\n",
       "dmax  9779134.0   19.864175    7.134849  -8.5   17.2   20.8   24.2    45.0\n",
       "dmin  9778361.0   14.220885    5.777089 -10.0   11.6   15.6   18.4    44.9\n",
       "hmdy  9779168.0   67.266673   26.542125   0.0   53.0   74.0   89.0   100.0\n",
       "hmax  9779156.0   69.969913   26.433711   0.0   58.0   78.0   91.0   100.0\n",
       "hmin  9779124.0   64.419647   26.565504   0.0   49.0   70.0   86.0   100.0\n",
       "wdsp  9779168.0    1.809038    1.647369   0.0    0.4    1.5    2.7    19.8\n",
       "wdct  9779168.0  138.599091  105.201791   0.0   56.0  114.0  216.0   360.0\n",
       "gust  9779168.0    4.348580    3.039042   0.0    2.1    4.1    6.3    50.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcont.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in ['tmax','tmin']:\n",
    "    dfcont[v] = dfcont[v].fillna(value=dfcont['temp'])\n",
    "    df[v] = df[v].fillna(value=df['temp'])\n",
    "for v in ['dmax','dmin']:\n",
    "    dfcont[v] = dfcont[v].fillna(value=dfcont['dewp'])\n",
    "    df[v] = df[v].fillna(value=df['dewp'])\n",
    "for v in ['hmax','hmin']:\n",
    "    dfcont[v] = dfcont[v].fillna(value=dfcont['hmdy'])\n",
    "    df[v] = df[v].fillna(value=df['hmdy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prcp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>0.134858</td>\n",
       "      <td>1.156940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>880.429177</td>\n",
       "      <td>248.264986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.3</td>\n",
       "      <td>944.2</td>\n",
       "      <td>973.1</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>880.303394</td>\n",
       "      <td>248.917148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.5</td>\n",
       "      <td>944.4</td>\n",
       "      <td>973.3</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>879.833097</td>\n",
       "      <td>248.771557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>943.9</td>\n",
       "      <td>972.8</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>20.474228</td>\n",
       "      <td>7.331113</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>17.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>24.9</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>14.727113</td>\n",
       "      <td>5.805794</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>16.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>42.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>21.104973</td>\n",
       "      <td>7.545616</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>21.9</td>\n",
       "      <td>25.8</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>15.240292</td>\n",
       "      <td>5.866723</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>16.6</td>\n",
       "      <td>19.4</td>\n",
       "      <td>44.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmax</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>19.864112</td>\n",
       "      <td>7.134923</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>17.2</td>\n",
       "      <td>20.8</td>\n",
       "      <td>24.2</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmin</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>14.219949</td>\n",
       "      <td>5.777816</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>15.6</td>\n",
       "      <td>18.4</td>\n",
       "      <td>44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>67.266673</td>\n",
       "      <td>26.542125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>69.969827</td>\n",
       "      <td>26.433808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>64.419357</td>\n",
       "      <td>26.565795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>1.809038</td>\n",
       "      <td>1.647369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>138.599091</td>\n",
       "      <td>105.201791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust</th>\n",
       "      <td>9779168.0</td>\n",
       "      <td>4.348580</td>\n",
       "      <td>3.039042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count        mean         std   min    25%    50%    75%     max\n",
       "prcp  9779168.0    0.134858    1.156940   0.0    0.0    0.0    0.0   100.0\n",
       "stp   9779168.0  880.429177  248.264986   0.0  911.3  944.2  973.1  1050.0\n",
       "smax  9779168.0  880.303394  248.917148   0.0  911.5  944.4  973.3  1050.0\n",
       "smin  9779168.0  879.833097  248.771557   0.0  911.0  943.9  972.8  1050.0\n",
       "temp  9779168.0   20.474228    7.331113  -3.8   17.7   21.4   24.9    44.9\n",
       "tmax  9779168.0   14.727113    5.805794 -10.0   12.1   16.1   18.9    42.7\n",
       "tmin  9779168.0   21.104973    7.545616  -3.2   18.2   21.9   25.8    45.0\n",
       "dewp  9779168.0   15.240292    5.866723 -10.0   12.7   16.6   19.4    44.8\n",
       "dmax  9779168.0   19.864112    7.134923  -8.5   17.2   20.8   24.2    45.0\n",
       "dmin  9779168.0   14.219949    5.777816 -10.0   11.6   15.6   18.4    44.9\n",
       "hmdy  9779168.0   67.266673   26.542125   0.0   53.0   74.0   89.0   100.0\n",
       "hmax  9779168.0   69.969827   26.433808   0.0   58.0   78.0   91.0   100.0\n",
       "hmin  9779168.0   64.419357   26.565795   0.0   49.0   70.0   86.0   100.0\n",
       "wdsp  9779168.0    1.809038    1.647369   0.0    0.4    1.5    2.7    19.8\n",
       "wdct  9779168.0  138.599091  105.201791   0.0   56.0  114.0  216.0   360.0\n",
       "gust  9779168.0    4.348580    3.039042   0.0    2.1    4.1    6.3    50.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcont.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Derivando novas variáveis</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>O objetivo é derivar cada variável climática contínua em uma nova variável t-1, t-2, t-3... t-n, onde n é o numeros de horas antes do momento t. Vamos primeiramente derivá-las para depois verificar quais quando massivamente as variávies estão zeradas, o que pode indicar que a estação falhou.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Utilizando um exemplo especifico de uma estação, depois verificamos o conjunto maior</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87456"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm = df[(df.wsid==329)]\n",
    "len(dfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wsid</th>\n",
       "      <th>wsnm</th>\n",
       "      <th>elvt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>inme</th>\n",
       "      <th>city</th>\n",
       "      <th>prov</th>\n",
       "      <th>mdct</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>tmin</th>\n",
       "      <th>dewp</th>\n",
       "      <th>dmax</th>\n",
       "      <th>dmin</th>\n",
       "      <th>hmdy</th>\n",
       "      <th>hmax</th>\n",
       "      <th>hmin</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>wdct</th>\n",
       "      <th>gust</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdct</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-10-10 00:00:00</th>\n",
       "      <td>329</td>\n",
       "      <td>BELO HOR. (PAMPULHA)</td>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>A521</td>\n",
       "      <td>Belo Horizonte</td>\n",
       "      <td>MG</td>\n",
       "      <td>2006-10-10 00:00:00</td>\n",
       "      <td>2006-10-10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-10 01:00:00</th>\n",
       "      <td>329</td>\n",
       "      <td>BELO HOR. (PAMPULHA)</td>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>A521</td>\n",
       "      <td>Belo Horizonte</td>\n",
       "      <td>MG</td>\n",
       "      <td>2006-10-10 01:00:00</td>\n",
       "      <td>2006-10-10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-10 02:00:00</th>\n",
       "      <td>329</td>\n",
       "      <td>BELO HOR. (PAMPULHA)</td>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>A521</td>\n",
       "      <td>Belo Horizonte</td>\n",
       "      <td>MG</td>\n",
       "      <td>2006-10-10 02:00:00</td>\n",
       "      <td>2006-10-10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-10 03:00:00</th>\n",
       "      <td>329</td>\n",
       "      <td>BELO HOR. (PAMPULHA)</td>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>A521</td>\n",
       "      <td>Belo Horizonte</td>\n",
       "      <td>MG</td>\n",
       "      <td>2006-10-10 03:00:00</td>\n",
       "      <td>2006-10-10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     wsid                  wsnm   elvt        lat        lon  \\\n",
       "mdct                                                                           \n",
       "2006-10-10 00:00:00   329  BELO HOR. (PAMPULHA)  854.0 -19.883945 -43.969397   \n",
       "2006-10-10 01:00:00   329  BELO HOR. (PAMPULHA)  854.0 -19.883945 -43.969397   \n",
       "2006-10-10 02:00:00   329  BELO HOR. (PAMPULHA)  854.0 -19.883945 -43.969397   \n",
       "2006-10-10 03:00:00   329  BELO HOR. (PAMPULHA)  854.0 -19.883945 -43.969397   \n",
       "\n",
       "                     inme            city prov                 mdct  \\\n",
       "mdct                                                                  \n",
       "2006-10-10 00:00:00  A521  Belo Horizonte   MG  2006-10-10 00:00:00   \n",
       "2006-10-10 01:00:00  A521  Belo Horizonte   MG  2006-10-10 01:00:00   \n",
       "2006-10-10 02:00:00  A521  Belo Horizonte   MG  2006-10-10 02:00:00   \n",
       "2006-10-10 03:00:00  A521  Belo Horizonte   MG  2006-10-10 03:00:00   \n",
       "\n",
       "                           date  ...   tmin  dewp  dmax  dmin  hmdy  hmax  \\\n",
       "mdct                             ...                                        \n",
       "2006-10-10 00:00:00  2006-10-10  ...    0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2006-10-10 01:00:00  2006-10-10  ...    0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2006-10-10 02:00:00  2006-10-10  ...    0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2006-10-10 03:00:00  2006-10-10  ...    0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "                     hmin  wdsp  wdct  gust  \n",
       "mdct                                         \n",
       "2006-10-10 00:00:00   0.0   0.0   0.0   0.0  \n",
       "2006-10-10 01:00:00   0.0   0.0   0.0   0.0  \n",
       "2006-10-10 02:00:00   0.0   0.0   0.0   0.0  \n",
       "2006-10-10 03:00:00   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.index = pd.to_datetime(dfm.mdct)\n",
    "dfm.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elvt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>prcp</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>dewp</th>\n",
       "      <th>dmax</th>\n",
       "      <th>dmin</th>\n",
       "      <th>hmdy</th>\n",
       "      <th>hmax</th>\n",
       "      <th>hmin</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>wdct</th>\n",
       "      <th>gust</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdct</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-10-10 00:00:00</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-10 01:00:00</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-10 02:00:00</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-10 03:00:00</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-10 04:00:00</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      elvt        lat        lon  prcp  stp  smax  smin  temp  \\\n",
       "mdct                                                                            \n",
       "2006-10-10 00:00:00  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   \n",
       "2006-10-10 01:00:00  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   \n",
       "2006-10-10 02:00:00  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   \n",
       "2006-10-10 03:00:00  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   \n",
       "2006-10-10 04:00:00  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   \n",
       "\n",
       "                     tmax  tmin  dewp  dmax  dmin  hmdy  hmax  hmin  wdsp  \\\n",
       "mdct                                                                        \n",
       "2006-10-10 00:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2006-10-10 01:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2006-10-10 02:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2006-10-10 03:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2006-10-10 04:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "                     wdct  gust  \n",
       "mdct                             \n",
       "2006-10-10 00:00:00   0.0   0.0  \n",
       "2006-10-10 01:00:00   0.0   0.0  \n",
       "2006-10-10 02:00:00   0.0   0.0  \n",
       "2006-10-10 03:00:00   0.0   0.0  \n",
       "2006-10-10 04:00:00   0.0   0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLEAN = ['wsnm','inme','city','prov','mdct','date']\n",
    "REMOVE = ['wsid','yr', 'mo', 'da', 'hr']\n",
    "for v in CLEAN + REMOVE:\n",
    "    dfm = dfm.drop(v,1)\n",
    "dfm.head(5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_nth_hour_feature(df, feature, N):  \n",
    "    rows = df.shape[0]\n",
    "    nth_prior_measurements = [None]*N + [df[feature][i-N] for i in range(N, rows)]\n",
    "    col_name = \"{}_{}\".format(feature, N)\n",
    "    df[col_name] = np.nan\n",
    "    df.loc[:][col_name] = nth_prior_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_DER = ['wsid','elvt','lat', 'lon', 'yr', 'mo', 'da', 'hr']\n",
    "\n",
    "for feature in dfm.columns:\n",
    "    if feature not in NON_DER:\n",
    "        for h in range(1,6):\n",
    "            derive_nth_hour_feature(dfm, feature, h) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOVE = [u'prcp_1', u'prcp_2', u'prcp_3', u'prcp_4', u'prcp_5']\n",
    "for v in REMOVE:\n",
    "    dfm = dfm.drop(v,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'elvt', u'lat', u'lon', u'prcp', u'stp', u'smax', u'smin', u'temp',\n",
       "       u'tmax', u'tmin', u'dewp', u'dmax', u'dmin', u'hmdy', u'hmax', u'hmin',\n",
       "       u'wdsp', u'wdct', u'gust', u'stp_1', u'stp_2', u'stp_3', u'stp_4',\n",
       "       u'stp_5', u'smax_1', u'smax_2', u'smax_3', u'smax_4', u'smax_5',\n",
       "       u'smin_1', u'smin_2', u'smin_3', u'smin_4', u'smin_5', u'temp_1',\n",
       "       u'temp_2', u'temp_3', u'temp_4', u'temp_5', u'tmax_1', u'tmax_2',\n",
       "       u'tmax_3', u'tmax_4', u'tmax_5', u'tmin_1', u'tmin_2', u'tmin_3',\n",
       "       u'tmin_4', u'tmin_5', u'dewp_1', u'dewp_2', u'dewp_3', u'dewp_4',\n",
       "       u'dewp_5', u'dmax_1', u'dmax_2', u'dmax_3', u'dmax_4', u'dmax_5',\n",
       "       u'dmin_1', u'dmin_2', u'dmin_3', u'dmin_4', u'dmin_5', u'hmdy_1',\n",
       "       u'hmdy_2', u'hmdy_3', u'hmdy_4', u'hmdy_5', u'hmax_1', u'hmax_2',\n",
       "       u'hmax_3', u'hmax_4', u'hmax_5', u'hmin_1', u'hmin_2', u'hmin_3',\n",
       "       u'hmin_4', u'hmin_5', u'wdsp_1', u'wdsp_2', u'wdsp_3', u'wdsp_4',\n",
       "       u'wdsp_5', u'wdct_1', u'wdct_2', u'wdct_3', u'wdct_4', u'wdct_5',\n",
       "       u'gust_1', u'gust_2', u'gust_3', u'gust_4', u'gust_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = dfm.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = dfm.dropna()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elvt</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>prcp</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>...</th>\n",
       "      <th>wdct_1</th>\n",
       "      <th>wdct_2</th>\n",
       "      <th>wdct_3</th>\n",
       "      <th>wdct_4</th>\n",
       "      <th>wdct_5</th>\n",
       "      <th>gust_1</th>\n",
       "      <th>gust_2</th>\n",
       "      <th>gust_3</th>\n",
       "      <th>gust_4</th>\n",
       "      <th>gust_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>854.0</td>\n",
       "      <td>-19.883945</td>\n",
       "      <td>-43.969397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    elvt        lat        lon  prcp  stp  smax  smin  temp  tmax  tmin  \\\n",
       "5  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "6  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "7  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "8  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "9  854.0 -19.883945 -43.969397   0.0  0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "    ...    wdct_1  wdct_2  wdct_3  wdct_4  wdct_5  gust_1  gust_2  gust_3  \\\n",
       "5   ...       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "6   ...       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "7   ...       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "8   ...       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "9   ...       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   gust_4  gust_5  \n",
       "5     0.0     0.0  \n",
       "6     0.0     0.0  \n",
       "7     0.0     0.0  \n",
       "8     0.0     0.0  \n",
       "9     0.0     0.0  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como esta rede é especifica para a BH, vamos remover elvt, lat, lon\n",
    "REMOVE = ['elvt','lat', 'lon']\n",
    "for v in REMOVE:\n",
    "    dfm = dfm.drop(v,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prcp</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>dewp</th>\n",
       "      <th>dmax</th>\n",
       "      <th>dmin</th>\n",
       "      <th>...</th>\n",
       "      <th>wdct_1</th>\n",
       "      <th>wdct_2</th>\n",
       "      <th>wdct_3</th>\n",
       "      <th>wdct_4</th>\n",
       "      <th>wdct_5</th>\n",
       "      <th>gust_1</th>\n",
       "      <th>gust_2</th>\n",
       "      <th>gust_3</th>\n",
       "      <th>gust_4</th>\n",
       "      <th>gust_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   prcp  stp  smax  smin  temp  tmax  tmin  dewp  dmax  dmin   ...    wdct_1  \\\n",
       "5   0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   ...       0.0   \n",
       "6   0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   ...       0.0   \n",
       "7   0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   ...       0.0   \n",
       "8   0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   ...       0.0   \n",
       "9   0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   ...       0.0   \n",
       "\n",
       "   wdct_2  wdct_3  wdct_4  wdct_5  gust_1  gust_2  gust_3  gust_4  gust_5  \n",
       "5     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "6     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "7     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "8     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "9     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wdsp', 'prcp', 'gust']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAN_BE_NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preparando a base</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Removendo registros que não pode ser nulos e prejudicariam o treinamento</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(dfm.columns)\n",
    "\n",
    "COLS_BE_NULL = ['prcp','wdsp','wdsp_1','wdsp_2','wdsp_3','wdsp_4','wdsp_5',\\\n",
    "                'gust','gust_1','gust_2','gust_3','gust_4','gust_5']\n",
    "for v in COLS_BE_NULL:\n",
    "    cols.remove(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prcp</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>dewp</th>\n",
       "      <th>dmax</th>\n",
       "      <th>dmin</th>\n",
       "      <th>...</th>\n",
       "      <th>wdct_1</th>\n",
       "      <th>wdct_2</th>\n",
       "      <th>wdct_3</th>\n",
       "      <th>wdct_4</th>\n",
       "      <th>wdct_5</th>\n",
       "      <th>gust_1</th>\n",
       "      <th>gust_2</th>\n",
       "      <th>gust_3</th>\n",
       "      <th>gust_4</th>\n",
       "      <th>gust_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   prcp  stp  smax  smin  temp  tmax  tmin  dewp  dmax  dmin   ...    wdct_1  \\\n",
       "5   0.0  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   ...       NaN   \n",
       "6   0.0  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   ...       NaN   \n",
       "7   0.0  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   ...       NaN   \n",
       "8   0.0  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   ...       NaN   \n",
       "9   0.0  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   ...       NaN   \n",
       "\n",
       "   wdct_2  wdct_3  wdct_4  wdct_5  gust_1  gust_2  gust_3  gust_4  gust_5  \n",
       "5     NaN     NaN     NaN     NaN     0.0     0.0     0.0     0.0     0.0  \n",
       "6     NaN     NaN     NaN     NaN     0.0     0.0     0.0     0.0     0.0  \n",
       "7     NaN     NaN     NaN     NaN     0.0     0.0     0.0     0.0     0.0  \n",
       "8     NaN     NaN     NaN     NaN     0.0     0.0     0.0     0.0     0.0  \n",
       "9     NaN     NaN     NaN     NaN     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm[cols] = dfm[cols].replace({0.0:np.nan})\n",
    "dfm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = dfm.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86007"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prcp</th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>dewp</th>\n",
       "      <th>dmax</th>\n",
       "      <th>dmin</th>\n",
       "      <th>...</th>\n",
       "      <th>wdct_1</th>\n",
       "      <th>wdct_2</th>\n",
       "      <th>wdct_3</th>\n",
       "      <th>wdct_4</th>\n",
       "      <th>wdct_5</th>\n",
       "      <th>gust_1</th>\n",
       "      <th>gust_2</th>\n",
       "      <th>gust_3</th>\n",
       "      <th>gust_4</th>\n",
       "      <th>gust_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>922.2</td>\n",
       "      <td>922.0</td>\n",
       "      <td>21.4</td>\n",
       "      <td>14.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>13.7</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>922.1</td>\n",
       "      <td>922.2</td>\n",
       "      <td>922.0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>14.8</td>\n",
       "      <td>21.4</td>\n",
       "      <td>14.9</td>\n",
       "      <td>20.7</td>\n",
       "      <td>14.2</td>\n",
       "      <td>...</td>\n",
       "      <td>118.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>921.9</td>\n",
       "      <td>922.1</td>\n",
       "      <td>921.8</td>\n",
       "      <td>20.3</td>\n",
       "      <td>14.9</td>\n",
       "      <td>20.8</td>\n",
       "      <td>15.1</td>\n",
       "      <td>20.3</td>\n",
       "      <td>14.7</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>921.6</td>\n",
       "      <td>922.1</td>\n",
       "      <td>921.6</td>\n",
       "      <td>20.1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>20.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>...</td>\n",
       "      <td>118.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>921.8</td>\n",
       "      <td>921.8</td>\n",
       "      <td>921.5</td>\n",
       "      <td>19.8</td>\n",
       "      <td>13.9</td>\n",
       "      <td>20.2</td>\n",
       "      <td>14.2</td>\n",
       "      <td>19.8</td>\n",
       "      <td>13.7</td>\n",
       "      <td>...</td>\n",
       "      <td>102.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    prcp    stp   smax   smin  temp  tmax  tmin  dewp  dmax  dmin   ...    \\\n",
       "19   0.0  922.0  922.2  922.0  21.4  14.2  22.0  15.0  21.3  13.7   ...     \n",
       "20   0.0  922.1  922.2  922.0  20.7  14.8  21.4  14.9  20.7  14.2   ...     \n",
       "21   0.0  921.9  922.1  921.8  20.3  14.9  20.8  15.1  20.3  14.7   ...     \n",
       "22   0.0  921.6  922.1  921.6  20.1  14.2  20.4  15.0  20.0  14.2   ...     \n",
       "23   0.0  921.8  921.8  921.5  19.8  13.9  20.2  14.2  19.8  13.7   ...     \n",
       "\n",
       "    wdct_1  wdct_2  wdct_3  wdct_4  wdct_5  gust_1  gust_2  gust_3  gust_4  \\\n",
       "19    59.0    61.0    69.0    98.0    75.0     6.9     8.0     7.3     8.8   \n",
       "20   118.0    59.0    61.0    69.0    98.0     7.5     6.9     8.0     7.3   \n",
       "21   108.0   118.0    59.0    61.0    69.0     7.7     7.5     6.9     8.0   \n",
       "22   118.0   108.0   118.0    59.0    61.0     7.6     7.7     7.5     6.9   \n",
       "23   102.0   118.0   108.0   118.0    59.0     7.3     7.6     7.7     7.5   \n",
       "\n",
       "    gust_5  \n",
       "19     8.8  \n",
       "20     8.8  \n",
       "21     7.3  \n",
       "22     8.0  \n",
       "23     6.9  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prcp</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>0.200865</td>\n",
       "      <td>1.632529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>919.116980</td>\n",
       "      <td>3.190611</td>\n",
       "      <td>906.5</td>\n",
       "      <td>916.9</td>\n",
       "      <td>919.0</td>\n",
       "      <td>921.2</td>\n",
       "      <td>931.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>919.358709</td>\n",
       "      <td>3.171215</td>\n",
       "      <td>906.7</td>\n",
       "      <td>917.2</td>\n",
       "      <td>919.2</td>\n",
       "      <td>921.5</td>\n",
       "      <td>931.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>918.874314</td>\n",
       "      <td>3.199579</td>\n",
       "      <td>906.4</td>\n",
       "      <td>916.7</td>\n",
       "      <td>918.7</td>\n",
       "      <td>921.0</td>\n",
       "      <td>931.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>21.897662</td>\n",
       "      <td>3.927088</td>\n",
       "      <td>8.1</td>\n",
       "      <td>19.2</td>\n",
       "      <td>21.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>14.566931</td>\n",
       "      <td>3.529708</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>12.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>22.572387</td>\n",
       "      <td>4.097611</td>\n",
       "      <td>8.7</td>\n",
       "      <td>19.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>25.5</td>\n",
       "      <td>37.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewp</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>15.120801</td>\n",
       "      <td>3.520662</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>12.7</td>\n",
       "      <td>15.6</td>\n",
       "      <td>17.9</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmax</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>21.243377</td>\n",
       "      <td>3.753360</td>\n",
       "      <td>7.4</td>\n",
       "      <td>18.8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.8</td>\n",
       "      <td>35.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmin</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>14.039955</td>\n",
       "      <td>3.583685</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>11.7</td>\n",
       "      <td>14.5</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>65.841676</td>\n",
       "      <td>17.407714</td>\n",
       "      <td>10.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>68.708268</td>\n",
       "      <td>16.807485</td>\n",
       "      <td>13.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>62.954260</td>\n",
       "      <td>17.841561</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>2.121754</td>\n",
       "      <td>1.195657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>126.579499</td>\n",
       "      <td>88.420803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>5.314223</td>\n",
       "      <td>2.359634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp_1</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>919.116931</td>\n",
       "      <td>3.190422</td>\n",
       "      <td>906.5</td>\n",
       "      <td>916.9</td>\n",
       "      <td>919.0</td>\n",
       "      <td>921.2</td>\n",
       "      <td>931.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp_2</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>919.116864</td>\n",
       "      <td>3.190247</td>\n",
       "      <td>906.5</td>\n",
       "      <td>916.9</td>\n",
       "      <td>919.0</td>\n",
       "      <td>921.2</td>\n",
       "      <td>931.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp_3</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>919.116885</td>\n",
       "      <td>3.189953</td>\n",
       "      <td>906.5</td>\n",
       "      <td>916.9</td>\n",
       "      <td>919.0</td>\n",
       "      <td>921.2</td>\n",
       "      <td>931.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp_4</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>919.116922</td>\n",
       "      <td>3.189579</td>\n",
       "      <td>906.5</td>\n",
       "      <td>917.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>921.2</td>\n",
       "      <td>931.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp_5</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>919.116967</td>\n",
       "      <td>3.189199</td>\n",
       "      <td>906.5</td>\n",
       "      <td>917.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>921.2</td>\n",
       "      <td>931.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax_1</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>919.358639</td>\n",
       "      <td>3.170998</td>\n",
       "      <td>906.7</td>\n",
       "      <td>917.2</td>\n",
       "      <td>919.2</td>\n",
       "      <td>921.5</td>\n",
       "      <td>931.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax_2</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>919.358559</td>\n",
       "      <td>3.170784</td>\n",
       "      <td>906.7</td>\n",
       "      <td>917.2</td>\n",
       "      <td>919.2</td>\n",
       "      <td>921.5</td>\n",
       "      <td>931.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax_3</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>919.358539</td>\n",
       "      <td>3.170451</td>\n",
       "      <td>906.7</td>\n",
       "      <td>917.2</td>\n",
       "      <td>919.2</td>\n",
       "      <td>921.5</td>\n",
       "      <td>931.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax_4</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>919.358574</td>\n",
       "      <td>3.170110</td>\n",
       "      <td>906.7</td>\n",
       "      <td>917.2</td>\n",
       "      <td>919.2</td>\n",
       "      <td>921.5</td>\n",
       "      <td>931.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax_5</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>919.358610</td>\n",
       "      <td>3.169831</td>\n",
       "      <td>906.7</td>\n",
       "      <td>917.2</td>\n",
       "      <td>919.2</td>\n",
       "      <td>921.5</td>\n",
       "      <td>931.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin_1</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>918.874259</td>\n",
       "      <td>3.199432</td>\n",
       "      <td>906.4</td>\n",
       "      <td>916.7</td>\n",
       "      <td>918.7</td>\n",
       "      <td>921.0</td>\n",
       "      <td>931.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin_2</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>918.874294</td>\n",
       "      <td>3.199195</td>\n",
       "      <td>906.4</td>\n",
       "      <td>916.7</td>\n",
       "      <td>918.7</td>\n",
       "      <td>921.0</td>\n",
       "      <td>931.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin_3</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>918.874390</td>\n",
       "      <td>3.198847</td>\n",
       "      <td>906.4</td>\n",
       "      <td>916.7</td>\n",
       "      <td>918.7</td>\n",
       "      <td>921.0</td>\n",
       "      <td>931.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin_4</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>918.874460</td>\n",
       "      <td>3.198407</td>\n",
       "      <td>906.4</td>\n",
       "      <td>916.7</td>\n",
       "      <td>918.7</td>\n",
       "      <td>921.0</td>\n",
       "      <td>931.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy_1</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>65.844571</td>\n",
       "      <td>17.406595</td>\n",
       "      <td>12.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy_2</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>65.844850</td>\n",
       "      <td>17.406649</td>\n",
       "      <td>12.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy_3</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>65.844745</td>\n",
       "      <td>17.408240</td>\n",
       "      <td>12.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy_4</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>65.844606</td>\n",
       "      <td>17.411076</td>\n",
       "      <td>12.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy_5</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>65.843908</td>\n",
       "      <td>17.413577</td>\n",
       "      <td>12.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax_1</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>68.709965</td>\n",
       "      <td>16.807024</td>\n",
       "      <td>13.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax_2</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>68.709942</td>\n",
       "      <td>16.807958</td>\n",
       "      <td>13.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax_3</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>68.709175</td>\n",
       "      <td>16.810100</td>\n",
       "      <td>13.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax_4</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>68.707942</td>\n",
       "      <td>16.813312</td>\n",
       "      <td>13.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax_5</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>68.706687</td>\n",
       "      <td>16.816340</td>\n",
       "      <td>13.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin_1</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>62.956004</td>\n",
       "      <td>17.840914</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin_2</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>62.956236</td>\n",
       "      <td>17.842056</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin_3</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>62.956608</td>\n",
       "      <td>17.844270</td>\n",
       "      <td>11.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin_4</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>62.957120</td>\n",
       "      <td>17.846822</td>\n",
       "      <td>11.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin_5</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>62.956294</td>\n",
       "      <td>17.849971</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp_1</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>2.121539</td>\n",
       "      <td>1.195621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp_2</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>2.121467</td>\n",
       "      <td>1.195532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp_3</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>2.121189</td>\n",
       "      <td>1.195533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp_4</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>2.121180</td>\n",
       "      <td>1.195564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp_5</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>2.121255</td>\n",
       "      <td>1.195675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct_1</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>126.576244</td>\n",
       "      <td>88.413254</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct_2</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>126.572605</td>\n",
       "      <td>88.399992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct_3</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>126.553025</td>\n",
       "      <td>88.389788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct_4</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>126.529782</td>\n",
       "      <td>88.377773</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct_5</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>126.532538</td>\n",
       "      <td>88.381503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust_1</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>5.313821</td>\n",
       "      <td>2.359852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust_2</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>5.313238</td>\n",
       "      <td>2.359721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust_3</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>5.312502</td>\n",
       "      <td>2.359189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust_4</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>5.312198</td>\n",
       "      <td>2.359235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust_5</th>\n",
       "      <td>86007.0</td>\n",
       "      <td>5.311584</td>\n",
       "      <td>2.358890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          count        mean        std    min    25%    50%    75%    max\n",
       "prcp    86007.0    0.200865   1.632529    0.0    0.0    0.0    0.0   78.4\n",
       "stp     86007.0  919.116980   3.190611  906.5  916.9  919.0  921.2  931.4\n",
       "smax    86007.0  919.358709   3.171215  906.7  917.2  919.2  921.5  931.5\n",
       "smin    86007.0  918.874314   3.199579  906.4  916.7  918.7  921.0  931.2\n",
       "temp    86007.0   21.897662   3.927088    8.1   19.2   21.6   24.6   37.0\n",
       "tmax    86007.0   14.566931   3.529708   -6.3   12.2   15.0   17.4   25.5\n",
       "tmin    86007.0   22.572387   4.097611    8.7   19.7   22.2   25.5   37.7\n",
       "dewp    86007.0   15.120801   3.520662   -1.7   12.7   15.6   17.9   23.6\n",
       "dmax    86007.0   21.243377   3.753360    7.4   18.8   21.0   23.8   35.1\n",
       "dmin    86007.0   14.039955   3.583685   -6.5   11.7   14.5   16.9   21.6\n",
       "hmdy    86007.0   65.841676  17.407714   10.0   54.0   67.0   79.0   99.0\n",
       "hmax    86007.0   68.708268  16.807485   13.0   57.0   70.0   82.0   99.0\n",
       "hmin    86007.0   62.954260  17.841561   10.0   50.0   64.0   77.0   99.0\n",
       "wdsp    86007.0    2.121754   1.195657    0.0    1.3    2.1    2.9   10.2\n",
       "wdct    86007.0  126.579499  88.420803    1.0   78.0   99.0  127.0  360.0\n",
       "gust    86007.0    5.314223   2.359634    0.0    3.8    5.4    6.9   25.0\n",
       "stp_1   86007.0  919.116931   3.190422  906.5  916.9  919.0  921.2  931.4\n",
       "stp_2   86007.0  919.116864   3.190247  906.5  916.9  919.0  921.2  931.4\n",
       "stp_3   86007.0  919.116885   3.189953  906.5  916.9  919.0  921.2  931.4\n",
       "stp_4   86007.0  919.116922   3.189579  906.5  917.0  919.0  921.2  931.4\n",
       "stp_5   86007.0  919.116967   3.189199  906.5  917.0  919.0  921.2  931.4\n",
       "smax_1  86007.0  919.358639   3.170998  906.7  917.2  919.2  921.5  931.5\n",
       "smax_2  86007.0  919.358559   3.170784  906.7  917.2  919.2  921.5  931.5\n",
       "smax_3  86007.0  919.358539   3.170451  906.7  917.2  919.2  921.5  931.5\n",
       "smax_4  86007.0  919.358574   3.170110  906.7  917.2  919.2  921.5  931.5\n",
       "smax_5  86007.0  919.358610   3.169831  906.7  917.2  919.2  921.5  931.5\n",
       "smin_1  86007.0  918.874259   3.199432  906.4  916.7  918.7  921.0  931.2\n",
       "smin_2  86007.0  918.874294   3.199195  906.4  916.7  918.7  921.0  931.2\n",
       "smin_3  86007.0  918.874390   3.198847  906.4  916.7  918.7  921.0  931.2\n",
       "smin_4  86007.0  918.874460   3.198407  906.4  916.7  918.7  921.0  931.2\n",
       "...         ...         ...        ...    ...    ...    ...    ...    ...\n",
       "hmdy_1  86007.0   65.844571  17.406595   12.0   54.0   67.0   79.0   99.0\n",
       "hmdy_2  86007.0   65.844850  17.406649   12.0   54.0   67.0   79.0   99.0\n",
       "hmdy_3  86007.0   65.844745  17.408240   12.0   54.0   67.0   79.0   99.0\n",
       "hmdy_4  86007.0   65.844606  17.411076   12.0   54.0   67.0   79.0   99.0\n",
       "hmdy_5  86007.0   65.843908  17.413577   12.0   54.0   67.0   79.0   99.0\n",
       "hmax_1  86007.0   68.709965  16.807024   13.0   57.0   70.0   82.0   99.0\n",
       "hmax_2  86007.0   68.709942  16.807958   13.0   57.0   70.0   82.0   99.0\n",
       "hmax_3  86007.0   68.709175  16.810100   13.0   57.0   70.0   82.0   99.0\n",
       "hmax_4  86007.0   68.707942  16.813312   13.0   57.0   70.0   82.0   99.0\n",
       "hmax_5  86007.0   68.706687  16.816340   13.0   57.0   70.0   82.0   99.0\n",
       "hmin_1  86007.0   62.956004  17.840914   12.0   50.0   64.0   77.0   99.0\n",
       "hmin_2  86007.0   62.956236  17.842056   12.0   50.0   64.0   77.0   99.0\n",
       "hmin_3  86007.0   62.956608  17.844270   11.0   50.0   64.0   77.0   99.0\n",
       "hmin_4  86007.0   62.957120  17.846822   11.0   50.0   64.0   77.0   99.0\n",
       "hmin_5  86007.0   62.956294  17.849971   10.0   50.0   64.0   77.0   99.0\n",
       "wdsp_1  86007.0    2.121539   1.195621    0.0    1.3    2.1    2.9   10.2\n",
       "wdsp_2  86007.0    2.121467   1.195532    0.0    1.3    2.1    2.9   10.2\n",
       "wdsp_3  86007.0    2.121189   1.195533    0.0    1.3    2.1    2.9   10.2\n",
       "wdsp_4  86007.0    2.121180   1.195564    0.0    1.3    2.1    2.9   10.2\n",
       "wdsp_5  86007.0    2.121255   1.195675    0.0    1.3    2.1    2.9   10.2\n",
       "wdct_1  86007.0  126.576244  88.413254    1.0   78.0   99.0  127.0  360.0\n",
       "wdct_2  86007.0  126.572605  88.399992    1.0   79.0   99.0  127.0  360.0\n",
       "wdct_3  86007.0  126.553025  88.389788    1.0   79.0   99.0  127.0  360.0\n",
       "wdct_4  86007.0  126.529782  88.377773    1.0   78.0   99.0  127.0  360.0\n",
       "wdct_5  86007.0  126.532538  88.381503    1.0   78.0   99.0  127.0  360.0\n",
       "gust_1  86007.0    5.313821   2.359852    0.0    3.8    5.4    6.9   25.0\n",
       "gust_2  86007.0    5.313238   2.359721    0.0    3.8    5.4    6.9   25.0\n",
       "gust_3  86007.0    5.312502   2.359189    0.0    3.8    5.4    6.9   25.0\n",
       "gust_4  86007.0    5.312198   2.359235    0.0    3.8    5.4    6.9   25.0\n",
       "gust_5  86007.0    5.311584   2.358890    0.0    3.8    5.4    6.9   25.0\n",
       "\n",
       "[91 rows x 8 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkp = dfm\n",
    "#dfm = bkp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp50 = dfm[(dfm['prcp']> 0.0)]\n",
    "dfp00 = dfm[(dfm['prcp'] == 0.0)]\n",
    "dfp00 = dfm.sample(n=len(dfp50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = dfp00.append(dfp50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11474"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prcp</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>1.609587</td>\n",
       "      <td>4.411131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>78.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>917.921893</td>\n",
       "      <td>3.181498</td>\n",
       "      <td>906.7</td>\n",
       "      <td>915.7</td>\n",
       "      <td>917.7</td>\n",
       "      <td>919.90</td>\n",
       "      <td>929.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>918.174621</td>\n",
       "      <td>3.164882</td>\n",
       "      <td>906.7</td>\n",
       "      <td>916.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>920.10</td>\n",
       "      <td>929.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>917.628429</td>\n",
       "      <td>3.197455</td>\n",
       "      <td>906.4</td>\n",
       "      <td>915.4</td>\n",
       "      <td>917.4</td>\n",
       "      <td>919.60</td>\n",
       "      <td>929.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>20.966176</td>\n",
       "      <td>3.258535</td>\n",
       "      <td>9.3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>22.60</td>\n",
       "      <td>35.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>16.343803</td>\n",
       "      <td>3.247955</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>17.3</td>\n",
       "      <td>18.70</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>21.747734</td>\n",
       "      <td>3.567036</td>\n",
       "      <td>10.4</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.80</td>\n",
       "      <td>36.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dewp</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>16.821562</td>\n",
       "      <td>3.223994</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>15.1</td>\n",
       "      <td>17.8</td>\n",
       "      <td>19.10</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmax</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>20.424490</td>\n",
       "      <td>3.058218</td>\n",
       "      <td>8.5</td>\n",
       "      <td>18.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.90</td>\n",
       "      <td>35.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmin</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>15.819592</td>\n",
       "      <td>3.279253</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>18.30</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>77.464528</td>\n",
       "      <td>17.680484</td>\n",
       "      <td>14.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>92.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>79.744902</td>\n",
       "      <td>16.712661</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>73.695921</td>\n",
       "      <td>18.507484</td>\n",
       "      <td>12.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>1.906763</td>\n",
       "      <td>1.222434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.70</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>141.476817</td>\n",
       "      <td>98.230290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>195.75</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>5.371666</td>\n",
       "      <td>2.773967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.90</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp_1</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>917.875118</td>\n",
       "      <td>3.194689</td>\n",
       "      <td>906.5</td>\n",
       "      <td>915.7</td>\n",
       "      <td>917.7</td>\n",
       "      <td>919.80</td>\n",
       "      <td>929.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp_2</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>917.811034</td>\n",
       "      <td>3.209945</td>\n",
       "      <td>907.3</td>\n",
       "      <td>915.6</td>\n",
       "      <td>917.6</td>\n",
       "      <td>919.80</td>\n",
       "      <td>930.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp_3</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>917.774002</td>\n",
       "      <td>3.221118</td>\n",
       "      <td>908.1</td>\n",
       "      <td>915.5</td>\n",
       "      <td>917.6</td>\n",
       "      <td>919.80</td>\n",
       "      <td>931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp_4</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>917.761722</td>\n",
       "      <td>3.225794</td>\n",
       "      <td>907.7</td>\n",
       "      <td>915.5</td>\n",
       "      <td>917.6</td>\n",
       "      <td>919.70</td>\n",
       "      <td>931.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stp_5</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>917.770455</td>\n",
       "      <td>3.225879</td>\n",
       "      <td>907.3</td>\n",
       "      <td>915.5</td>\n",
       "      <td>917.6</td>\n",
       "      <td>919.70</td>\n",
       "      <td>931.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax_1</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>918.117239</td>\n",
       "      <td>3.177960</td>\n",
       "      <td>907.3</td>\n",
       "      <td>915.9</td>\n",
       "      <td>917.9</td>\n",
       "      <td>920.10</td>\n",
       "      <td>930.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax_2</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>918.062768</td>\n",
       "      <td>3.194418</td>\n",
       "      <td>908.1</td>\n",
       "      <td>915.9</td>\n",
       "      <td>917.9</td>\n",
       "      <td>920.00</td>\n",
       "      <td>931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax_3</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>918.032874</td>\n",
       "      <td>3.203615</td>\n",
       "      <td>908.5</td>\n",
       "      <td>915.8</td>\n",
       "      <td>917.9</td>\n",
       "      <td>920.00</td>\n",
       "      <td>931.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax_4</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>918.026355</td>\n",
       "      <td>3.205944</td>\n",
       "      <td>907.8</td>\n",
       "      <td>915.8</td>\n",
       "      <td>917.8</td>\n",
       "      <td>920.00</td>\n",
       "      <td>931.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smax_5</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>918.038278</td>\n",
       "      <td>3.204015</td>\n",
       "      <td>907.4</td>\n",
       "      <td>915.8</td>\n",
       "      <td>917.9</td>\n",
       "      <td>920.00</td>\n",
       "      <td>931.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin_1</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>917.570760</td>\n",
       "      <td>3.214708</td>\n",
       "      <td>906.5</td>\n",
       "      <td>915.4</td>\n",
       "      <td>917.3</td>\n",
       "      <td>919.60</td>\n",
       "      <td>929.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin_2</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>917.522834</td>\n",
       "      <td>3.225909</td>\n",
       "      <td>907.3</td>\n",
       "      <td>915.3</td>\n",
       "      <td>917.3</td>\n",
       "      <td>919.50</td>\n",
       "      <td>930.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin_3</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>917.503050</td>\n",
       "      <td>3.232483</td>\n",
       "      <td>907.7</td>\n",
       "      <td>915.3</td>\n",
       "      <td>917.3</td>\n",
       "      <td>919.50</td>\n",
       "      <td>931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smin_4</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>917.505055</td>\n",
       "      <td>3.234843</td>\n",
       "      <td>907.3</td>\n",
       "      <td>915.3</td>\n",
       "      <td>917.3</td>\n",
       "      <td>919.50</td>\n",
       "      <td>931.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy_1</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>75.992853</td>\n",
       "      <td>17.740411</td>\n",
       "      <td>13.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>92.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy_2</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>74.554907</td>\n",
       "      <td>17.803546</td>\n",
       "      <td>14.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy_3</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>73.574342</td>\n",
       "      <td>17.848386</td>\n",
       "      <td>13.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>89.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy_4</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>72.884522</td>\n",
       "      <td>17.815610</td>\n",
       "      <td>12.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>88.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmdy_5</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>72.432979</td>\n",
       "      <td>17.738041</td>\n",
       "      <td>14.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>88.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax_1</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>78.173000</td>\n",
       "      <td>16.807589</td>\n",
       "      <td>15.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax_2</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>76.932195</td>\n",
       "      <td>16.874528</td>\n",
       "      <td>15.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>92.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax_3</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>76.100314</td>\n",
       "      <td>16.877943</td>\n",
       "      <td>14.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax_4</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>75.537215</td>\n",
       "      <td>16.835680</td>\n",
       "      <td>15.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmax_5</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>75.171954</td>\n",
       "      <td>16.800613</td>\n",
       "      <td>16.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin_1</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>72.180582</td>\n",
       "      <td>18.566288</td>\n",
       "      <td>12.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>88.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin_2</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>71.065627</td>\n",
       "      <td>18.600259</td>\n",
       "      <td>12.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>87.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin_3</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>70.248562</td>\n",
       "      <td>18.632353</td>\n",
       "      <td>12.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>86.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin_4</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>69.679885</td>\n",
       "      <td>18.542168</td>\n",
       "      <td>12.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>85.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmin_5</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>69.320638</td>\n",
       "      <td>18.468692</td>\n",
       "      <td>13.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>85.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp_1</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>1.963535</td>\n",
       "      <td>1.241594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.70</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp_2</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>1.960284</td>\n",
       "      <td>1.221829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.70</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp_3</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>1.960014</td>\n",
       "      <td>1.205432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.70</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp_4</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>1.959404</td>\n",
       "      <td>1.196633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.70</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdsp_5</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>1.962968</td>\n",
       "      <td>1.193099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.70</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct_1</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>141.918860</td>\n",
       "      <td>100.332506</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>204.00</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct_2</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>140.658707</td>\n",
       "      <td>101.002249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>202.00</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct_3</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>139.710302</td>\n",
       "      <td>101.496273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>197.00</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct_4</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>138.470804</td>\n",
       "      <td>101.747499</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>190.00</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wdct_5</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>137.359421</td>\n",
       "      <td>101.285162</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>182.00</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust_1</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>5.382857</td>\n",
       "      <td>2.759879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.90</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust_2</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>5.308489</td>\n",
       "      <td>2.620856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.80</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust_3</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>5.251795</td>\n",
       "      <td>2.544905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.70</td>\n",
       "      <td>24.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust_4</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>5.224516</td>\n",
       "      <td>2.487690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.70</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gust_5</th>\n",
       "      <td>11474.0</td>\n",
       "      <td>5.190309</td>\n",
       "      <td>2.449159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.70</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          count        mean         std    min    25%    50%     75%    max\n",
       "prcp    11474.0    1.609587    4.411131    0.0    0.0    0.2    1.00   78.4\n",
       "stp     11474.0  917.921893    3.181498  906.7  915.7  917.7  919.90  929.3\n",
       "smax    11474.0  918.174621    3.164882  906.7  916.0  918.0  920.10  929.7\n",
       "smin    11474.0  917.628429    3.197455  906.4  915.4  917.4  919.60  929.2\n",
       "temp    11474.0   20.966176    3.258535    9.3   19.0   20.4   22.60   35.6\n",
       "tmax    11474.0   16.343803    3.247955   -2.0   14.6   17.3   18.70   22.6\n",
       "tmin    11474.0   21.747734    3.567036   10.4   19.4   21.0   23.80   36.9\n",
       "dewp    11474.0   16.821562    3.223994   -1.7   15.1   17.8   19.10   23.6\n",
       "dmax    11474.0   20.424490    3.058218    8.5   18.7   20.0   21.90   35.1\n",
       "dmin    11474.0   15.819592    3.279253   -4.4   14.0   16.8   18.30   21.4\n",
       "hmdy    11474.0   77.464528   17.680484   14.0   66.0   83.0   92.00   99.0\n",
       "hmax    11474.0   79.744902   16.712661   15.0   70.0   86.0   93.00   99.0\n",
       "hmin    11474.0   73.695921   18.507484   12.0   61.0   78.0   90.00   99.0\n",
       "wdsp    11474.0    1.906763    1.222434    0.0    1.0    1.8    2.70   10.2\n",
       "wdct    11474.0  141.476817   98.230290    1.0   78.0  105.0  195.75  360.0\n",
       "gust    11474.0    5.371666    2.773967    0.0    3.5    5.1    6.90   25.0\n",
       "stp_1   11474.0  917.875118    3.194689  906.5  915.7  917.7  919.80  929.7\n",
       "stp_2   11474.0  917.811034    3.209945  907.3  915.6  917.6  919.80  930.4\n",
       "stp_3   11474.0  917.774002    3.221118  908.1  915.5  917.6  919.80  931.0\n",
       "stp_4   11474.0  917.761722    3.225794  907.7  915.5  917.6  919.70  931.4\n",
       "stp_5   11474.0  917.770455    3.225879  907.3  915.5  917.6  919.70  931.2\n",
       "smax_1  11474.0  918.117239    3.177960  907.3  915.9  917.9  920.10  930.4\n",
       "smax_2  11474.0  918.062768    3.194418  908.1  915.9  917.9  920.00  931.0\n",
       "smax_3  11474.0  918.032874    3.203615  908.5  915.8  917.9  920.00  931.4\n",
       "smax_4  11474.0  918.026355    3.205944  907.8  915.8  917.8  920.00  931.5\n",
       "smax_5  11474.0  918.038278    3.204015  907.4  915.8  917.9  920.00  931.2\n",
       "smin_1  11474.0  917.570760    3.214708  906.5  915.4  917.3  919.60  929.7\n",
       "smin_2  11474.0  917.522834    3.225909  907.3  915.3  917.3  919.50  930.4\n",
       "smin_3  11474.0  917.503050    3.232483  907.7  915.3  917.3  919.50  931.0\n",
       "smin_4  11474.0  917.505055    3.234843  907.3  915.3  917.3  919.50  931.2\n",
       "...         ...         ...         ...    ...    ...    ...     ...    ...\n",
       "hmdy_1  11474.0   75.992853   17.740411   13.0   64.0   81.0   92.00   99.0\n",
       "hmdy_2  11474.0   74.554907   17.803546   14.0   62.0   78.0   90.00   99.0\n",
       "hmdy_3  11474.0   73.574342   17.848386   13.0   61.0   76.0   89.00   99.0\n",
       "hmdy_4  11474.0   72.884522   17.815610   12.0   60.0   75.0   88.00   99.0\n",
       "hmdy_5  11474.0   72.432979   17.738041   14.0   60.0   75.0   88.00   99.0\n",
       "hmax_1  11474.0   78.173000   16.807589   15.0   67.0   83.0   93.00   99.0\n",
       "hmax_2  11474.0   76.932195   16.874528   15.0   65.0   81.0   92.00   99.0\n",
       "hmax_3  11474.0   76.100314   16.877943   14.0   64.0   79.0   91.00   99.0\n",
       "hmax_4  11474.0   75.537215   16.835680   15.0   64.0   78.0   90.00   99.0\n",
       "hmax_5  11474.0   75.171954   16.800613   16.0   64.0   78.0   90.00   99.0\n",
       "hmin_1  11474.0   72.180582   18.566288   12.0   59.0   75.0   88.00   99.0\n",
       "hmin_2  11474.0   71.065627   18.600259   12.0   57.0   74.0   87.00   99.0\n",
       "hmin_3  11474.0   70.248562   18.632353   12.0   57.0   72.0   86.00   99.0\n",
       "hmin_4  11474.0   69.679885   18.542168   12.0   56.0   71.0   85.00   99.0\n",
       "hmin_5  11474.0   69.320638   18.468692   13.0   56.0   71.0   85.00   99.0\n",
       "wdsp_1  11474.0    1.963535    1.241594    0.0    1.1    1.9    2.70   10.2\n",
       "wdsp_2  11474.0    1.960284    1.221829    0.0    1.1    1.9    2.70   10.2\n",
       "wdsp_3  11474.0    1.960014    1.205432    0.0    1.1    1.9    2.70    9.6\n",
       "wdsp_4  11474.0    1.959404    1.196633    0.0    1.1    1.9    2.70   10.1\n",
       "wdsp_5  11474.0    1.962968    1.193099    0.0    1.1    1.9    2.70    8.0\n",
       "wdct_1  11474.0  141.918860  100.332506    1.0   76.0  104.0  204.00  360.0\n",
       "wdct_2  11474.0  140.658707  101.002249    1.0   75.0  103.0  202.00  360.0\n",
       "wdct_3  11474.0  139.710302  101.496273    1.0   73.0  102.0  197.00  360.0\n",
       "wdct_4  11474.0  138.470804  101.747499    1.0   72.0  101.0  190.00  360.0\n",
       "wdct_5  11474.0  137.359421  101.285162    1.0   72.0  101.0  182.00  360.0\n",
       "gust_1  11474.0    5.382857    2.759879    0.0    3.5    5.2    6.90   25.0\n",
       "gust_2  11474.0    5.308489    2.620856    0.0    3.5    5.2    6.80   25.0\n",
       "gust_3  11474.0    5.251795    2.544905    0.0    3.5    5.1    6.70   24.4\n",
       "gust_4  11474.0    5.224516    2.487690    0.0    3.5    5.1    6.70   21.0\n",
       "gust_5  11474.0    5.190309    2.449159    0.0    3.5    5.1    6.70   21.0\n",
       "\n",
       "[91 rows x 8 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mineiração dos dados</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Rede neural</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  \n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error,  median_absolute_error\n",
    "from sklearn.model_selection import train_test_split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'prcp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfm[[col for col in dfm.columns if col != target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dfm[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stp</th>\n",
       "      <th>smax</th>\n",
       "      <th>smin</th>\n",
       "      <th>temp</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>dewp</th>\n",
       "      <th>dmax</th>\n",
       "      <th>dmin</th>\n",
       "      <th>hmdy</th>\n",
       "      <th>...</th>\n",
       "      <th>wdct_1</th>\n",
       "      <th>wdct_2</th>\n",
       "      <th>wdct_3</th>\n",
       "      <th>wdct_4</th>\n",
       "      <th>wdct_5</th>\n",
       "      <th>gust_1</th>\n",
       "      <th>gust_2</th>\n",
       "      <th>gust_3</th>\n",
       "      <th>gust_4</th>\n",
       "      <th>gust_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50789</th>\n",
       "      <td>921.2</td>\n",
       "      <td>921.7</td>\n",
       "      <td>921.2</td>\n",
       "      <td>15.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>15.9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15872</th>\n",
       "      <td>919.9</td>\n",
       "      <td>919.9</td>\n",
       "      <td>919.8</td>\n",
       "      <td>15.6</td>\n",
       "      <td>10.4</td>\n",
       "      <td>16.3</td>\n",
       "      <td>10.5</td>\n",
       "      <td>15.6</td>\n",
       "      <td>9.9</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7992</th>\n",
       "      <td>923.6</td>\n",
       "      <td>923.6</td>\n",
       "      <td>923.4</td>\n",
       "      <td>20.7</td>\n",
       "      <td>9.5</td>\n",
       "      <td>21.4</td>\n",
       "      <td>9.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>109.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.8</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7894</th>\n",
       "      <td>924.8</td>\n",
       "      <td>924.8</td>\n",
       "      <td>924.2</td>\n",
       "      <td>21.8</td>\n",
       "      <td>12.9</td>\n",
       "      <td>22.9</td>\n",
       "      <td>13.1</td>\n",
       "      <td>21.8</td>\n",
       "      <td>12.6</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>11.1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54072</th>\n",
       "      <td>917.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>915.9</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>22.9</td>\n",
       "      <td>16.7</td>\n",
       "      <td>21.7</td>\n",
       "      <td>16.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         stp   smax   smin  temp  tmax  tmin  dewp  dmax  dmin  hmdy   ...    \\\n",
       "50789  921.2  921.7  921.2  15.9   7.3  18.0   7.5  15.9   7.0  57.0   ...     \n",
       "15872  919.9  919.9  919.8  15.6  10.4  16.3  10.5  15.6   9.9  71.0   ...     \n",
       "7992   923.6  923.6  923.4  20.7   9.5  21.4   9.6  20.7   9.2  49.0   ...     \n",
       "7894   924.8  924.8  924.2  21.8  12.9  22.9  13.1  21.8  12.6  57.0   ...     \n",
       "54072  917.0  917.0  915.9  22.0  16.5  22.9  16.7  21.7  16.0  71.0   ...     \n",
       "\n",
       "       wdct_1  wdct_2  wdct_3  wdct_4  wdct_5  gust_1  gust_2  gust_3  gust_4  \\\n",
       "50789   108.0     6.0   124.0    80.0   103.0     3.3     2.3     1.2     2.2   \n",
       "15872   193.0   148.0   112.0   128.0   122.0     1.6     2.6     3.0     3.8   \n",
       "7992    109.0    93.0    88.0    77.0    71.0     5.0     5.5     8.4     8.8   \n",
       "7894     71.0    80.0    91.0    89.0    88.0    11.1    11.1    11.0    10.1   \n",
       "54072    35.0   352.0   167.0   175.0   219.0     3.2     5.0     5.1     5.3   \n",
       "\n",
       "       gust_5  \n",
       "50789     2.5  \n",
       "15872     3.6  \n",
       "7992      7.0  \n",
       "7894     10.3  \n",
       "54072     8.0  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Separando o conjunto de treinamento e validação</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Separando o conjunto de testes (metade dos 30% separados para validação)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_val, y_test, y_val = train_test_split(X_tmp, y_tmp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances   8031, Training features   90\n",
      "Validation instances 1722, Validation features 90\n",
      "Testing instances    1721, Testing features    90\n"
     ]
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_val.shape  \n",
    "print(\"Training instances   {}, Training features   {}\".format(X_train.shape[0], X_train.shape[1]))  \n",
    "print(\"Validation instances {}, Validation features {}\".format(X_val.shape[0], X_val.shape[1]))  \n",
    "print(\"Testing instances    {}, Testing features    {}\".format(X_test.shape[0], X_test.shape[1]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zarate instructions\n",
    "st_units = (X_train.shape[1] * 2) + 1\n",
    "sd_units = X_train.shape[1] \n",
    "#activation_fn = tf.sigmoid\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [tf.feature_column.numeric_column(col) for col in X.columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4ba980b650>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tf_wx_model-9', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.estimator.DNNRegressor(feature_columns=feature_cols,  \n",
    "                                      hidden_units=[st_units,sd_units],\n",
    "                                     # activation_fn=activation_fn,\n",
    "                                      model_dir='/tmp/tf_wx_model-9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wx_input_fn(X, y=None, num_epochs=None, shuffle=True, batch_size=batch_size):  \n",
    "    return tf.estimator.inputs.pandas_input_fn(x=X,\n",
    "                                               y=y,\n",
    "                                               num_epochs=num_epochs,\n",
    "                                               shuffle=shuffle,\n",
    "                                               batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7116066.5, step = 1\n",
      "INFO:tensorflow:global_step/sec: 24.4137\n",
      "INFO:tensorflow:loss = 26489.246, step = 101 (4.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7814\n",
      "INFO:tensorflow:loss = 25844.562, step = 201 (4.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2032\n",
      "INFO:tensorflow:loss = 24140.258, step = 301 (3.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2623\n",
      "INFO:tensorflow:loss = 21331.867, step = 401 (3.959 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 15626.115.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:04:15\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:04:15\n",
      "INFO:tensorflow:Saving dict for global step 500: average_loss = 36.80442, global_step = 500, loss = 15844.304\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-500\n",
      "INFO:tensorflow:Saving checkpoints for 501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 18872.68, step = 501\n",
      "INFO:tensorflow:global_step/sec: 24.6674\n",
      "INFO:tensorflow:loss = 22286.889, step = 601 (4.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9751\n",
      "INFO:tensorflow:loss = 13974.254, step = 701 (4.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4784\n",
      "INFO:tensorflow:loss = 13641.79, step = 801 (3.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0001\n",
      "INFO:tensorflow:loss = 12475.913, step = 901 (3.846 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 13829.24.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:04:39\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:04:39\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 29.090603, global_step = 1000, loss = 12523.505\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-1000\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 9717.219, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 24.2139\n",
      "INFO:tensorflow:loss = 12447.65, step = 1101 (4.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3274\n",
      "INFO:tensorflow:loss = 15231.351, step = 1201 (3.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5864\n",
      "INFO:tensorflow:loss = 7158.6997, step = 1301 (3.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8181\n",
      "INFO:tensorflow:loss = 9979.246, step = 1401 (4.033 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8793.664.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:05:03\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-1500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:05:03\n",
      "INFO:tensorflow:Saving dict for global step 1500: average_loss = 25.8968, global_step = 1500, loss = 11148.572\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-1500\n",
      "INFO:tensorflow:Saving checkpoints for 1501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 10513.584, step = 1501\n",
      "INFO:tensorflow:global_step/sec: 23.7287\n",
      "INFO:tensorflow:loss = 6339.9575, step = 1601 (4.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.936\n",
      "INFO:tensorflow:loss = 8096.2563, step = 1701 (4.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.963\n",
      "INFO:tensorflow:loss = 9836.813, step = 1801 (3.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9805\n",
      "INFO:tensorflow:loss = 6873.7764, step = 1901 (3.849 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 15514.349.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:05:27\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:05:27\n",
      "INFO:tensorflow:Saving dict for global step 2000: average_loss = 24.168917, global_step = 2000, loss = 10404.719\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-2000\n",
      "INFO:tensorflow:Saving checkpoints for 2001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 5778.8555, step = 2001\n",
      "INFO:tensorflow:global_step/sec: 24.094\n",
      "INFO:tensorflow:loss = 8390.387, step = 2101 (4.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5682\n",
      "INFO:tensorflow:loss = 6932.4575, step = 2201 (3.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.732\n",
      "INFO:tensorflow:loss = 11772.872, step = 2301 (3.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5284\n",
      "INFO:tensorflow:loss = 10318.178, step = 2401 (4.077 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9273.741.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:05:51\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-2500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:05:51\n",
      "INFO:tensorflow:Saving dict for global step 2500: average_loss = 23.201912, global_step = 2500, loss = 9988.423\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-2500\n",
      "INFO:tensorflow:Saving checkpoints for 2501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 12169.031, step = 2501\n",
      "INFO:tensorflow:global_step/sec: 24.7397\n",
      "INFO:tensorflow:loss = 14467.076, step = 2601 (4.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2793\n",
      "INFO:tensorflow:loss = 13793.221, step = 2701 (3.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6136\n",
      "INFO:tensorflow:loss = 7902.6455, step = 2801 (3.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.002\n",
      "INFO:tensorflow:loss = 9251.615, step = 2901 (4.000 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 13238.824.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:06:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-3000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:06:15\n",
      "INFO:tensorflow:Saving dict for global step 3000: average_loss = 22.601494, global_step = 3000, loss = 9729.943\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-3000\n",
      "INFO:tensorflow:Saving checkpoints for 3001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 12230.412, step = 3001\n",
      "INFO:tensorflow:global_step/sec: 24.6801\n",
      "INFO:tensorflow:loss = 8652.946, step = 3101 (4.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1219\n",
      "INFO:tensorflow:loss = 7259.2705, step = 3201 (3.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0832\n",
      "INFO:tensorflow:loss = 13662.514, step = 3301 (3.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.965\n",
      "INFO:tensorflow:loss = 9404.283, step = 3401 (4.009 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5228.0225.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:06:39\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-3500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:06:39\n",
      "INFO:tensorflow:Saving dict for global step 3500: average_loss = 22.325762, global_step = 3500, loss = 9611.24\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-3500\n",
      "INFO:tensorflow:Saving checkpoints for 3501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7589.917, step = 3501\n",
      "INFO:tensorflow:global_step/sec: 25.0592\n",
      "INFO:tensorflow:loss = 7481.318, step = 3601 (3.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6964\n",
      "INFO:tensorflow:loss = 10832.033, step = 3701 (4.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0809\n",
      "INFO:tensorflow:loss = 7226.01, step = 3801 (3.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3126\n",
      "INFO:tensorflow:loss = 8385.991, step = 3901 (3.951 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6851.208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:07:03\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-4000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:07:03\n",
      "INFO:tensorflow:Saving dict for global step 4000: average_loss = 22.005413, global_step = 4000, loss = 9473.33\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-4000\n",
      "INFO:tensorflow:Saving checkpoints for 4001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 4301.3354, step = 4001\n",
      "INFO:tensorflow:global_step/sec: 23.8083\n",
      "INFO:tensorflow:loss = 6420.873, step = 4101 (4.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8324\n",
      "INFO:tensorflow:loss = 7863.1113, step = 4201 (4.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7479\n",
      "INFO:tensorflow:loss = 4846.833, step = 4301 (4.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2101\n",
      "INFO:tensorflow:loss = 8367.203, step = 4401 (3.967 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5849.163.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:07:27\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-4500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:07:27\n",
      "INFO:tensorflow:Saving dict for global step 4500: average_loss = 21.76644, global_step = 4500, loss = 9370.452\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-4500\n",
      "INFO:tensorflow:Saving checkpoints for 4501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7861.519, step = 4501\n",
      "INFO:tensorflow:global_step/sec: 24.7399\n",
      "INFO:tensorflow:loss = 5087.231, step = 4601 (4.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.887\n",
      "INFO:tensorflow:loss = 5757.3525, step = 4701 (3.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9436\n",
      "INFO:tensorflow:loss = 9939.334, step = 4801 (3.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2409\n",
      "INFO:tensorflow:loss = 5514.2056, step = 4901 (3.961 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9760.758.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:07:51\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-5000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:07:51\n",
      "INFO:tensorflow:Saving dict for global step 5000: average_loss = 21.616877, global_step = 5000, loss = 9306.065\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-5000\n",
      "INFO:tensorflow:Saving checkpoints for 5001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 6729.6177, step = 5001\n",
      "INFO:tensorflow:global_step/sec: 25.2096\n",
      "INFO:tensorflow:loss = 14077.227, step = 5101 (3.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7945\n",
      "INFO:tensorflow:loss = 9541.09, step = 5201 (3.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3055\n",
      "INFO:tensorflow:loss = 8092.448, step = 5301 (3.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7452\n",
      "INFO:tensorflow:loss = 6838.58, step = 5401 (4.041 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7883.2583.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:08:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-5500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:08:15\n",
      "INFO:tensorflow:Saving dict for global step 5500: average_loss = 21.4322, global_step = 5500, loss = 9226.562\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-5500\n",
      "INFO:tensorflow:Saving checkpoints for 5501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 8656.667, step = 5501\n",
      "INFO:tensorflow:global_step/sec: 24.0999\n",
      "INFO:tensorflow:loss = 6946.8574, step = 5601 (4.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5624\n",
      "INFO:tensorflow:loss = 12134.84, step = 5701 (4.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4562\n",
      "INFO:tensorflow:loss = 7138.42, step = 5801 (3.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3582\n",
      "INFO:tensorflow:loss = 8121.2314, step = 5901 (3.943 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4512.0283.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:08:38\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-6000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:08:39\n",
      "INFO:tensorflow:Saving dict for global step 6000: average_loss = 21.401945, global_step = 6000, loss = 9213.537\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-6000\n",
      "INFO:tensorflow:Saving checkpoints for 6001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7665.9062, step = 6001\n",
      "INFO:tensorflow:global_step/sec: 23.7117\n",
      "INFO:tensorflow:loss = 4344.139, step = 6101 (4.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7912\n",
      "INFO:tensorflow:loss = 5590.709, step = 6201 (4.034 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4364\n",
      "INFO:tensorflow:loss = 4992.7246, step = 6301 (3.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4616\n",
      "INFO:tensorflow:loss = 8969.668, step = 6401 (3.928 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6577.1416.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:09:03\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-6500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:09:03\n",
      "INFO:tensorflow:Saving dict for global step 6500: average_loss = 21.281992, global_step = 6500, loss = 9161.897\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-6500\n",
      "INFO:tensorflow:Saving checkpoints for 6501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7284.343, step = 6501\n",
      "INFO:tensorflow:global_step/sec: 23.9616\n",
      "INFO:tensorflow:loss = 8857.255, step = 6601 (4.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.229\n",
      "INFO:tensorflow:loss = 11181.322, step = 6701 (3.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.54\n",
      "INFO:tensorflow:loss = 7184.2773, step = 6801 (3.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.905\n",
      "INFO:tensorflow:loss = 5398.1357, step = 6901 (3.860 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 13445.877.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:09:27\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-7000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:09:27\n",
      "INFO:tensorflow:Saving dict for global step 7000: average_loss = 21.162243, global_step = 7000, loss = 9110.346\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-7000\n",
      "INFO:tensorflow:Saving checkpoints for 7001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7451.5674, step = 7001\n",
      "INFO:tensorflow:global_step/sec: 24.5421\n",
      "INFO:tensorflow:loss = 9965.202, step = 7101 (4.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0986\n",
      "INFO:tensorflow:loss = 13281.574, step = 7201 (3.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4349\n",
      "INFO:tensorflow:loss = 7164.582, step = 7301 (3.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2118\n",
      "INFO:tensorflow:loss = 6960.823, step = 7401 (3.967 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6119.626.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:09:51\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-7500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:09:51\n",
      "INFO:tensorflow:Saving dict for global step 7500: average_loss = 21.103083, global_step = 7500, loss = 9084.877\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-7500\n",
      "INFO:tensorflow:Saving checkpoints for 7501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 6939.1606, step = 7501\n",
      "INFO:tensorflow:global_step/sec: 23.8727\n",
      "INFO:tensorflow:loss = 5207.154, step = 7601 (4.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 13317.129, step = 7701 (4.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8839\n",
      "INFO:tensorflow:loss = 7416.993, step = 7801 (4.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7584\n",
      "INFO:tensorflow:loss = 6277.352, step = 7901 (4.040 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4541.0146.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:10:15\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-8000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:10:15\n",
      "INFO:tensorflow:Saving dict for global step 8000: average_loss = 21.023428, global_step = 8000, loss = 9050.586\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-8000\n",
      "INFO:tensorflow:Saving checkpoints for 8001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 5541.5645, step = 8001\n",
      "INFO:tensorflow:global_step/sec: 24.6198\n",
      "INFO:tensorflow:loss = 8152.533, step = 8101 (4.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3096\n",
      "INFO:tensorflow:loss = 6056.633, step = 8201 (3.951 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5434\n",
      "INFO:tensorflow:loss = 5244.365, step = 8301 (4.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.784\n",
      "INFO:tensorflow:loss = 9469.318, step = 8401 (4.035 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8437.779.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:10:39\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-8500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:10:40\n",
      "INFO:tensorflow:Saving dict for global step 8500: average_loss = 20.925255, global_step = 8500, loss = 9008.322\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-8500\n",
      "INFO:tensorflow:Saving checkpoints for 8501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 5979.5957, step = 8501\n",
      "INFO:tensorflow:global_step/sec: 24.9232\n",
      "INFO:tensorflow:loss = 8730.302, step = 8601 (4.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4826\n",
      "INFO:tensorflow:loss = 6913.2314, step = 8701 (3.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7211\n",
      "INFO:tensorflow:loss = 7934.0947, step = 8801 (3.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7792\n",
      "INFO:tensorflow:loss = 8103.469, step = 8901 (3.879 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8798.856.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:11:03\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-9000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:11:03\n",
      "INFO:tensorflow:Saving dict for global step 9000: average_loss = 20.872757, global_step = 9000, loss = 8985.722\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-9000\n",
      "INFO:tensorflow:Saving checkpoints for 9001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7735.758, step = 9001\n",
      "INFO:tensorflow:global_step/sec: 23.6882\n",
      "INFO:tensorflow:loss = 4316.6226, step = 9101 (4.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7741\n",
      "INFO:tensorflow:loss = 5325.5903, step = 9201 (3.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.421\n",
      "INFO:tensorflow:loss = 7975.9067, step = 9301 (3.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0828\n",
      "INFO:tensorflow:loss = 6942.8965, step = 9401 (3.834 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6725.37.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:11:27\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-9500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:11:27\n",
      "INFO:tensorflow:Saving dict for global step 9500: average_loss = 20.843842, global_step = 9500, loss = 8973.273\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-9500\n",
      "INFO:tensorflow:Saving checkpoints for 9501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 6557.6313, step = 9501\n",
      "INFO:tensorflow:global_step/sec: 24.7373\n",
      "INFO:tensorflow:loss = 7930.477, step = 9601 (4.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7838\n",
      "INFO:tensorflow:loss = 6912.209, step = 9701 (3.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6509\n",
      "INFO:tensorflow:loss = 6562.869, step = 9801 (3.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9297\n",
      "INFO:tensorflow:loss = 6802.184, step = 9901 (4.012 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6667.155.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:11:50\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:11:51\n",
      "INFO:tensorflow:Saving dict for global step 10000: average_loss = 20.796207, global_step = 10000, loss = 8952.768\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-10000\n",
      "INFO:tensorflow:Saving checkpoints for 10001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 10923.482, step = 10001\n",
      "INFO:tensorflow:global_step/sec: 24.0409\n",
      "INFO:tensorflow:loss = 6808.2456, step = 10101 (4.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7213\n",
      "INFO:tensorflow:loss = 4564.8354, step = 10201 (3.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7517\n",
      "INFO:tensorflow:loss = 5935.08, step = 10301 (3.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1415\n",
      "INFO:tensorflow:loss = 6732.342, step = 10401 (3.978 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 12166.052.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:12:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-10500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:12:15\n",
      "INFO:tensorflow:Saving dict for global step 10500: average_loss = 20.759455, global_step = 10500, loss = 8936.945\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-10500\n",
      "INFO:tensorflow:Saving checkpoints for 10501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 11279.339, step = 10501\n",
      "INFO:tensorflow:global_step/sec: 24.1447\n",
      "INFO:tensorflow:loss = 10246.277, step = 10601 (4.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4709\n",
      "INFO:tensorflow:loss = 5673.9575, step = 10701 (3.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0174\n",
      "INFO:tensorflow:loss = 16139.909, step = 10801 (3.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7123\n",
      "INFO:tensorflow:loss = 4457.324, step = 10901 (3.889 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6331.254.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:12:38\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-11000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:12:39\n",
      "INFO:tensorflow:Saving dict for global step 11000: average_loss = 20.671373, global_step = 11000, loss = 8899.026\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-11000\n",
      "INFO:tensorflow:Saving checkpoints for 11001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 9581.789, step = 11001\n",
      "INFO:tensorflow:global_step/sec: 24.4471\n",
      "INFO:tensorflow:loss = 6031.994, step = 11101 (4.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5788\n",
      "INFO:tensorflow:loss = 6126.083, step = 11201 (4.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3764\n",
      "INFO:tensorflow:loss = 17402.844, step = 11301 (3.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5779\n",
      "INFO:tensorflow:loss = 8779.718, step = 11401 (3.910 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9408.787.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:13:02\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-11500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:13:03\n",
      "INFO:tensorflow:Saving dict for global step 11500: average_loss = 20.630545, global_step = 11500, loss = 8881.449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-11500\n",
      "INFO:tensorflow:Saving checkpoints for 11501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 3710.3982, step = 11501\n",
      "INFO:tensorflow:global_step/sec: 23.5197\n",
      "INFO:tensorflow:loss = 4723.4766, step = 11601 (4.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2013\n",
      "INFO:tensorflow:loss = 5866.822, step = 11701 (3.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7964\n",
      "INFO:tensorflow:loss = 9168.397, step = 11801 (3.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1568\n",
      "INFO:tensorflow:loss = 10320.131, step = 11901 (3.975 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 10871.73.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:13:26\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-12000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:13:27\n",
      "INFO:tensorflow:Saving dict for global step 12000: average_loss = 20.586935, global_step = 12000, loss = 8862.676\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-12000\n",
      "INFO:tensorflow:Saving checkpoints for 12001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7292.716, step = 12001\n",
      "INFO:tensorflow:global_step/sec: 24.9225\n",
      "INFO:tensorflow:loss = 6381.4775, step = 12101 (4.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.76\n",
      "INFO:tensorflow:loss = 7958.4473, step = 12201 (3.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5852\n",
      "INFO:tensorflow:loss = 6654.1455, step = 12301 (3.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5716\n",
      "INFO:tensorflow:loss = 12243.134, step = 12401 (3.910 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8261.457.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:13:50\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-12500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:13:51\n",
      "INFO:tensorflow:Saving dict for global step 12500: average_loss = 20.5512, global_step = 12500, loss = 8847.292\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-12500\n",
      "INFO:tensorflow:Saving checkpoints for 12501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 6869.683, step = 12501\n",
      "INFO:tensorflow:global_step/sec: 24.0406\n",
      "INFO:tensorflow:loss = 13278.811, step = 12601 (4.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6512\n",
      "INFO:tensorflow:loss = 4554.299, step = 12701 (3.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8587\n",
      "INFO:tensorflow:loss = 7381.687, step = 12801 (4.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5691\n",
      "INFO:tensorflow:loss = 8396.873, step = 12901 (4.070 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9505.806.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:14:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-13000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:14:15\n",
      "INFO:tensorflow:Saving dict for global step 13000: average_loss = 20.50278, global_step = 13000, loss = 8826.447\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-13000\n",
      "INFO:tensorflow:Saving checkpoints for 13001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 9535.936, step = 13001\n",
      "INFO:tensorflow:global_step/sec: 24.9357\n",
      "INFO:tensorflow:loss = 8756.225, step = 13101 (4.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0482\n",
      "INFO:tensorflow:loss = 7313.218, step = 13201 (3.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7432\n",
      "INFO:tensorflow:loss = 15510.777, step = 13301 (4.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8926\n",
      "INFO:tensorflow:loss = 4800.3604, step = 13401 (3.862 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5526.5327.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:14:38\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-13500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:14:39\n",
      "INFO:tensorflow:Saving dict for global step 13500: average_loss = 20.47503, global_step = 13500, loss = 8814.501\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-13500\n",
      "INFO:tensorflow:Saving checkpoints for 13501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 6888.6406, step = 13501\n",
      "INFO:tensorflow:global_step/sec: 24.5935\n",
      "INFO:tensorflow:loss = 6029.8306, step = 13601 (4.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.992\n",
      "INFO:tensorflow:loss = 8364.992, step = 13701 (4.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4883\n",
      "INFO:tensorflow:loss = 7619.7876, step = 13801 (3.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1379\n",
      "INFO:tensorflow:loss = 7313.0913, step = 13901 (3.978 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4758.0483.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:15:02\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-14000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:15:03\n",
      "INFO:tensorflow:Saving dict for global step 14000: average_loss = 20.467419, global_step = 14000, loss = 8811.224\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-14000\n",
      "INFO:tensorflow:Saving checkpoints for 14001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 5660.1387, step = 14001\n",
      "INFO:tensorflow:global_step/sec: 23.3303\n",
      "INFO:tensorflow:loss = 10533.268, step = 14101 (4.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.575\n",
      "INFO:tensorflow:loss = 7470.593, step = 14201 (3.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.536\n",
      "INFO:tensorflow:loss = 10019.146, step = 14301 (3.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.944\n",
      "INFO:tensorflow:loss = 9096.518, step = 14401 (4.008 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7148.0547.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:15:26\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-14500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:15:27\n",
      "INFO:tensorflow:Saving dict for global step 14500: average_loss = 20.409674, global_step = 14500, loss = 8786.364\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-14500\n",
      "INFO:tensorflow:Saving checkpoints for 14501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 8870.254, step = 14501\n",
      "INFO:tensorflow:global_step/sec: 24.9563\n",
      "INFO:tensorflow:loss = 7982.162, step = 14601 (4.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7404\n",
      "INFO:tensorflow:loss = 5733.1035, step = 14701 (3.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6674\n",
      "INFO:tensorflow:loss = 4692.8115, step = 14801 (3.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1942\n",
      "INFO:tensorflow:loss = 7178.307, step = 14901 (3.969 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5824.292.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:15:50\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-15000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:15:51\n",
      "INFO:tensorflow:Saving dict for global step 15000: average_loss = 20.384333, global_step = 15000, loss = 8775.455\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-15000\n",
      "INFO:tensorflow:Saving checkpoints for 15001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7839.7314, step = 15001\n",
      "INFO:tensorflow:global_step/sec: 24.7025\n",
      "INFO:tensorflow:loss = 7423.641, step = 15101 (4.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.359\n",
      "INFO:tensorflow:loss = 10727.5, step = 15201 (3.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7614\n",
      "INFO:tensorflow:loss = 5421.753, step = 15301 (3.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5883\n",
      "INFO:tensorflow:loss = 6387.33, step = 15401 (3.907 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 15500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6971.1865.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:16:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-15500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:16:14\n",
      "INFO:tensorflow:Saving dict for global step 15500: average_loss = 20.330544, global_step = 15500, loss = 8752.299\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-15500\n",
      "INFO:tensorflow:Saving checkpoints for 15501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 6602.301, step = 15501\n",
      "INFO:tensorflow:global_step/sec: 23.9337\n",
      "INFO:tensorflow:loss = 10495.016, step = 15601 (4.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9655\n",
      "INFO:tensorflow:loss = 5735.3945, step = 15701 (4.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.2787\n",
      "INFO:tensorflow:loss = 7800.8, step = 15801 (4.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3131\n",
      "INFO:tensorflow:loss = 5912.6914, step = 15901 (4.113 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 14703.979.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:16:38\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-16000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:16:39\n",
      "INFO:tensorflow:Saving dict for global step 16000: average_loss = 20.327839, global_step = 16000, loss = 8751.135\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-16000\n",
      "INFO:tensorflow:Saving checkpoints for 16001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 9347.002, step = 16001\n",
      "INFO:tensorflow:global_step/sec: 24.2704\n",
      "INFO:tensorflow:loss = 5580.4297, step = 16101 (4.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9234\n",
      "INFO:tensorflow:loss = 7335.1284, step = 16201 (4.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5602\n",
      "INFO:tensorflow:loss = 13618.016, step = 16301 (4.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3028\n",
      "INFO:tensorflow:loss = 8409.282, step = 16401 (3.951 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6208.875.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:17:03\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-16500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:17:03\n",
      "INFO:tensorflow:Saving dict for global step 16500: average_loss = 20.256739, global_step = 16500, loss = 8720.526\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-16500\n",
      "INFO:tensorflow:Saving checkpoints for 16501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 8254.238, step = 16501\n",
      "INFO:tensorflow:global_step/sec: 22.9256\n",
      "INFO:tensorflow:loss = 5764.994, step = 16601 (4.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4434\n",
      "INFO:tensorflow:loss = 3835.5522, step = 16701 (3.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0218\n",
      "INFO:tensorflow:loss = 7047.666, step = 16801 (3.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5971\n",
      "INFO:tensorflow:loss = 3328.1504, step = 16901 (4.066 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9460.565.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:17:27\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-17000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:17:28\n",
      "INFO:tensorflow:Saving dict for global step 17000: average_loss = 20.229137, global_step = 17000, loss = 8708.644\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-17000\n",
      "INFO:tensorflow:Saving checkpoints for 17001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 6302.8193, step = 17001\n",
      "INFO:tensorflow:global_step/sec: 23.5759\n",
      "INFO:tensorflow:loss = 5484.499, step = 17101 (4.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.522\n",
      "INFO:tensorflow:loss = 5789.273, step = 17201 (3.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9559\n",
      "INFO:tensorflow:loss = 11400.809, step = 17301 (3.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4821\n",
      "INFO:tensorflow:loss = 7762.786, step = 17401 (3.924 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7704.901.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:17:51\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-17500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:17:52\n",
      "INFO:tensorflow:Saving dict for global step 17500: average_loss = 20.222322, global_step = 17500, loss = 8705.71\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-17500\n",
      "INFO:tensorflow:Saving checkpoints for 17501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 10148.901, step = 17501\n",
      "INFO:tensorflow:global_step/sec: 24.5823\n",
      "INFO:tensorflow:loss = 5464.922, step = 17601 (4.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0964\n",
      "INFO:tensorflow:loss = 9611.867, step = 17701 (3.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6577\n",
      "INFO:tensorflow:loss = 8682.924, step = 17801 (3.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2376\n",
      "INFO:tensorflow:loss = 6047.744, step = 17901 (3.962 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7380.7383.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:18:15\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-18000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:18:15\n",
      "INFO:tensorflow:Saving dict for global step 18000: average_loss = 20.164927, global_step = 18000, loss = 8681.001\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-18000\n",
      "INFO:tensorflow:Saving checkpoints for 18001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 5919.2734, step = 18001\n",
      "INFO:tensorflow:global_step/sec: 25.1639\n",
      "INFO:tensorflow:loss = 7822.635, step = 18101 (3.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1383\n",
      "INFO:tensorflow:loss = 5230.7017, step = 18201 (3.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6546\n",
      "INFO:tensorflow:loss = 7355.412, step = 18301 (3.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0036\n",
      "INFO:tensorflow:loss = 5304.5894, step = 18401 (3.846 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6107.5195.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:18:39\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-18500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:18:39\n",
      "INFO:tensorflow:Saving dict for global step 18500: average_loss = 20.172104, global_step = 18500, loss = 8684.091\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-18500\n",
      "INFO:tensorflow:Saving checkpoints for 18501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7017.0996, step = 18501\n",
      "INFO:tensorflow:global_step/sec: 24.1962\n",
      "INFO:tensorflow:loss = 8678.0625, step = 18601 (4.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0527\n",
      "INFO:tensorflow:loss = 8188.191, step = 18701 (3.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4092\n",
      "INFO:tensorflow:loss = 7154.4385, step = 18801 (3.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.466\n",
      "INFO:tensorflow:loss = 9915.348, step = 18901 (3.779 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6575.6924.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:19:02\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-19000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:19:03\n",
      "INFO:tensorflow:Saving dict for global step 19000: average_loss = 20.123386, global_step = 19000, loss = 8663.118\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-19000\n",
      "INFO:tensorflow:Saving checkpoints for 19001 into /tmp/tf_wx_model-9/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 10608.862, step = 19001\n",
      "INFO:tensorflow:global_step/sec: 23.4913\n",
      "INFO:tensorflow:loss = 4867.1113, step = 19101 (4.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6134\n",
      "INFO:tensorflow:loss = 11099.523, step = 19201 (3.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7861\n",
      "INFO:tensorflow:loss = 14150.204, step = 19301 (3.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8971\n",
      "INFO:tensorflow:loss = 5734.9277, step = 19401 (3.862 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6209.2383.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:19:26\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-19500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:19:27\n",
      "INFO:tensorflow:Saving dict for global step 19500: average_loss = 20.097328, global_step = 19500, loss = 8651.899\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-19500\n",
      "INFO:tensorflow:Saving checkpoints for 19501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 10523.028, step = 19501\n",
      "INFO:tensorflow:global_step/sec: 24.9689\n",
      "INFO:tensorflow:loss = 6808.67, step = 19601 (4.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8448\n",
      "INFO:tensorflow:loss = 11548.065, step = 19701 (3.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0354\n",
      "INFO:tensorflow:loss = 5986.0425, step = 19801 (3.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8277\n",
      "INFO:tensorflow:loss = 6565.4336, step = 19901 (4.028 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 11839.803.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:19:50\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-20000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:19:50\n",
      "INFO:tensorflow:Saving dict for global step 20000: average_loss = 20.074648, global_step = 20000, loss = 8642.136\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-20000\n",
      "INFO:tensorflow:Saving checkpoints for 20001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 6816.2515, step = 20001\n",
      "INFO:tensorflow:global_step/sec: 24.1713\n",
      "INFO:tensorflow:loss = 7475.4277, step = 20101 (4.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6985\n",
      "INFO:tensorflow:loss = 5901.1465, step = 20201 (3.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6338\n",
      "INFO:tensorflow:loss = 8422.686, step = 20301 (3.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3987\n",
      "INFO:tensorflow:loss = 6628.9746, step = 20401 (3.937 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6441.5547.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:20:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-20500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:20:14\n",
      "INFO:tensorflow:Saving dict for global step 20500: average_loss = 20.061592, global_step = 20500, loss = 8636.516\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-20500\n",
      "INFO:tensorflow:Saving checkpoints for 20501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 8781.488, step = 20501\n",
      "INFO:tensorflow:global_step/sec: 25.0753\n",
      "INFO:tensorflow:loss = 11256.164, step = 20601 (3.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2019\n",
      "INFO:tensorflow:loss = 5579.54, step = 20701 (3.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.212\n",
      "INFO:tensorflow:loss = 5247.592, step = 20801 (3.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0269\n",
      "INFO:tensorflow:loss = 5102.2275, step = 20901 (3.842 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5310.65.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:20:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-21000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:20:38\n",
      "INFO:tensorflow:Saving dict for global step 21000: average_loss = 20.052322, global_step = 21000, loss = 8632.524\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-21000\n",
      "INFO:tensorflow:Saving checkpoints for 21001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 6273.135, step = 21001\n",
      "INFO:tensorflow:global_step/sec: 24.6621\n",
      "INFO:tensorflow:loss = 7642.45, step = 21101 (4.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2686\n",
      "INFO:tensorflow:loss = 7400.6943, step = 21201 (3.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7142\n",
      "INFO:tensorflow:loss = 12087.682, step = 21301 (3.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9582\n",
      "INFO:tensorflow:loss = 6552.4854, step = 21401 (3.852 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8192.877.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:21:01\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-21500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:21:02\n",
      "INFO:tensorflow:Saving dict for global step 21500: average_loss = 20.018194, global_step = 21500, loss = 8617.833\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-21500\n",
      "INFO:tensorflow:Saving checkpoints for 21501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 8470.797, step = 21501\n",
      "INFO:tensorflow:global_step/sec: 22.8578\n",
      "INFO:tensorflow:loss = 4174.0293, step = 21601 (4.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9097\n",
      "INFO:tensorflow:loss = 11250.039, step = 21701 (4.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2926\n",
      "INFO:tensorflow:loss = 8015.421, step = 21801 (3.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5404\n",
      "INFO:tensorflow:loss = 7803.9805, step = 21901 (3.916 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6964.0273.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:21:25\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-22000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:21:26\n",
      "INFO:tensorflow:Saving dict for global step 22000: average_loss = 19.99915, global_step = 22000, loss = 8609.634\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-22000\n",
      "INFO:tensorflow:Saving checkpoints for 22001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 6084.15, step = 22001\n",
      "INFO:tensorflow:global_step/sec: 24.5188\n",
      "INFO:tensorflow:loss = 8798.672, step = 22101 (4.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7317\n",
      "INFO:tensorflow:loss = 5864.1436, step = 22201 (3.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4346\n",
      "INFO:tensorflow:loss = 7796.884, step = 22301 (3.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0196\n",
      "INFO:tensorflow:loss = 4649.418, step = 22401 (3.997 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8994.858.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:21:49\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-22500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:21:50\n",
      "INFO:tensorflow:Saving dict for global step 22500: average_loss = 19.980791, global_step = 22500, loss = 8601.73\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-22500\n",
      "INFO:tensorflow:Saving checkpoints for 22501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 4812.8296, step = 22501\n",
      "INFO:tensorflow:global_step/sec: 25.0102\n",
      "INFO:tensorflow:loss = 13432.819, step = 22601 (4.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3425\n",
      "INFO:tensorflow:loss = 7996.294, step = 22701 (4.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.0716\n",
      "INFO:tensorflow:loss = 5095.1235, step = 22801 (4.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1673\n",
      "INFO:tensorflow:loss = 8157.747, step = 22901 (3.974 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 13504.18.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:22:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-23000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:22:14\n",
      "INFO:tensorflow:Saving dict for global step 23000: average_loss = 20.010029, global_step = 23000, loss = 8614.317\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-23000\n",
      "INFO:tensorflow:Saving checkpoints for 23001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 5128.6836, step = 23001\n",
      "INFO:tensorflow:global_step/sec: 24.5832\n",
      "INFO:tensorflow:loss = 12133.521, step = 23101 (4.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8957\n",
      "INFO:tensorflow:loss = 5071.215, step = 23201 (3.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7076\n",
      "INFO:tensorflow:loss = 4885.732, step = 23301 (3.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9409\n",
      "INFO:tensorflow:loss = 10451.024, step = 23401 (3.855 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 12596.922.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:22:38\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-23500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:22:38\n",
      "INFO:tensorflow:Saving dict for global step 23500: average_loss = 20.080309, global_step = 23500, loss = 8644.573\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-23500\n",
      "INFO:tensorflow:Saving checkpoints for 23501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 13337.051, step = 23501\n",
      "INFO:tensorflow:global_step/sec: 24.4577\n",
      "INFO:tensorflow:loss = 7009.88, step = 23601 (4.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2254\n",
      "INFO:tensorflow:loss = 13049.178, step = 23701 (3.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7843\n",
      "INFO:tensorflow:loss = 6319.1333, step = 23801 (3.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9232\n",
      "INFO:tensorflow:loss = 6123.1343, step = 23901 (4.012 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 10824.801.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:23:01\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-24000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:23:02\n",
      "INFO:tensorflow:Saving dict for global step 24000: average_loss = 19.946882, global_step = 24000, loss = 8587.133\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-24000\n",
      "INFO:tensorflow:Saving checkpoints for 24001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 14327.18, step = 24001\n",
      "INFO:tensorflow:global_step/sec: 22.8174\n",
      "INFO:tensorflow:loss = 5541.425, step = 24101 (4.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4816\n",
      "INFO:tensorflow:loss = 7119.7627, step = 24201 (3.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3341\n",
      "INFO:tensorflow:loss = 7403.7217, step = 24301 (3.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4046\n",
      "INFO:tensorflow:loss = 3436.0493, step = 24401 (3.937 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9894.939.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:23:26\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-24500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:23:26\n",
      "INFO:tensorflow:Saving dict for global step 24500: average_loss = 19.917248, global_step = 24500, loss = 8574.375\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-24500\n",
      "INFO:tensorflow:Saving checkpoints for 24501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7600.2656, step = 24501\n",
      "INFO:tensorflow:global_step/sec: 24.6862\n",
      "INFO:tensorflow:loss = 6865.2896, step = 24601 (4.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1586\n",
      "INFO:tensorflow:loss = 5625.08, step = 24701 (3.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0967\n",
      "INFO:tensorflow:loss = 4374.992, step = 24801 (3.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.675\n",
      "INFO:tensorflow:loss = 4920.169, step = 24901 (3.895 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 10972.996.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:23:49\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-25000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:23:50\n",
      "INFO:tensorflow:Saving dict for global step 25000: average_loss = 19.89385, global_step = 25000, loss = 8564.303\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-25000\n",
      "INFO:tensorflow:Saving checkpoints for 25001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 8466.471, step = 25001\n",
      "INFO:tensorflow:global_step/sec: 24.4626\n",
      "INFO:tensorflow:loss = 11323.263, step = 25101 (4.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2114\n",
      "INFO:tensorflow:loss = 6456.845, step = 25201 (3.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7248\n",
      "INFO:tensorflow:loss = 4638.116, step = 25301 (3.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1186\n",
      "INFO:tensorflow:loss = 5993.709, step = 25401 (3.981 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6259.784.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:24:13\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-25500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:24:14\n",
      "INFO:tensorflow:Saving dict for global step 25500: average_loss = 19.913813, global_step = 25500, loss = 8572.896\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-25500\n",
      "INFO:tensorflow:Saving checkpoints for 25501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 6749.457, step = 25501\n",
      "INFO:tensorflow:global_step/sec: 24.1181\n",
      "INFO:tensorflow:loss = 10206.547, step = 25601 (4.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0968\n",
      "INFO:tensorflow:loss = 7162.4775, step = 25701 (3.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9501\n",
      "INFO:tensorflow:loss = 4911.7314, step = 25801 (3.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0184\n",
      "INFO:tensorflow:loss = 6889.7954, step = 25901 (3.997 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6534.64.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:24:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-26000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:24:38\n",
      "INFO:tensorflow:Saving dict for global step 26000: average_loss = 19.87066, global_step = 26000, loss = 8554.319\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-26000\n",
      "INFO:tensorflow:Saving checkpoints for 26001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 4078.78, step = 26001\n",
      "INFO:tensorflow:global_step/sec: 24.6481\n",
      "INFO:tensorflow:loss = 7422.8223, step = 26101 (4.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0947\n",
      "INFO:tensorflow:loss = 4847.2485, step = 26201 (3.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1145\n",
      "INFO:tensorflow:loss = 7136.206, step = 26301 (3.982 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5447\n",
      "INFO:tensorflow:loss = 7363.7666, step = 26401 (3.918 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6784.6245.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:25:01\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-26500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:25:02\n",
      "INFO:tensorflow:Saving dict for global step 26500: average_loss = 19.86065, global_step = 26500, loss = 8550.01\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-26500\n",
      "INFO:tensorflow:Saving checkpoints for 26501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 4299.2676, step = 26501\n",
      "INFO:tensorflow:global_step/sec: 23.2943\n",
      "INFO:tensorflow:loss = 10009.567, step = 26601 (4.294 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.349\n",
      "INFO:tensorflow:loss = 7403.5205, step = 26701 (3.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2534\n",
      "INFO:tensorflow:loss = 9084.787, step = 26801 (3.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0484\n",
      "INFO:tensorflow:loss = 5901.229, step = 26901 (3.993 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4019.04.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:25:25\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-27000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:25:26\n",
      "INFO:tensorflow:Saving dict for global step 27000: average_loss = 19.881071, global_step = 27000, loss = 8558.801\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-27000\n",
      "INFO:tensorflow:Saving checkpoints for 27001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 6943.8237, step = 27001\n",
      "INFO:tensorflow:global_step/sec: 23.947\n",
      "INFO:tensorflow:loss = 8651.477, step = 27101 (4.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1493\n",
      "INFO:tensorflow:loss = 8416.355, step = 27201 (4.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1988\n",
      "INFO:tensorflow:loss = 9469.268, step = 27301 (3.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3109\n",
      "INFO:tensorflow:loss = 7953.844, step = 27401 (3.951 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5290.581.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:25:49\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-27500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:25:50\n",
      "INFO:tensorflow:Saving dict for global step 27500: average_loss = 19.82228, global_step = 27500, loss = 8533.492\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-27500\n",
      "INFO:tensorflow:Saving checkpoints for 27501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 8962.211, step = 27501\n",
      "INFO:tensorflow:global_step/sec: 24.248\n",
      "INFO:tensorflow:loss = 5717.2603, step = 27601 (4.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3897\n",
      "INFO:tensorflow:loss = 5621.623, step = 27701 (3.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3616\n",
      "INFO:tensorflow:loss = 8725.615, step = 27801 (3.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7101\n",
      "INFO:tensorflow:loss = 8833.154, step = 27901 (4.047 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3977.194.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:26:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-28000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:26:14\n",
      "INFO:tensorflow:Saving dict for global step 28000: average_loss = 19.896301, global_step = 28000, loss = 8565.357\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-28000\n",
      "INFO:tensorflow:Saving checkpoints for 28001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 4803.5913, step = 28001\n",
      "INFO:tensorflow:global_step/sec: 24.606\n",
      "INFO:tensorflow:loss = 7584.8584, step = 28101 (4.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9721\n",
      "INFO:tensorflow:loss = 11583.207, step = 28201 (3.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4396\n",
      "INFO:tensorflow:loss = 5856.09, step = 28301 (3.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8156\n",
      "INFO:tensorflow:loss = 9750.0625, step = 28401 (4.031 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5611.0537.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:26:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-28500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:26:38\n",
      "INFO:tensorflow:Saving dict for global step 28500: average_loss = 19.802711, global_step = 28500, loss = 8525.067\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-28500\n",
      "INFO:tensorflow:Saving checkpoints for 28501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 5636.175, step = 28501\n",
      "INFO:tensorflow:global_step/sec: 24.0403\n",
      "INFO:tensorflow:loss = 9910.066, step = 28601 (4.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9425\n",
      "INFO:tensorflow:loss = 8321.139, step = 28701 (3.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0043\n",
      "INFO:tensorflow:loss = 5895.725, step = 28801 (3.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6244\n",
      "INFO:tensorflow:loss = 6723.39, step = 28901 (3.903 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6438.43.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:27:01\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-29000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:27:02\n",
      "INFO:tensorflow:Saving dict for global step 29000: average_loss = 19.79489, global_step = 29000, loss = 8521.7\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-29000\n",
      "INFO:tensorflow:Saving checkpoints for 29001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7460.594, step = 29001\n",
      "INFO:tensorflow:global_step/sec: 23.1632\n",
      "INFO:tensorflow:loss = 8187.6533, step = 29101 (4.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.824\n",
      "INFO:tensorflow:loss = 8692.347, step = 29201 (3.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6626\n",
      "INFO:tensorflow:loss = 7153.116, step = 29301 (3.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0342\n",
      "INFO:tensorflow:loss = 7828.1895, step = 29401 (3.841 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4422.407.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:27:25\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-29500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:27:25\n",
      "INFO:tensorflow:Saving dict for global step 29500: average_loss = 19.824385, global_step = 29500, loss = 8534.397\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-29500\n",
      "INFO:tensorflow:Saving checkpoints for 29501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 8344.34, step = 29501\n",
      "INFO:tensorflow:global_step/sec: 24.1855\n",
      "INFO:tensorflow:loss = 5105.203, step = 29601 (4.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1493\n",
      "INFO:tensorflow:loss = 8150.84, step = 29701 (3.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1906\n",
      "INFO:tensorflow:loss = 6645.823, step = 29801 (3.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1621\n",
      "INFO:tensorflow:loss = 6297.637, step = 29901 (3.974 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 15215.998.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:27:49\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-30000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:27:50\n",
      "INFO:tensorflow:Saving dict for global step 30000: average_loss = 19.857492, global_step = 30000, loss = 8548.65\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-30000\n",
      "INFO:tensorflow:Saving checkpoints for 30001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 8907.901, step = 30001\n",
      "INFO:tensorflow:global_step/sec: 24.5654\n",
      "INFO:tensorflow:loss = 9011.5625, step = 30101 (4.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.625\n",
      "INFO:tensorflow:loss = 6561.5737, step = 30201 (3.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8884\n",
      "INFO:tensorflow:loss = 6698.938, step = 30301 (4.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5624\n",
      "INFO:tensorflow:loss = 5642.7144, step = 30401 (3.912 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4999.0684.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:28:13\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-30500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:28:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 30500: average_loss = 19.75442, global_step = 30500, loss = 8504.277\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-30500\n",
      "INFO:tensorflow:Saving checkpoints for 30501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7506.662, step = 30501\n",
      "INFO:tensorflow:global_step/sec: 24.656\n",
      "INFO:tensorflow:loss = 6659.0127, step = 30601 (4.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6553\n",
      "INFO:tensorflow:loss = 11598.789, step = 30701 (3.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5874\n",
      "INFO:tensorflow:loss = 10798.184, step = 30801 (3.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9262\n",
      "INFO:tensorflow:loss = 6805.142, step = 30901 (3.857 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 31000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4275.29.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:28:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-31000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:28:37\n",
      "INFO:tensorflow:Saving dict for global step 31000: average_loss = 19.770597, global_step = 31000, loss = 8511.242\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-31000\n",
      "INFO:tensorflow:Saving checkpoints for 31001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 9399.986, step = 31001\n",
      "INFO:tensorflow:global_step/sec: 23.841\n",
      "INFO:tensorflow:loss = 6878.1475, step = 31101 (4.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6485\n",
      "INFO:tensorflow:loss = 10735.803, step = 31201 (4.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5798\n",
      "INFO:tensorflow:loss = 15229.73, step = 31301 (3.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2051\n",
      "INFO:tensorflow:loss = 6876.259, step = 31401 (3.968 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 31500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8607.159.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:29:01\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-31500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:29:01\n",
      "INFO:tensorflow:Saving dict for global step 31500: average_loss = 19.7246, global_step = 31500, loss = 8491.44\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-31500\n",
      "INFO:tensorflow:Saving checkpoints for 31501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 4667.868, step = 31501\n",
      "INFO:tensorflow:global_step/sec: 23.2742\n",
      "INFO:tensorflow:loss = 7433.9863, step = 31601 (4.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1081\n",
      "INFO:tensorflow:loss = 9312.972, step = 31701 (3.983 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5627\n",
      "INFO:tensorflow:loss = 5007.81, step = 31801 (3.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5911\n",
      "INFO:tensorflow:loss = 6859.669, step = 31901 (3.907 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9618.733.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:29:25\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-32000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:29:25\n",
      "INFO:tensorflow:Saving dict for global step 32000: average_loss = 19.738878, global_step = 32000, loss = 8497.587\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-32000\n",
      "INFO:tensorflow:Saving checkpoints for 32001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 9708.871, step = 32001\n",
      "INFO:tensorflow:global_step/sec: 24.5376\n",
      "INFO:tensorflow:loss = 4898.367, step = 32101 (4.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9512\n",
      "INFO:tensorflow:loss = 7279.076, step = 32201 (4.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8503\n",
      "INFO:tensorflow:loss = 7582.056, step = 32301 (4.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.968\n",
      "INFO:tensorflow:loss = 8615.1, step = 32401 (4.173 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5575.953.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:29:49\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-32500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:29:50\n",
      "INFO:tensorflow:Saving dict for global step 32500: average_loss = 19.677395, global_step = 32500, loss = 8471.118\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-32500\n",
      "INFO:tensorflow:Saving checkpoints for 32501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 11122.365, step = 32501\n",
      "INFO:tensorflow:global_step/sec: 23.7808\n",
      "INFO:tensorflow:loss = 8416.734, step = 32601 (4.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1457\n",
      "INFO:tensorflow:loss = 8294.3125, step = 32701 (3.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6014\n",
      "INFO:tensorflow:loss = 7791.7314, step = 32801 (3.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1467\n",
      "INFO:tensorflow:loss = 2752.8396, step = 32901 (3.977 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 33000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 12324.223.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:30:13\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-33000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:30:14\n",
      "INFO:tensorflow:Saving dict for global step 33000: average_loss = 19.673517, global_step = 33000, loss = 8469.449\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-33000\n",
      "INFO:tensorflow:Saving checkpoints for 33001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 3896.3167, step = 33001\n",
      "INFO:tensorflow:global_step/sec: 25.1568\n",
      "INFO:tensorflow:loss = 6657.1675, step = 33101 (3.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5249\n",
      "INFO:tensorflow:loss = 10196.807, step = 33201 (3.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.682\n",
      "INFO:tensorflow:loss = 8334.473, step = 33301 (3.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5611\n",
      "INFO:tensorflow:loss = 10086.736, step = 33401 (3.912 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 33500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5390.324.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:30:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-33500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:30:38\n",
      "INFO:tensorflow:Saving dict for global step 33500: average_loss = 19.72032, global_step = 33500, loss = 8489.598\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-33500\n",
      "INFO:tensorflow:Saving checkpoints for 33501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 6490.1157, step = 33501\n",
      "INFO:tensorflow:global_step/sec: 24.6773\n",
      "INFO:tensorflow:loss = 4987.754, step = 33601 (4.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3155\n",
      "INFO:tensorflow:loss = 8930.047, step = 33701 (3.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.427\n",
      "INFO:tensorflow:loss = 9564.818, step = 33801 (3.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7708\n",
      "INFO:tensorflow:loss = 13489.962, step = 33901 (3.880 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8462.406.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:31:01\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-34000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:31:01\n",
      "INFO:tensorflow:Saving dict for global step 34000: average_loss = 19.646353, global_step = 34000, loss = 8457.755\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-34000\n",
      "INFO:tensorflow:Saving checkpoints for 34001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7291.1885, step = 34001\n",
      "INFO:tensorflow:global_step/sec: 23.1382\n",
      "INFO:tensorflow:loss = 9898.471, step = 34101 (4.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8314\n",
      "INFO:tensorflow:loss = 4054.3887, step = 34201 (4.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1646\n",
      "INFO:tensorflow:loss = 6146.881, step = 34301 (3.974 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.1532\n",
      "INFO:tensorflow:loss = 7020.1455, step = 34401 (3.975 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6736.694.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:31:25\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-34500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:31:25\n",
      "INFO:tensorflow:Saving dict for global step 34500: average_loss = 19.628954, global_step = 34500, loss = 8450.265\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-34500\n",
      "INFO:tensorflow:Saving checkpoints for 34501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 11214.963, step = 34501\n",
      "INFO:tensorflow:global_step/sec: 24.6743\n",
      "INFO:tensorflow:loss = 8212.355, step = 34601 (4.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1608\n",
      "INFO:tensorflow:loss = 9236.789, step = 34701 (3.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0148\n",
      "INFO:tensorflow:loss = 5574.018, step = 34801 (3.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8264\n",
      "INFO:tensorflow:loss = 17254.2, step = 34901 (4.028 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 35000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6293.5366.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:31:49\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-35000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:31:50\n",
      "INFO:tensorflow:Saving dict for global step 35000: average_loss = 19.617186, global_step = 35000, loss = 8445.198\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-35000\n",
      "INFO:tensorflow:Saving checkpoints for 35001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 8877.682, step = 35001\n",
      "INFO:tensorflow:global_step/sec: 24.7546\n",
      "INFO:tensorflow:loss = 6548.9507, step = 35101 (4.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4362\n",
      "INFO:tensorflow:loss = 8802.665, step = 35201 (3.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4165\n",
      "INFO:tensorflow:loss = 8701.607, step = 35301 (3.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1304\n",
      "INFO:tensorflow:loss = 8926.293, step = 35401 (3.979 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 35500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7524.1455.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:32:13\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-35500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:32:13\n",
      "INFO:tensorflow:Saving dict for global step 35500: average_loss = 19.600428, global_step = 35500, loss = 8437.984\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-35500\n",
      "INFO:tensorflow:Saving checkpoints for 35501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 9977.502, step = 35501\n",
      "INFO:tensorflow:global_step/sec: 24.2846\n",
      "INFO:tensorflow:loss = 12991.955, step = 35601 (4.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3252\n",
      "INFO:tensorflow:loss = 7462.4526, step = 35701 (3.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1813\n",
      "INFO:tensorflow:loss = 6761.1475, step = 35801 (4.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.0149\n",
      "INFO:tensorflow:loss = 5121.6035, step = 35901 (4.164 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9786.2.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:32:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-36000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:32:38\n",
      "INFO:tensorflow:Saving dict for global step 36000: average_loss = 19.592968, global_step = 36000, loss = 8434.772\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-36000\n",
      "INFO:tensorflow:Saving checkpoints for 36001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7225.6006, step = 36001\n",
      "INFO:tensorflow:global_step/sec: 25.0175\n",
      "INFO:tensorflow:loss = 7335.9106, step = 36101 (3.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1971\n",
      "INFO:tensorflow:loss = 4570.3154, step = 36201 (3.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2396\n",
      "INFO:tensorflow:loss = 8255.281, step = 36301 (3.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7218\n",
      "INFO:tensorflow:loss = 11413.854, step = 36401 (4.045 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 12495.072.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:33:01\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-36500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:33:02\n",
      "INFO:tensorflow:Saving dict for global step 36500: average_loss = 19.693226, global_step = 36500, loss = 8477.934\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-36500\n",
      "INFO:tensorflow:Saving checkpoints for 36501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 5460.7925, step = 36501\n",
      "INFO:tensorflow:global_step/sec: 22.7957\n",
      "INFO:tensorflow:loss = 5408.6836, step = 36601 (4.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4532\n",
      "INFO:tensorflow:loss = 5528.421, step = 36701 (3.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6859\n",
      "INFO:tensorflow:loss = 10909.926, step = 36801 (3.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9811\n",
      "INFO:tensorflow:loss = 7826.2827, step = 36901 (4.003 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 37000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7472.499.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:33:25\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-37000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:33:26\n",
      "INFO:tensorflow:Saving dict for global step 37000: average_loss = 19.572012, global_step = 37000, loss = 8425.751\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-37000\n",
      "INFO:tensorflow:Saving checkpoints for 37001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 5530.4316, step = 37001\n",
      "INFO:tensorflow:global_step/sec: 24.0114\n",
      "INFO:tensorflow:loss = 4786.085, step = 37101 (4.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8995\n",
      "INFO:tensorflow:loss = 7793.2812, step = 37201 (4.016 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2425\n",
      "INFO:tensorflow:loss = 8443.049, step = 37301 (3.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.01\n",
      "INFO:tensorflow:loss = 4884.4053, step = 37401 (3.998 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 37500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8539.843.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:33:50\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-37500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:33:50\n",
      "INFO:tensorflow:Saving dict for global step 37500: average_loss = 19.568535, global_step = 37500, loss = 8424.254\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-37500\n",
      "INFO:tensorflow:Saving checkpoints for 37501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7573.776, step = 37501\n",
      "INFO:tensorflow:global_step/sec: 23.9372\n",
      "INFO:tensorflow:loss = 10265.146, step = 37601 (4.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.2797\n",
      "INFO:tensorflow:loss = 8651.498, step = 37701 (4.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2937\n",
      "INFO:tensorflow:loss = 9205.871, step = 37801 (3.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3917\n",
      "INFO:tensorflow:loss = 4806.4277, step = 37901 (3.939 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8471.6045.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:34:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-38000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:34:14\n",
      "INFO:tensorflow:Saving dict for global step 38000: average_loss = 19.563025, global_step = 38000, loss = 8421.882\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-38000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 38001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7362.4604, step = 38001\n",
      "INFO:tensorflow:global_step/sec: 23.9887\n",
      "INFO:tensorflow:loss = 6699.4556, step = 38101 (4.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0611\n",
      "INFO:tensorflow:loss = 8822.546, step = 38201 (3.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5039\n",
      "INFO:tensorflow:loss = 8035.867, step = 38301 (3.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2222\n",
      "INFO:tensorflow:loss = 5207.441, step = 38401 (3.964 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8663.635.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:34:38\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-38500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:34:39\n",
      "INFO:tensorflow:Saving dict for global step 38500: average_loss = 19.52511, global_step = 38500, loss = 8405.56\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-38500\n",
      "INFO:tensorflow:Saving checkpoints for 38501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 5737.766, step = 38501\n",
      "INFO:tensorflow:global_step/sec: 24.2229\n",
      "INFO:tensorflow:loss = 7910.293, step = 38601 (4.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7365\n",
      "INFO:tensorflow:loss = 5779.754, step = 38701 (4.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5432\n",
      "INFO:tensorflow:loss = 7072.0127, step = 38801 (3.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7829\n",
      "INFO:tensorflow:loss = 13481.102, step = 38901 (4.035 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 39000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4435.359.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:35:02\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-39000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:35:03\n",
      "INFO:tensorflow:Saving dict for global step 39000: average_loss = 19.512957, global_step = 39000, loss = 8400.328\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-39000\n",
      "INFO:tensorflow:Saving checkpoints for 39001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 3140.4438, step = 39001\n",
      "INFO:tensorflow:global_step/sec: 23.5785\n",
      "INFO:tensorflow:loss = 4785.384, step = 39101 (4.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9912\n",
      "INFO:tensorflow:loss = 10798.27, step = 39201 (3.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7831\n",
      "INFO:tensorflow:loss = 4282.115, step = 39301 (3.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5868\n",
      "INFO:tensorflow:loss = 9672.47, step = 39401 (3.908 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 39500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9296.231.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:35:26\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-39500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:35:26\n",
      "INFO:tensorflow:Saving dict for global step 39500: average_loss = 19.507431, global_step = 39500, loss = 8397.949\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-39500\n",
      "INFO:tensorflow:Saving checkpoints for 39501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 8577.089, step = 39501\n",
      "INFO:tensorflow:global_step/sec: 24.4507\n",
      "INFO:tensorflow:loss = 7099.072, step = 39601 (4.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6646\n",
      "INFO:tensorflow:loss = 3916.81, step = 39701 (3.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2072\n",
      "INFO:tensorflow:loss = 6170.1885, step = 39801 (3.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4365\n",
      "INFO:tensorflow:loss = 11565.492, step = 39901 (3.932 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6707.1533.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:35:50\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-40000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:35:50\n",
      "INFO:tensorflow:Saving dict for global step 40000: average_loss = 19.486822, global_step = 40000, loss = 8389.077\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-40000\n",
      "INFO:tensorflow:Saving checkpoints for 40001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 12135.422, step = 40001\n",
      "INFO:tensorflow:global_step/sec: 24.4499\n",
      "INFO:tensorflow:loss = 5869.487, step = 40101 (4.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3854\n",
      "INFO:tensorflow:loss = 7770.787, step = 40201 (3.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3378\n",
      "INFO:tensorflow:loss = 7685.2554, step = 40301 (3.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5262\n",
      "INFO:tensorflow:loss = 5698.8047, step = 40401 (3.918 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9895.223.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:36:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-40500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:36:14\n",
      "INFO:tensorflow:Saving dict for global step 40500: average_loss = 19.481295, global_step = 40500, loss = 8386.697\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-40500\n",
      "INFO:tensorflow:Saving checkpoints for 40501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 5675.4736, step = 40501\n",
      "INFO:tensorflow:global_step/sec: 24.5124\n",
      "INFO:tensorflow:loss = 7814.594, step = 40601 (4.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7976\n",
      "INFO:tensorflow:loss = 5218.115, step = 40701 (3.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9538\n",
      "INFO:tensorflow:loss = 6590.3857, step = 40801 (4.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6249\n",
      "INFO:tensorflow:loss = 7380.5024, step = 40901 (3.903 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 41000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7412.0195.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:36:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-41000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:36:38\n",
      "INFO:tensorflow:Saving dict for global step 41000: average_loss = 19.473978, global_step = 41000, loss = 8383.548\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-41000\n",
      "INFO:tensorflow:Saving checkpoints for 41001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 6885.654, step = 41001\n",
      "INFO:tensorflow:global_step/sec: 25.3057\n",
      "INFO:tensorflow:loss = 8765.627, step = 41101 (3.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8854\n",
      "INFO:tensorflow:loss = 5397.924, step = 41201 (3.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.474\n",
      "INFO:tensorflow:loss = 7630.8496, step = 41301 (3.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.846\n",
      "INFO:tensorflow:loss = 9063.697, step = 41401 (3.869 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 41500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5742.962.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:37:01\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-41500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:37:01\n",
      "INFO:tensorflow:Saving dict for global step 41500: average_loss = 19.516214, global_step = 41500, loss = 8401.73\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-41500\n",
      "INFO:tensorflow:Saving checkpoints for 41501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 6294.648, step = 41501\n",
      "INFO:tensorflow:global_step/sec: 22.912\n",
      "INFO:tensorflow:loss = 6092.01, step = 41601 (4.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2259\n",
      "INFO:tensorflow:loss = 6891.451, step = 41701 (3.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7599\n",
      "INFO:tensorflow:loss = 5668.259, step = 41801 (4.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.564\n",
      "INFO:tensorflow:loss = 7216.9243, step = 41901 (3.912 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 42000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8110.6323.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:37:25\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-42000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:37:26\n",
      "INFO:tensorflow:Saving dict for global step 42000: average_loss = 19.446642, global_step = 42000, loss = 8371.779\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-42000\n",
      "INFO:tensorflow:Saving checkpoints for 42001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 11792.619, step = 42001\n",
      "INFO:tensorflow:global_step/sec: 24.5533\n",
      "INFO:tensorflow:loss = 6541.0615, step = 42101 (4.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2149\n",
      "INFO:tensorflow:loss = 5513.17, step = 42201 (3.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3654\n",
      "INFO:tensorflow:loss = 7644.254, step = 42301 (3.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6156\n",
      "INFO:tensorflow:loss = 8898.524, step = 42401 (4.062 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 42500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6681.757.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:37:49\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-42500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:37:50\n",
      "INFO:tensorflow:Saving dict for global step 42500: average_loss = 19.425528, global_step = 42500, loss = 8362.689\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-42500\n",
      "INFO:tensorflow:Saving checkpoints for 42501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7240.949, step = 42501\n",
      "INFO:tensorflow:global_step/sec: 23.1924\n",
      "INFO:tensorflow:loss = 9951.993, step = 42601 (4.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6724\n",
      "INFO:tensorflow:loss = 7879.542, step = 42701 (4.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4918\n",
      "INFO:tensorflow:loss = 4913.37, step = 42801 (3.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4657\n",
      "INFO:tensorflow:loss = 5942.767, step = 42901 (3.927 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 43000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7555.376.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:38:13\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-43000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:38:14\n",
      "INFO:tensorflow:Saving dict for global step 43000: average_loss = 19.462168, global_step = 43000, loss = 8378.463\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-43000\n",
      "INFO:tensorflow:Saving checkpoints for 43001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 10137.228, step = 43001\n",
      "INFO:tensorflow:global_step/sec: 24.91\n",
      "INFO:tensorflow:loss = 4401.542, step = 43101 (4.016 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9081\n",
      "INFO:tensorflow:loss = 6693.5977, step = 43201 (4.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.685\n",
      "INFO:tensorflow:loss = 4063.5427, step = 43301 (3.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.027\n",
      "INFO:tensorflow:loss = 4422.078, step = 43401 (3.996 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 43500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5013.7124.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:38:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-43500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:38:38\n",
      "INFO:tensorflow:Saving dict for global step 43500: average_loss = 19.425482, global_step = 43500, loss = 8362.67\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-43500\n",
      "INFO:tensorflow:Saving checkpoints for 43501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7577.918, step = 43501\n",
      "INFO:tensorflow:global_step/sec: 24.3146\n",
      "INFO:tensorflow:loss = 12935.666, step = 43601 (4.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.505\n",
      "INFO:tensorflow:loss = 6685.272, step = 43701 (3.921 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6067\n",
      "INFO:tensorflow:loss = 7101.772, step = 43801 (3.905 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7909\n",
      "INFO:tensorflow:loss = 5900.373, step = 43901 (3.877 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 44000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6406.8457.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:39:01\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-44000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:39:01\n",
      "INFO:tensorflow:Saving dict for global step 44000: average_loss = 19.393484, global_step = 44000, loss = 8348.895\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-44000\n",
      "INFO:tensorflow:Saving checkpoints for 44001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7543.616, step = 44001\n",
      "INFO:tensorflow:global_step/sec: 23.3725\n",
      "INFO:tensorflow:loss = 7845.389, step = 44101 (4.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6473\n",
      "INFO:tensorflow:loss = 5566.0977, step = 44201 (3.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8093\n",
      "INFO:tensorflow:loss = 16490.156, step = 44301 (4.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7674\n",
      "INFO:tensorflow:loss = 8029.2393, step = 44401 (3.881 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 44500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7525.725.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:39:25\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-44500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:39:25\n",
      "INFO:tensorflow:Saving dict for global step 44500: average_loss = 19.396387, global_step = 44500, loss = 8350.145\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-44500\n",
      "INFO:tensorflow:Saving checkpoints for 44501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 5845.015, step = 44501\n",
      "INFO:tensorflow:global_step/sec: 24.3611\n",
      "INFO:tensorflow:loss = 8067.565, step = 44601 (4.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6647\n",
      "INFO:tensorflow:loss = 5076.5615, step = 44701 (3.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0952\n",
      "INFO:tensorflow:loss = 9150.076, step = 44801 (3.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7765\n",
      "INFO:tensorflow:loss = 5737.6846, step = 44901 (3.879 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 45000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6207.4243.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:39:49\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-45000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:39:49\n",
      "INFO:tensorflow:Saving dict for global step 45000: average_loss = 19.394115, global_step = 45000, loss = 8349.167\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-45000\n",
      "INFO:tensorflow:Saving checkpoints for 45001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 4276.327, step = 45001\n",
      "INFO:tensorflow:global_step/sec: 24.6739\n",
      "INFO:tensorflow:loss = 7242.445, step = 45101 (4.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5866\n",
      "INFO:tensorflow:loss = 8943.888, step = 45201 (3.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4771\n",
      "INFO:tensorflow:loss = 3968.1445, step = 45301 (3.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5578\n",
      "INFO:tensorflow:loss = 13404.858, step = 45401 (3.912 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 45500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5307.829.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:40:13\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-45500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:40:13\n",
      "INFO:tensorflow:Saving dict for global step 45500: average_loss = 19.360554, global_step = 45500, loss = 8334.719\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-45500\n",
      "INFO:tensorflow:Saving checkpoints for 45501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 4796.339, step = 45501\n",
      "INFO:tensorflow:global_step/sec: 24.0041\n",
      "INFO:tensorflow:loss = 6561.6675, step = 45601 (4.168 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.5979\n",
      "INFO:tensorflow:loss = 6561.0156, step = 45701 (3.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8306\n",
      "INFO:tensorflow:loss = 9286.67, step = 45801 (4.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0191\n",
      "INFO:tensorflow:loss = 6937.2534, step = 45901 (3.996 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 46000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5178.5103.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:40:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-46000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:40:37\n",
      "INFO:tensorflow:Saving dict for global step 46000: average_loss = 19.37683, global_step = 46000, loss = 8341.725\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-46000\n",
      "INFO:tensorflow:Saving checkpoints for 46001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7706.1436, step = 46001\n",
      "INFO:tensorflow:global_step/sec: 24.6989\n",
      "INFO:tensorflow:loss = 4865.4375, step = 46101 (4.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1928\n",
      "INFO:tensorflow:loss = 9196.087, step = 46201 (3.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3938\n",
      "INFO:tensorflow:loss = 9282.652, step = 46301 (3.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4545\n",
      "INFO:tensorflow:loss = 6249.6694, step = 46401 (3.928 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 46500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6875.0396.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:41:00\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-46500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:41:01\n",
      "INFO:tensorflow:Saving dict for global step 46500: average_loss = 19.346163, global_step = 46500, loss = 8328.523\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-46500\n",
      "INFO:tensorflow:Saving checkpoints for 46501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 7717.8213, step = 46501\n",
      "INFO:tensorflow:global_step/sec: 23.3878\n",
      "INFO:tensorflow:loss = 13244.402, step = 46601 (4.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0988\n",
      "INFO:tensorflow:loss = 5893.714, step = 46701 (3.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0771\n",
      "INFO:tensorflow:loss = 5076.5405, step = 46801 (3.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2577\n",
      "INFO:tensorflow:loss = 9702.541, step = 46901 (3.959 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 47000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6517.826.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:41:25\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-47000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:41:25\n",
      "INFO:tensorflow:Saving dict for global step 47000: average_loss = 19.339413, global_step = 47000, loss = 8325.617\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-47000\n",
      "INFO:tensorflow:Saving checkpoints for 47001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 5811.789, step = 47001\n",
      "INFO:tensorflow:global_step/sec: 24.1763\n",
      "INFO:tensorflow:loss = 10166.736, step = 47101 (4.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4642\n",
      "INFO:tensorflow:loss = 10760.664, step = 47201 (3.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6624\n",
      "INFO:tensorflow:loss = 3840.2578, step = 47301 (3.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1468\n",
      "INFO:tensorflow:loss = 4535.0093, step = 47401 (3.977 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 47500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7046.0117.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:41:49\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-47500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:41:49\n",
      "INFO:tensorflow:Saving dict for global step 47500: average_loss = 19.318907, global_step = 47500, loss = 8316.789\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-47500\n",
      "INFO:tensorflow:Saving checkpoints for 47501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 8302.37, step = 47501\n",
      "INFO:tensorflow:global_step/sec: 24.1201\n",
      "INFO:tensorflow:loss = 5048.3687, step = 47601 (4.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5452\n",
      "INFO:tensorflow:loss = 11776.411, step = 47701 (3.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4556\n",
      "INFO:tensorflow:loss = 17700.918, step = 47801 (4.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7308\n",
      "INFO:tensorflow:loss = 8476.447, step = 47901 (4.043 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 48000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7264.1797.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:42:13\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-48000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:42:13\n",
      "INFO:tensorflow:Saving dict for global step 48000: average_loss = 19.316095, global_step = 48000, loss = 8315.579\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-48000\n",
      "INFO:tensorflow:Saving checkpoints for 48001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 4323.327, step = 48001\n",
      "INFO:tensorflow:global_step/sec: 23.6901\n",
      "INFO:tensorflow:loss = 5409.359, step = 48101 (4.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1813\n",
      "INFO:tensorflow:loss = 4739.4175, step = 48201 (3.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5944\n",
      "INFO:tensorflow:loss = 9049.498, step = 48301 (4.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7905\n",
      "INFO:tensorflow:loss = 13760.786, step = 48401 (3.878 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 48500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4818.6875.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:42:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-48500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:42:37\n",
      "INFO:tensorflow:Saving dict for global step 48500: average_loss = 19.349972, global_step = 48500, loss = 8330.163\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-48500\n",
      "INFO:tensorflow:Saving checkpoints for 48501 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 8223.887, step = 48501\n",
      "INFO:tensorflow:global_step/sec: 24.5039\n",
      "INFO:tensorflow:loss = 9349.061, step = 48601 (4.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4106\n",
      "INFO:tensorflow:loss = 4879.316, step = 48701 (4.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7227\n",
      "INFO:tensorflow:loss = 10238.355, step = 48801 (4.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2179\n",
      "INFO:tensorflow:loss = 5350.7407, step = 48901 (3.966 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 49000 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 10946.139.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:43:01\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-49000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:43:02\n",
      "INFO:tensorflow:Saving dict for global step 49000: average_loss = 19.291462, global_step = 49000, loss = 8304.975\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-49000\n",
      "INFO:tensorflow:Saving checkpoints for 49001 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:loss = 8707.785, step = 49001\n",
      "INFO:tensorflow:global_step/sec: 22.5467\n",
      "INFO:tensorflow:loss = 8313.221, step = 49101 (4.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0997\n",
      "INFO:tensorflow:loss = 4509.201, step = 49201 (3.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3959\n",
      "INFO:tensorflow:loss = 6495.0825, step = 49301 (4.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2919\n",
      "INFO:tensorflow:loss = 6462.4863, step = 49401 (3.953 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 49500 into /tmp/tf_wx_model-9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 13838.606.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-16-02:43:26\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-49500\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-02:43:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 49500: average_loss = 19.397392, global_step = 49500, loss = 8350.577\n"
     ]
    }
   ],
   "source": [
    "evaluations = []  \n",
    "STEPS = 500  \n",
    "for i in range(1, 100):  \n",
    "    regressor.train(input_fn=wx_input_fn(X_train, y=y_train), steps=STEPS)\n",
    "    evaluations.append(regressor.evaluate(input_fn=wx_input_fn(X_val,\n",
    "                                                               y_val,\n",
    "                                                               num_epochs=1,\n",
    "                                                               shuffle=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ba71f63d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "loss_values = [ev['loss'] for ev in evaluations]  \n",
    "training_steps = [ev['global_step'] for ev in evaluations]\n",
    "\n",
    "plt.scatter(x=training_steps, y=loss_values)  \n",
    "plt.xlabel('Training steps')  \n",
    "plt.ylabel('Loss (SSE)')  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tf_wx_model-9/model.ckpt-49500\n"
     ]
    }
   ],
   "source": [
    "pred = regressor.predict(input_fn=wx_input_fn(X_test,  \n",
    "                                              num_epochs=1,\n",
    "                                              shuffle=False))\n",
    "\n",
    "predictions = np.array([p['predictions'][0] for p in pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Explained Variance: 0.18\n",
      "The Mean Absolute Error: 2.20 mm \n",
      "The Median Absolute Error: 1.48 mm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"The Explained Variance: %.2f\" % explained_variance_score(  \n",
    "                                            y_test, predictions))  \n",
    "print(\"The Mean Absolute Error: %.2f mm \" % mean_absolute_error(  \n",
    "                                            y_test, predictions))  \n",
    "print(\"The Median Absolute Error: %.2f mm\" % median_absolute_error(  \n",
    "                                            y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.4774148 ,  3.377352  ,  0.31059483, ...,  0.0191901 ,\n",
       "        0.5070975 ,  2.359156  ], dtype=float32)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1721"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42065    0.0\n",
       "72769    0.2\n",
       "17030    0.0\n",
       "20810    0.6\n",
       "45503    0.6\n",
       "22698    0.0\n",
       "45068    0.0\n",
       "6224     0.0\n",
       "81218    0.2\n",
       "62593    0.2\n",
       "10177    0.2\n",
       "38834    0.0\n",
       "19208    2.0\n",
       "55390    5.8\n",
       "21573    0.0\n",
       "73953    0.0\n",
       "20468    0.4\n",
       "19142    6.4\n",
       "13034    2.6\n",
       "74807    6.0\n",
       "27650    1.4\n",
       "27940    0.0\n",
       "84620    0.2\n",
       "1261     0.2\n",
       "68755    0.0\n",
       "19581    0.0\n",
       "47457    0.0\n",
       "49819    0.0\n",
       "20465    0.4\n",
       "517      0.0\n",
       "        ... \n",
       "10492    1.0\n",
       "45807    0.6\n",
       "29762    0.0\n",
       "31458    0.2\n",
       "3063     0.2\n",
       "75680    0.2\n",
       "44998    1.0\n",
       "71191    2.8\n",
       "11045    0.0\n",
       "8844     0.0\n",
       "54956    0.2\n",
       "85197    0.0\n",
       "759      0.2\n",
       "10432    0.0\n",
       "3505     0.0\n",
       "550      0.2\n",
       "80969    0.2\n",
       "82197    0.0\n",
       "10197    0.4\n",
       "26609    2.4\n",
       "59946    0.0\n",
       "56423    0.0\n",
       "28238    0.2\n",
       "45233    0.4\n",
       "45858    1.0\n",
       "27511    0.6\n",
       "52656    0.0\n",
       "64168    0.0\n",
       "29079    0.0\n",
       "71870    0.0\n",
       "Name: prcp, Length: 1721, dtype: float64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ba7376590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, predictions, edgecolors=(0, 0, 0))\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=1)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
